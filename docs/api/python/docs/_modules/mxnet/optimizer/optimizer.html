<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    
    <title>mxnet.optimizer.optimizer &#8212; Apache MXNet  documentation</title>

    <link rel="stylesheet" href="../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mxnet.css" />
    <link rel="stylesheet" href="../../../_static/material-design-lite-1.3.0/material.blue-deep_orange.min.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx_materialdesign_theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/fontawesome/all.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/fonts.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/language_data.js"></script>
    <script type="text/javascript" src="../../../_static/google_analytics.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="shortcut icon" href="../../../_static/mxnet-icon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
  </head>
<body><header class="site-header" role="banner">
  <div class="wrapper">
      <a class="site-title" rel="author" href="/"><img
            src="../../../_static/mxnet_logo.png" class="site-header-logo"></a>
    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger"/>
      <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
      </label>

      <div class="trigger">
        <a class="page-link" href="/get_started">Get Started</a>
        <a class="page-link" href="/blog">Blog</a>
        <a class="page-link" href="/features">Features</a>
        <a class="page-link" href="/ecosystem">Ecosystem</a>
        <a class="page-link page-current" href="/api">Docs & Tutorials</a>
        <a class="page-link" href="https://github.com/apache/incubator-mxnet">GitHub</a>
      </div>
    </nav>
  </div>
</header>
    <div class="mdl-layout mdl-js-layout mdl-layout--fixed-header mdl-layout--fixed-drawer"><header class="mdl-layout__header mdl-layout__header--waterfall ">
    <div class="mdl-layout__header-row">
        
        <nav class="mdl-navigation breadcrumb">
            <a class="mdl-navigation__link" href="../../index.html">Module code</a><i class="material-icons">navigate_next</i>
            <a class="mdl-navigation__link is-active">mxnet.optimizer.optimizer</a>
        </nav>
        <div class="mdl-layout-spacer"></div>
        <nav class="mdl-navigation">
        
<form class="form-inline pull-sm-right" action="../../../search.html" method="get">
      <div class="mdl-textfield mdl-js-textfield mdl-textfield--expandable mdl-textfield--floating-label mdl-textfield--align-right">
        <label id="quick-search-icon" class="mdl-button mdl-js-button mdl-button--icon"  for="waterfall-exp">
          <i class="material-icons">search</i>
        </label>
        <div class="mdl-textfield__expandable-holder">
          <input class="mdl-textfield__input" type="text" name="q"  id="waterfall-exp" placeholder="Search" />
          <input type="hidden" name="check_keywords" value="yes" />
          <input type="hidden" name="area" value="default" />
        </div>
      </div>
      <div class="mdl-tooltip" data-mdl-for="quick-search-icon">
      Quick search
      </div>
</form>
        
        </nav>
    </div>
    <div class="mdl-layout__header-row header-links">
      <div class="mdl-layout-spacer"></div>
      <nav class="mdl-navigation">
      </nav>
    </div>
</header><header class="mdl-layout__drawer">      
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/index.html">Python Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/getting-started/index.html">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/index.html">Crash Course</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/1-ndarray.html">Manipulate data with <code class="docutils literal notranslate"><span class="pre">ndarray</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/2-nn.html">Create a neural network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/3-autograd.html">Automatic differentiation with <code class="docutils literal notranslate"><span class="pre">autograd</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/4-train.html">Train the neural network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/5-predict.html">Predict with a pre-trained model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/6-use_gpus.html">Use GPUs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/to-mxnet/index.html">Moving to MXNet from Other Frameworks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/to-mxnet/pytorch.html">PyTorch vs Apache MXNet</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/packages/index.html">Packages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/gluon/index.html">Gluon</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/custom_layer_beginners.html">How to write a custom layer in Apache MxNet Gluon API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/data.html">Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/image-augmentation.html">Image Augmentation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/nn.html">Layers and Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/normalization/normalization.html">Normalization Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/activations/activations.html">Activation Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/custom-loss/custom-loss.html">Custom Loss Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/init.html">Initialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/init.html#Conclusion">Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/init.html#Recommended-Next-Steps">Recommended Next Steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/parameters.html">Parameter Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/trainer.html">Trainer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/naming.html">Naming of Gluon Parameter and Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/custom-layer.html">Custom Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/customop.html">Creating custom operators with numpy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/hybridize.html">Hybridize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/image/index.html">Image Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/mnist.html">Handwritten Digit Recognition</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/pretrained_models.html">Using pre-trained models in MXNet</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/text/index.html">Text Tutorials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/text/index.html#language-model">Language Model</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/ndarray/index.html">NDArray</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/symbol/index.html">Symbol</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/autograd/autograd.html">Automatic Differentiation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/onnx/index.html">ONNX</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/performance/index.html">Performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/performance/compression/index.html">Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/compression/int8.html">Deploy with int-8</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/performance/backend/index.html">Accelerated Backend Tools</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/deploy/index.html">Deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/export/index.html">Export</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/inference/index.html">Inference</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/index.html">Run on AWS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/use_ec2.html">Run on an EC2 Instance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/use_sagemaker.html">Run on Amazon SageMaker</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/extend/index.html">Customization</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/index.html">Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/ndarray/index.html">mxnet.ndarray</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/ndarray/mxnet.ndarray.NDArray.html">NDArray</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.context.html">mxnet.ndarray.NDArray.context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.dtype.html">mxnet.ndarray.NDArray.dtype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.grad.html">mxnet.ndarray.NDArray.grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.handle.html">mxnet.ndarray.NDArray.handle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.ndim.html">mxnet.ndarray.NDArray.ndim</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.shape.html">mxnet.ndarray.NDArray.shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.size.html">mxnet.ndarray.NDArray.size</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.stype.html">mxnet.ndarray.NDArray.stype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.writable.html">mxnet.ndarray.NDArray.writable</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.ones_like.html">mxnet.ndarray.NDArray.ones_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.zeros_like.html">mxnet.ndarray.NDArray.zeros_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.as_in_context.html">mxnet.ndarray.NDArray.as_in_context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.asnumpy.html">mxnet.ndarray.NDArray.asnumpy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.asscalar.html">mxnet.ndarray.NDArray.asscalar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.astype.html">mxnet.ndarray.NDArray.astype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.copy.html">mxnet.ndarray.NDArray.copy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.copyto.html">mxnet.ndarray.NDArray.copyto</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.tostype.html">mxnet.ndarray.NDArray.tostype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.diag.html">mxnet.ndarray.NDArray.diag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.expand_dims.html">mxnet.ndarray.NDArray.expand_dims</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.flatten.html">mxnet.ndarray.NDArray.flatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.reshape.html">mxnet.ndarray.NDArray.reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.reshape_like.html">mxnet.ndarray.NDArray.reshape_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.shape_array.html">mxnet.ndarray.NDArray.shape_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.size_array.html">mxnet.ndarray.NDArray.size_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.split.html">mxnet.ndarray.NDArray.split</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.broadcast_to.html">mxnet.ndarray.NDArray.broadcast_to</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.broadcast_axes.html">mxnet.ndarray.NDArray.broadcast_axes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.broadcast_like.html">mxnet.ndarray.NDArray.broadcast_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.pad.html">mxnet.ndarray.NDArray.pad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.repeat.html">mxnet.ndarray.NDArray.repeat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.tile.html">mxnet.ndarray.NDArray.tile</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.depth_to_space.html">mxnet.ndarray.NDArray.depth_to_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.flip.html">mxnet.ndarray.NDArray.flip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.swapaxes.html">mxnet.ndarray.NDArray.swapaxes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.space_to_depth.html">mxnet.ndarray.NDArray.space_to_depth</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.T.html">mxnet.ndarray.NDArray.T</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.transpose.html">mxnet.ndarray.NDArray.transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.argmax.html">mxnet.ndarray.NDArray.argmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.argmax_channel.html">mxnet.ndarray.NDArray.argmax_channel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.argmin.html">mxnet.ndarray.NDArray.argmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.argsort.html">mxnet.ndarray.NDArray.argsort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.sort.html">mxnet.ndarray.NDArray.sort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.topk.html">mxnet.ndarray.NDArray.topk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__getitem__.html">mxnet.ndarray.NDArray.__getitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__setitem__.html">mxnet.ndarray.NDArray.__setitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.one_hot.html">mxnet.ndarray.NDArray.one_hot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.pick.html">mxnet.ndarray.NDArray.pick</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.slice.html">mxnet.ndarray.NDArray.slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.slice_axis.html">mxnet.ndarray.NDArray.slice_axis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.slice_like.html">mxnet.ndarray.NDArray.slice_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.take.html">mxnet.ndarray.NDArray.take</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.wait_to_read.html">mxnet.ndarray.NDArray.wait_to_read</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__add__.html">mxnet.ndarray.NDArray.__add__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__div__.html">mxnet.ndarray.NDArray.__div__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__neg__.html">mxnet.ndarray.NDArray.__neg__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__mod__.html">mxnet.ndarray.NDArray.__mod__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__mul__.html">mxnet.ndarray.NDArray.__mul__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__pow__.html">mxnet.ndarray.NDArray.__pow__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__rdiv__.html">mxnet.ndarray.NDArray.__rdiv__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__rmod__.html">mxnet.ndarray.NDArray.__rmod__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__rsub__.html">mxnet.ndarray.NDArray.__rsub__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__sub__.html">mxnet.ndarray.NDArray.__sub__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.ceil.html">mxnet.ndarray.NDArray.ceil</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.fix.html">mxnet.ndarray.NDArray.fix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.floor.html">mxnet.ndarray.NDArray.floor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.rint.html">mxnet.ndarray.NDArray.rint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.round.html">mxnet.ndarray.NDArray.round</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.trunc.html">mxnet.ndarray.NDArray.trunc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.max.html">mxnet.ndarray.NDArray.max</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.mean.html">mxnet.ndarray.NDArray.mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.min.html">mxnet.ndarray.NDArray.min</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.nanprod.html">mxnet.ndarray.NDArray.nanprod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.nansum.html">mxnet.ndarray.NDArray.nansum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.norm.html">mxnet.ndarray.NDArray.norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.prod.html">mxnet.ndarray.NDArray.prod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.sum.html">mxnet.ndarray.NDArray.sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__iadd__.html">mxnet.ndarray.NDArray.__iadd__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__idiv__.html">mxnet.ndarray.NDArray.__idiv__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__imod__.html">mxnet.ndarray.NDArray.__imod__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__imul__.html">mxnet.ndarray.NDArray.__imul__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__isub__.html">mxnet.ndarray.NDArray.__isub__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__eq__.html">mxnet.ndarray.NDArray.__eq__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__ge__.html">mxnet.ndarray.NDArray.__ge__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__gt__.html">mxnet.ndarray.NDArray.__gt__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__le__.html">mxnet.ndarray.NDArray.__le__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__lt__.html">mxnet.ndarray.NDArray.__lt__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__ne__.html">mxnet.ndarray.NDArray.__ne__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.arccos.html">mxnet.ndarray.NDArray.arccos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.arcsin.html">mxnet.ndarray.NDArray.arcsin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.arctan.html">mxnet.ndarray.NDArray.arctan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.cos.html">mxnet.ndarray.NDArray.cos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.degrees.html">mxnet.ndarray.NDArray.degrees</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.radians.html">mxnet.ndarray.NDArray.radians</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.sin.html">mxnet.ndarray.NDArray.sin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.tan.html">mxnet.ndarray.NDArray.tan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.arccosh.html">mxnet.ndarray.NDArray.arccosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.arcsinh.html">mxnet.ndarray.NDArray.arcsinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.arctanh.html">mxnet.ndarray.NDArray.arctanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.cosh.html">mxnet.ndarray.NDArray.cosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.sinh.html">mxnet.ndarray.NDArray.sinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.tanh.html">mxnet.ndarray.NDArray.tanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.exp.html">mxnet.ndarray.NDArray.exp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.expm1.html">mxnet.ndarray.NDArray.expm1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.log.html">mxnet.ndarray.NDArray.log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.log1p.html">mxnet.ndarray.NDArray.log1p</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.log10.html">mxnet.ndarray.NDArray.log10</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.log2.html">mxnet.ndarray.NDArray.log2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.cbrt.html">mxnet.ndarray.NDArray.cbrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.rcbrt.html">mxnet.ndarray.NDArray.rcbrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.reciprocal.html">mxnet.ndarray.NDArray.reciprocal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.rsqrt.html">mxnet.ndarray.NDArray.rsqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.square.html">mxnet.ndarray.NDArray.square</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.sqrt.html">mxnet.ndarray.NDArray.sqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.clip.html">mxnet.ndarray.NDArray.clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.sign.html">mxnet.ndarray.NDArray.sign</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.log_softmax.html">mxnet.ndarray.NDArray.log_softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.relu.html">mxnet.ndarray.NDArray.relu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.sigmoid.html">mxnet.ndarray.NDArray.sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.softmax.html">mxnet.ndarray.NDArray.softmax</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/ndarray/routines.html">Routines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.arange.html">mxnet.ndarray.arange</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.array.html">mxnet.ndarray.array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.diag.html">mxnet.ndarray.diag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.empty.html">mxnet.ndarray.empty</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.full.html">mxnet.ndarray.full</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.load.html">mxnet.ndarray.load</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.ones.html">mxnet.ndarray.ones</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.ones_like.html">mxnet.ndarray.ones_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.save.html">mxnet.ndarray.save</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.zeros.html">mxnet.ndarray.zeros</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.zeros_like.html">mxnet.ndarray.zeros_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.cast.html">mxnet.ndarray.cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.flatten.html">mxnet.ndarray.flatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.expand_dims.html">mxnet.ndarray.expand_dims</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.reshape.html">mxnet.ndarray.reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.reshape_like.html">mxnet.ndarray.reshape_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.shape_array.html">mxnet.ndarray.shape_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.size_array.html">mxnet.ndarray.size_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.broadcast_axes.html">mxnet.ndarray.broadcast_axes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.broadcast_like.html">mxnet.ndarray.broadcast_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.broadcast_to.html">mxnet.ndarray.broadcast_to</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.pad.html">mxnet.ndarray.pad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.repeat.html">mxnet.ndarray.repeat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.tile.html">mxnet.ndarray.tile</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.depth_to_space.html">mxnet.ndarray.depth_to_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.flip.html">mxnet.ndarray.flip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.space_to_depth.html">mxnet.ndarray.space_to_depth</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.swapaxes.html">mxnet.ndarray.swapaxes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.transpose.html">mxnet.ndarray.transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.concat.html">mxnet.ndarray.concat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.split.html">mxnet.ndarray.split</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.stack.html">mxnet.ndarray.stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.batch_take.html">mxnet.ndarray.batch_take</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.one_hot.html">mxnet.ndarray.one_hot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.pick.html">mxnet.ndarray.pick</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.ravel_multi_index.html">mxnet.ndarray.ravel_multi_index</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.slice.html">mxnet.ndarray.slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.slice_axis.html">mxnet.ndarray.slice_axis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.slice_like.html">mxnet.ndarray.slice_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.take.html">mxnet.ndarray.take</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.unravel_index.html">mxnet.ndarray.unravel_index</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.where.html">mxnet.ndarray.where</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.SequenceLast.html">mxnet.ndarray.SequenceLast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.SequenceMask.html">mxnet.ndarray.SequenceMask</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.SequenceReverse.html">mxnet.ndarray.SequenceReverse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.add.html">mxnet.ndarray.add</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.add_n.html">mxnet.ndarray.add_n</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.batch_dot.html">mxnet.ndarray.batch_dot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.divide.html">mxnet.ndarray.divide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.dot.html">mxnet.ndarray.dot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.modulo.html">mxnet.ndarray.modulo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.multiply.html">mxnet.ndarray.multiply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.negative.html">mxnet.ndarray.negative</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.subtract.html">mxnet.ndarray.subtract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.arccos.html">mxnet.ndarray.arccos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.arcsin.html">mxnet.ndarray.arcsin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.arctan.html">mxnet.ndarray.arctan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.broadcast_hypot.html">mxnet.ndarray.broadcast_hypot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.degrees.html">mxnet.ndarray.degrees</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.cos.html">mxnet.ndarray.cos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.radians.html">mxnet.ndarray.radians</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sin.html">mxnet.ndarray.sin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.tan.html">mxnet.ndarray.tan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.arcsinh.html">mxnet.ndarray.arcsinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.arccosh.html">mxnet.ndarray.arccosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.arctanh.html">mxnet.ndarray.arctanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.cosh.html">mxnet.ndarray.cosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sinh.html">mxnet.ndarray.sinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.tanh.html">mxnet.ndarray.tanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.max.html">mxnet.ndarray.max</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.min.html">mxnet.ndarray.min</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.mean.html">mxnet.ndarray.mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.nanprod.html">mxnet.ndarray.nanprod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.nansum.html">mxnet.ndarray.nansum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.norm.html">mxnet.ndarray.norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.prod.html">mxnet.ndarray.prod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sum.html">mxnet.ndarray.sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.ceil.html">mxnet.ndarray.ceil</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.fix.html">mxnet.ndarray.fix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.floor.html">mxnet.ndarray.floor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.round.html">mxnet.ndarray.round</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.rint.html">mxnet.ndarray.rint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.trunc.html">mxnet.ndarray.trunc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.exp.html">mxnet.ndarray.exp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.expm1.html">mxnet.ndarray.expm1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.log.html">mxnet.ndarray.log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.log1p.html">mxnet.ndarray.log1p</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.log10.html">mxnet.ndarray.log10</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.log2.html">mxnet.ndarray.log2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.cbrt.html">mxnet.ndarray.cbrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.power.html">mxnet.ndarray.power</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.rcbrt.html">mxnet.ndarray.rcbrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.reciprocal.html">mxnet.ndarray.reciprocal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.rsqrt.html">mxnet.ndarray.rsqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.square.html">mxnet.ndarray.square</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sqrt.html">mxnet.ndarray.sqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.equal.html">mxnet.ndarray.equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.greater.html">mxnet.ndarray.greater</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.greater_equal.html">mxnet.ndarray.greater_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.lesser.html">mxnet.ndarray.lesser</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.lesser_equal.html">mxnet.ndarray.lesser_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.not_equal.html">mxnet.ndarray.not_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.logical_and.html">mxnet.ndarray.logical_and</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.logical_not.html">mxnet.ndarray.logical_not</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.logical_or.html">mxnet.ndarray.logical_or</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.logical_xor.html">mxnet.ndarray.logical_xor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.argmax.html">mxnet.ndarray.argmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.argmin.html">mxnet.ndarray.argmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.argsort.html">mxnet.ndarray.argsort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sort.html">mxnet.ndarray.sort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.topk.html">mxnet.ndarray.topk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.exponential.html">mxnet.ndarray.random.exponential</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.gamma.html">mxnet.ndarray.random.gamma</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.generalized_negative_binomial.html">mxnet.ndarray.random.generalized_negative_binomial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.multinomial.html">mxnet.ndarray.random.multinomial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.negative_binomial.html">mxnet.ndarray.random.negative_binomial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.normal.html">mxnet.ndarray.random.normal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.poisson.html">mxnet.ndarray.random.poisson</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.randint.html">mxnet.ndarray.random.randint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.randn.html">mxnet.ndarray.random.randn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.shuffle.html">mxnet.ndarray.random.shuffle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.uniform.html">mxnet.ndarray.random.uniform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.gelqf.html">mxnet.ndarray.linalg.gelqf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.gemm.html">mxnet.ndarray.linalg.gemm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.gemm2.html">mxnet.ndarray.linalg.gemm2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.potrf.html">mxnet.ndarray.linalg.potrf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.potri.html">mxnet.ndarray.linalg.potri</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.sumlogdiag.html">mxnet.ndarray.linalg.sumlogdiag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.syevd.html">mxnet.ndarray.linalg.syevd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.syrk.html">mxnet.ndarray.linalg.syrk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.trmm.html">mxnet.ndarray.linalg.trmm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.trsm.html">mxnet.ndarray.linalg.trsm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.abs.html">mxnet.ndarray.abs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.clip.html">mxnet.ndarray.clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.gamma.html">mxnet.ndarray.gamma</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.gammaln.html">mxnet.ndarray.gammaln</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.maximum.html">mxnet.ndarray.maximum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.minimum.html">mxnet.ndarray.minimum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sign.html">mxnet.ndarray.sign</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Activation.html">mxnet.ndarray.Activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.BatchNorm.html">mxnet.ndarray.BatchNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.BilinearSampler.html">mxnet.ndarray.BilinearSampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.BlockGrad.html">mxnet.ndarray.BlockGrad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Convolution.html">mxnet.ndarray.Convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Correlation.html">mxnet.ndarray.Correlation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Custom.html">mxnet.ndarray.Custom</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Deconvolution.html">mxnet.ndarray.Deconvolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Dropout.html">mxnet.ndarray.Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Embedding.html">mxnet.ndarray.Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.FullyConnected.html">mxnet.ndarray.FullyConnected</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.GridGenerator.html">mxnet.ndarray.GridGenerator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.IdentityAttachKLSparseReg.html">mxnet.ndarray.IdentityAttachKLSparseReg</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.InstanceNorm.html">mxnet.ndarray.InstanceNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.L2Normalization.html">mxnet.ndarray.L2Normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.LayerNorm.html">mxnet.ndarray.LayerNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.LeakyReLU.html">mxnet.ndarray.LeakyReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.LinearRegressionOutput.html">mxnet.ndarray.LinearRegressionOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.log_softmax.html">mxnet.ndarray.log_softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.LogisticRegressionOutput.html">mxnet.ndarray.LogisticRegressionOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.LRN.html">mxnet.ndarray.LRN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.MAERegressionOutput.html">mxnet.ndarray.MAERegressionOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.MakeLoss.html">mxnet.ndarray.MakeLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Pooling.html">mxnet.ndarray.Pooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.relu.html">mxnet.ndarray.relu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.ROIPooling.html">mxnet.ndarray.ROIPooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.RNN.html">mxnet.ndarray.RNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sigmoid.html">mxnet.ndarray.sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.smooth_l1.html">mxnet.ndarray.smooth_l1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.softmax.html">mxnet.ndarray.softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.softmax_cross_entropy.html">mxnet.ndarray.softmax_cross_entropy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.SoftmaxOutput.html">mxnet.ndarray.SoftmaxOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.SoftmaxActivation.html">mxnet.ndarray.SoftmaxActivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.SpatialTransformer.html">mxnet.ndarray.SpatialTransformer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.SVMOutput.html">mxnet.ndarray.SVMOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.UpSampling.html">mxnet.ndarray.UpSampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.count_sketch.html">mxnet.ndarray.contrib.count_sketch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.getnnz.html">mxnet.ndarray.contrib.getnnz</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.index_copy.html">mxnet.ndarray.contrib.index_copy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.fft.html">mxnet.ndarray.contrib.fft</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.ifft.html">mxnet.ndarray.contrib.ifft</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.dequantize.html">mxnet.ndarray.contrib.dequantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.quantize.html">mxnet.ndarray.contrib.quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.AdaptiveAvgPooling2D.html">mxnet.ndarray.contrib.AdaptiveAvgPooling2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.BilinearResize2D.html">mxnet.ndarray.contrib.BilinearResize2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.ctc_loss.html">mxnet.ndarray.contrib.ctc_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.DeformableConvolution.html">mxnet.ndarray.contrib.DeformableConvolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.DeformablePSROIPooling.html">mxnet.ndarray.contrib.DeformablePSROIPooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.MultiBoxDetection.html">mxnet.ndarray.contrib.MultiBoxDetection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.MultiBoxPrior.html">mxnet.ndarray.contrib.MultiBoxPrior</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.MultiBoxTarget.html">mxnet.ndarray.contrib.MultiBoxTarget</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.MultiProposal.html">mxnet.ndarray.contrib.MultiProposal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.Proposal.html">mxnet.ndarray.contrib.Proposal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.PSROIPooling.html">mxnet.ndarray.contrib.PSROIPooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.ROIAlign.html">mxnet.ndarray.contrib.ROIAlign</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.cond.html">mxnet.ndarray.contrib.cond</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.foreach.html">mxnet.ndarray.contrib.foreach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.while_loop.html">mxnet.ndarray.contrib.while_loop</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/ndarray/mxnet.ndarray.sparse.CSRNDArray.html">CSRNDArray</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.context.html">mxnet.ndarray.sparse.CSRNDArray.context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.data.html">mxnet.ndarray.sparse.CSRNDArray.data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.dtype.html">mxnet.ndarray.sparse.CSRNDArray.dtype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.indices.html">mxnet.ndarray.sparse.CSRNDArray.indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.indptr.html">mxnet.ndarray.sparse.CSRNDArray.indptr</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.shape.html">mxnet.ndarray.sparse.CSRNDArray.shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.stype.html">mxnet.ndarray.sparse.CSRNDArray.stype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.zeros_like.html">mxnet.ndarray.sparse.CSRNDArray.zeros_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.as_in_context.html">mxnet.ndarray.sparse.CSRNDArray.as_in_context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.asnumpy.html">mxnet.ndarray.sparse.CSRNDArray.asnumpy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.asscalar.html">mxnet.ndarray.sparse.CSRNDArray.asscalar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.asscipy.html">mxnet.ndarray.sparse.CSRNDArray.asscipy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.astype.html">mxnet.ndarray.sparse.CSRNDArray.astype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.copy.html">mxnet.ndarray.sparse.CSRNDArray.copy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.copyto.html">mxnet.ndarray.sparse.CSRNDArray.copyto</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.tostype.html">mxnet.ndarray.sparse.CSRNDArray.tostype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.check_format.html">mxnet.ndarray.sparse.CSRNDArray.check_format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.mean.html">mxnet.ndarray.sparse.CSRNDArray.mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.norm.html">mxnet.ndarray.sparse.CSRNDArray.norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.sum.html">mxnet.ndarray.sparse.CSRNDArray.sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.__getitem__.html">mxnet.ndarray.sparse.CSRNDArray.__getitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.__setitem__.html">mxnet.ndarray.sparse.CSRNDArray.__setitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.slice.html">mxnet.ndarray.sparse.CSRNDArray.slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.concat.html">mxnet.ndarray.sparse.concat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.wait_to_read.html">mxnet.ndarray.sparse.CSRNDArray.wait_to_read</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.ceil.html">mxnet.ndarray.sparse.CSRNDArray.ceil</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.fix.html">mxnet.ndarray.sparse.CSRNDArray.fix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.floor.html">mxnet.ndarray.sparse.CSRNDArray.floor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.round.html">mxnet.ndarray.sparse.CSRNDArray.round</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.rint.html">mxnet.ndarray.sparse.CSRNDArray.rint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.trunc.html">mxnet.ndarray.sparse.CSRNDArray.trunc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.arcsin.html">mxnet.ndarray.sparse.CSRNDArray.arcsin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.arctan.html">mxnet.ndarray.sparse.CSRNDArray.arctan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.degrees.html">mxnet.ndarray.sparse.CSRNDArray.degrees</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.radians.html">mxnet.ndarray.sparse.CSRNDArray.radians</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.sin.html">mxnet.ndarray.sparse.CSRNDArray.sin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.tan.html">mxnet.ndarray.sparse.CSRNDArray.tan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.arcsinh.html">mxnet.ndarray.sparse.CSRNDArray.arcsinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.arctanh.html">mxnet.ndarray.sparse.CSRNDArray.arctanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.sinh.html">mxnet.ndarray.sparse.CSRNDArray.sinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.tanh.html">mxnet.ndarray.sparse.CSRNDArray.tanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.expm1.html">mxnet.ndarray.sparse.CSRNDArray.expm1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.log1p.html">mxnet.ndarray.sparse.CSRNDArray.log1p</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.sqrt.html">mxnet.ndarray.sparse.CSRNDArray.sqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.square.html">mxnet.ndarray.sparse.CSRNDArray.square</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.abs.html">mxnet.ndarray.sparse.CSRNDArray.abs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.clip.html">mxnet.ndarray.sparse.CSRNDArray.clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.sign.html">mxnet.ndarray.sparse.CSRNDArray.sign</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/ndarray/mxnet.ndarray.sparse.RowSparseNDArray.html">RowSparseNDArray</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.context.html">mxnet.ndarray.sparse.RowSparseNDArray.context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.data.html">mxnet.ndarray.sparse.RowSparseNDArray.data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.dtype.html">mxnet.ndarray.sparse.RowSparseNDArray.dtype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.indices.html">mxnet.ndarray.sparse.RowSparseNDArray.indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.shape.html">mxnet.ndarray.sparse.RowSparseNDArray.shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.stype.html">mxnet.ndarray.sparse.RowSparseNDArray.stype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.as_in_context.html">mxnet.ndarray.sparse.RowSparseNDArray.as_in_context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.asnumpy.html">mxnet.ndarray.sparse.RowSparseNDArray.asnumpy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.asscalar.html">mxnet.ndarray.sparse.RowSparseNDArray.asscalar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.astype.html">mxnet.ndarray.sparse.RowSparseNDArray.astype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.copy.html">mxnet.ndarray.sparse.RowSparseNDArray.copy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.copyto.html">mxnet.ndarray.sparse.RowSparseNDArray.copyto</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.tostype.html">mxnet.ndarray.sparse.RowSparseNDArray.tostype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.check_format.html">mxnet.ndarray.sparse.RowSparseNDArray.check_format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.zeros_like.html">mxnet.ndarray.sparse.RowSparseNDArray.zeros_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.norm.html">mxnet.ndarray.sparse.RowSparseNDArray.norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.ceil.html">mxnet.ndarray.sparse.RowSparseNDArray.ceil</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.fix.html">mxnet.ndarray.sparse.RowSparseNDArray.fix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.floor.html">mxnet.ndarray.sparse.RowSparseNDArray.floor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.rint.html">mxnet.ndarray.sparse.RowSparseNDArray.rint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.round.html">mxnet.ndarray.sparse.RowSparseNDArray.round</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.trunc.html">mxnet.ndarray.sparse.RowSparseNDArray.trunc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.arcsin.html">mxnet.ndarray.sparse.RowSparseNDArray.arcsin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.arctan.html">mxnet.ndarray.sparse.RowSparseNDArray.arctan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.degrees.html">mxnet.ndarray.sparse.RowSparseNDArray.degrees</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.radians.html">mxnet.ndarray.sparse.RowSparseNDArray.radians</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.sin.html">mxnet.ndarray.sparse.RowSparseNDArray.sin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.tan.html">mxnet.ndarray.sparse.RowSparseNDArray.tan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.arcsinh.html">mxnet.ndarray.sparse.RowSparseNDArray.arcsinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.arctanh.html">mxnet.ndarray.sparse.RowSparseNDArray.arctanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.sinh.html">mxnet.ndarray.sparse.RowSparseNDArray.sinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.tanh.html">mxnet.ndarray.sparse.RowSparseNDArray.tanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.expm1.html">mxnet.ndarray.sparse.RowSparseNDArray.expm1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.log1p.html">mxnet.ndarray.sparse.RowSparseNDArray.log1p</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.sqrt.html">mxnet.ndarray.sparse.RowSparseNDArray.sqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.square.html">mxnet.ndarray.sparse.RowSparseNDArray.square</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.__getitem__.html">mxnet.ndarray.sparse.RowSparseNDArray.__getitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.__setitem__.html">mxnet.ndarray.sparse.RowSparseNDArray.__setitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.retain.html">mxnet.ndarray.sparse.RowSparseNDArray.retain</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.wait_to_read.html">mxnet.ndarray.sparse.RowSparseNDArray.wait_to_read</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.abs.html">mxnet.ndarray.sparse.RowSparseNDArray.abs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.clip.html">mxnet.ndarray.sparse.RowSparseNDArray.clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.sign.html">mxnet.ndarray.sparse.RowSparseNDArray.sign</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/ndarray/sparse_routines.html">Sparse routines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.array.html">mxnet.ndarray.sparse.array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.csr_matrix.html">mxnet.ndarray.sparse.csr_matrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.empty.html">mxnet.ndarray.sparse.empty</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.row_sparse_array.html">mxnet.ndarray.sparse.row_sparse_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.zeros.html">mxnet.ndarray.sparse.zeros</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.zeros_like.html">mxnet.ndarray.sparse.zeros_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.cast_storage.html">mxnet.ndarray.sparse.cast_storage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.retain.html">mxnet.ndarray.sparse.retain</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.slice.html">mxnet.ndarray.sparse.slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.where.html">mxnet.ndarray.sparse.where</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.add_n.html">mxnet.ndarray.sparse.add_n</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.broadcast_add.html">mxnet.ndarray.sparse.broadcast_add</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.broadcast_div.html">mxnet.ndarray.sparse.broadcast_div</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.broadcast_mul.html">mxnet.ndarray.sparse.broadcast_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.broadcast_sub.html">mxnet.ndarray.sparse.broadcast_sub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.dot.html">mxnet.ndarray.sparse.dot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.elemwise_add.html">mxnet.ndarray.sparse.elemwise_add</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.elemwise_mul.html">mxnet.ndarray.sparse.elemwise_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.elemwise_sub.html">mxnet.ndarray.sparse.elemwise_sub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.negative.html">mxnet.ndarray.sparse.negative</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.arcsin.html">mxnet.ndarray.sparse.arcsin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.arctan.html">mxnet.ndarray.sparse.arctan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.degrees.html">mxnet.ndarray.sparse.degrees</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.radians.html">mxnet.ndarray.sparse.radians</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.sin.html">mxnet.ndarray.sparse.sin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.tan.html">mxnet.ndarray.sparse.tan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.arcsinh.html">mxnet.ndarray.sparse.arcsinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.arctanh.html">mxnet.ndarray.sparse.arctanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.sinh.html">mxnet.ndarray.sparse.sinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.tanh.html">mxnet.ndarray.sparse.tanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.mean.html">mxnet.ndarray.sparse.mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.norm.html">mxnet.ndarray.sparse.norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.sum.html">mxnet.ndarray.sparse.sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.ceil.html">mxnet.ndarray.sparse.ceil</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.fix.html">mxnet.ndarray.sparse.fix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.floor.html">mxnet.ndarray.sparse.floor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.rint.html">mxnet.ndarray.sparse.rint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.round.html">mxnet.ndarray.sparse.round</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.trunc.html">mxnet.ndarray.sparse.trunc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.expm1.html">mxnet.ndarray.sparse.expm1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.log1p.html">mxnet.ndarray.sparse.log1p</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.sqrt.html">mxnet.ndarray.sparse.sqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.square.html">mxnet.ndarray.sparse.square</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.abs.html">mxnet.ndarray.sparse.abs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.sign.html">mxnet.ndarray.sparse.sign</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.adam_update.html">mxnet.ndarray.sparse.adam_update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.adagrad_update.html">mxnet.ndarray.sparse.adagrad_update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.sgd_mom_update.html">mxnet.ndarray.sparse.sgd_mom_update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.sgd_update.html">mxnet.ndarray.sparse.sgd_update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.Embedding.html">mxnet.ndarray.sparse.Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.LinearRegressionOutput.html">mxnet.ndarray.sparse.LinearRegressionOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.LogisticRegressionOutput.html">mxnet.ndarray.sparse.LogisticRegressionOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.make_loss.html">mxnet.ndarray.sparse.make_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.stop_gradient.html">mxnet.ndarray.sparse.stop_gradient</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gluon/index.html">mxnet.gluon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/nn.html">nn and contrib.nn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.nn.Block.html">Block</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.initialize.html">mxnet.gluon.nn.Block.initialize</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.save_parameters.html">mxnet.gluon.nn.Block.save_parameters</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.load_parameters.html">mxnet.gluon.nn.Block.load_parameters</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.collect_params.html">mxnet.gluon.nn.Block.collect_params</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.cast.html">mxnet.gluon.nn.Block.cast</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.apply.html">mxnet.gluon.nn.Block.apply</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.forward.html">mxnet.gluon.nn.Block.forward</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.summary.html">mxnet.gluon.nn.Block.summary</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.name_scope.html">mxnet.gluon.nn.Block.name_scope</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.register_child.html">mxnet.gluon.nn.Block.register_child</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.register_forward_hook.html">mxnet.gluon.nn.Block.register_forward_hook</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.register_forward_pre_hook.html">mxnet.gluon.nn.Block.register_forward_pre_hook</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.save_params.html">mxnet.gluon.nn.Block.save_params</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.load_params.html">mxnet.gluon.nn.Block.load_params</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.nn.HybridBlock.html">HybridBlock</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.nn.SymbolBlock.html">SymbolBlock</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Sequential.html">mxnet.gluon.nn.Sequential</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.HybridSequential.html">mxnet.gluon.nn.HybridSequential</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.nn.Concurrent.html">mxnet.gluon.contrib.nn.Concurrent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.nn.HybridConcurrent.html">mxnet.gluon.contrib.nn.HybridConcurrent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Dense.html">mxnet.gluon.nn.Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Activation.html">mxnet.gluon.nn.Activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Dropout.html">mxnet.gluon.nn.Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Flatten.html">mxnet.gluon.nn.Flatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Lambda.html">mxnet.gluon.nn.Lambda</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.HybridLambda.html">mxnet.gluon.nn.HybridLambda</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Conv1D.html">mxnet.gluon.nn.Conv1D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Conv2D.html">mxnet.gluon.nn.Conv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Conv3D.html">mxnet.gluon.nn.Conv3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Conv1DTranspose.html">mxnet.gluon.nn.Conv1DTranspose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Conv2DTranspose.html">mxnet.gluon.nn.Conv2DTranspose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Conv3DTranspose.html">mxnet.gluon.nn.Conv3DTranspose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.MaxPool1D.html">mxnet.gluon.nn.MaxPool1D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.MaxPool2D.html">mxnet.gluon.nn.MaxPool2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.MaxPool3D.html">mxnet.gluon.nn.MaxPool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.AvgPool1D.html">mxnet.gluon.nn.AvgPool1D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.AvgPool2D.html">mxnet.gluon.nn.AvgPool2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.AvgPool3D.html">mxnet.gluon.nn.AvgPool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.GlobalMaxPool1D.html">mxnet.gluon.nn.GlobalMaxPool1D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.GlobalMaxPool2D.html">mxnet.gluon.nn.GlobalMaxPool2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.GlobalMaxPool3D.html">mxnet.gluon.nn.GlobalMaxPool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.GlobalAvgPool1D.html">mxnet.gluon.nn.GlobalAvgPool1D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.GlobalAvgPool2D.html">mxnet.gluon.nn.GlobalAvgPool2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.GlobalAvgPool3D.html">mxnet.gluon.nn.GlobalAvgPool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.ReflectionPad2D.html">mxnet.gluon.nn.ReflectionPad2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.BatchNorm.html">mxnet.gluon.nn.BatchNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.InstanceNorm.html">mxnet.gluon.nn.InstanceNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.LayerNorm.html">mxnet.gluon.nn.LayerNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.nn.SyncBatchNorm.html">mxnet.gluon.contrib.nn.SyncBatchNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Embedding.html">mxnet.gluon.nn.Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.nn.SparseEmbedding.html">mxnet.gluon.contrib.nn.SparseEmbedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.LeakyReLU.html">mxnet.gluon.nn.LeakyReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.PReLU.html">mxnet.gluon.nn.PReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.ELU.html">mxnet.gluon.nn.ELU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.SELU.html">mxnet.gluon.nn.SELU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Swish.html">mxnet.gluon.nn.Swish</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/rnn.html">rnn and contrib.rnn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.LSTMCell.html">mxnet.gluon.rnn.LSTMCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.GRUCell.html">mxnet.gluon.rnn.GRUCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.RecurrentCell.html">mxnet.gluon.rnn.RecurrentCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.SequentialRNNCell.html">mxnet.gluon.rnn.SequentialRNNCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.BidirectionalCell.html">mxnet.gluon.rnn.BidirectionalCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.DropoutCell.html">mxnet.gluon.rnn.DropoutCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.ZoneoutCell.html">mxnet.gluon.rnn.ZoneoutCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.ResidualCell.html">mxnet.gluon.rnn.ResidualCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv1DRNNCell.html">mxnet.gluon.contrib.rnn.Conv1DRNNCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv2DRNNCell.html">mxnet.gluon.contrib.rnn.Conv2DRNNCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv3DRNNCell.html">mxnet.gluon.contrib.rnn.Conv3DRNNCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv1DLSTMCell.html">mxnet.gluon.contrib.rnn.Conv1DLSTMCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv2DLSTMCell.html">mxnet.gluon.contrib.rnn.Conv2DLSTMCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv3DLSTMCell.html">mxnet.gluon.contrib.rnn.Conv3DLSTMCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv1DGRUCell.html">mxnet.gluon.contrib.rnn.Conv1DGRUCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv2DGRUCell.html">mxnet.gluon.contrib.rnn.Conv2DGRUCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv3DGRUCell.html">mxnet.gluon.contrib.rnn.Conv3DGRUCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.VariationalDropoutCell.html">mxnet.gluon.contrib.rnn.VariationalDropoutCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.LSTMPCell.html">mxnet.gluon.contrib.rnn.LSTMPCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.RNN.html">mxnet.gluon.rnn.RNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.LSTM.html">mxnet.gluon.rnn.LSTM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.GRU.html">mxnet.gluon.rnn.GRU</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.loss.html"><code class="docutils literal notranslate"><span class="pre">loss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.Loss.html">mxnet.gluon.loss.Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.L2Loss.html">mxnet.gluon.loss.L2Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.L1Loss.html">mxnet.gluon.loss.L1Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.SigmoidBinaryCrossEntropyLoss.html">mxnet.gluon.loss.SigmoidBinaryCrossEntropyLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.SoftmaxCrossEntropyLoss.html">mxnet.gluon.loss.SoftmaxCrossEntropyLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.KLDivLoss.html">mxnet.gluon.loss.KLDivLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.HuberLoss.html">mxnet.gluon.loss.HuberLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.HingeLoss.html">mxnet.gluon.loss.HingeLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.SquaredHingeLoss.html">mxnet.gluon.loss.SquaredHingeLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.LogisticLoss.html">mxnet.gluon.loss.LogisticLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.TripletLoss.html">mxnet.gluon.loss.TripletLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.CTCLoss.html">mxnet.gluon.loss.CTCLoss</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.parameter.html">Parameter</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.initialize.html">mxnet.gluon.Parameter.initialize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.data.html">mxnet.gluon.Parameter.data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.list_data.html">mxnet.gluon.Parameter.list_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.list_row_sparse_data.html">mxnet.gluon.Parameter.list_row_sparse_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.row_sparse_data.html">mxnet.gluon.Parameter.row_sparse_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.set_data.html">mxnet.gluon.Parameter.set_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.shape.html">mxnet.gluon.Parameter.shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.grad.html">mxnet.gluon.Parameter.grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.list_grad.html">mxnet.gluon.Parameter.list_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.zero_grad.html">mxnet.gluon.Parameter.zero_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.grad_req.html">mxnet.gluon.Parameter.grad_req</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.cast.html">mxnet.gluon.Parameter.cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.list_ctx.html">mxnet.gluon.Parameter.list_ctx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.reset_ctx.html">mxnet.gluon.Parameter.reset_ctx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.var.html">mxnet.gluon.Parameter.var</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.Trainer.html">Trainer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Trainer.step.html">mxnet.gluon.Trainer.step</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Trainer.allreduce_grads.html">mxnet.gluon.Trainer.allreduce_grads</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Trainer.update.html">mxnet.gluon.Trainer.update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Trainer.load_states.html">mxnet.gluon.Trainer.load_states</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Trainer.save_states.html">mxnet.gluon.Trainer.save_states</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Trainer.learning_rate.html">mxnet.gluon.Trainer.learning_rate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Trainer.set_learning_rate.html">mxnet.gluon.Trainer.set_learning_rate</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.data.html">data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.Dataset.html">mxnet.gluon.data.Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.ArrayDataset.html">mxnet.gluon.data.ArrayDataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.RecordFileDataset.html">mxnet.gluon.data.RecordFileDataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.Sampler.html">mxnet.gluon.data.Sampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.SequentialSampler.html">mxnet.gluon.data.SequentialSampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.RandomSampler.html">mxnet.gluon.data.RandomSampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.BatchSampler.html">mxnet.gluon.data.BatchSampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.DataLoader.html">mxnet.gluon.data.DataLoader</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.data.vision.html">data.vision</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.datasets.MNIST.html">mxnet.gluon.data.vision.datasets.MNIST</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.datasets.FashionMNIST.html">mxnet.gluon.data.vision.datasets.FashionMNIST</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.datasets.CIFAR10.html">mxnet.gluon.data.vision.datasets.CIFAR10</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.datasets.CIFAR100.html">mxnet.gluon.data.vision.datasets.CIFAR100</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.datasets.ImageRecordDataset.html">mxnet.gluon.data.vision.datasets.ImageRecordDataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.datasets.ImageFolderDataset.html">mxnet.gluon.data.vision.datasets.ImageFolderDataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.Compose.html">mxnet.gluon.data.vision.transforms.Compose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.Cast.html">mxnet.gluon.data.vision.transforms.Cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.ToTensor.html">mxnet.gluon.data.vision.transforms.ToTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.Normalize.html">mxnet.gluon.data.vision.transforms.Normalize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomResizedCrop.html">mxnet.gluon.data.vision.transforms.RandomResizedCrop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.CenterCrop.html">mxnet.gluon.data.vision.transforms.CenterCrop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.Resize.html">mxnet.gluon.data.vision.transforms.Resize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomFlipLeftRight.html">mxnet.gluon.data.vision.transforms.RandomFlipLeftRight</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomFlipTopBottom.html">mxnet.gluon.data.vision.transforms.RandomFlipTopBottom</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomBrightness.html">mxnet.gluon.data.vision.transforms.RandomBrightness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomContrast.html">mxnet.gluon.data.vision.transforms.RandomContrast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomSaturation.html">mxnet.gluon.data.vision.transforms.RandomSaturation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomHue.html">mxnet.gluon.data.vision.transforms.RandomHue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomColorJitter.html">mxnet.gluon.data.vision.transforms.RandomColorJitter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomLighting.html">mxnet.gluon.data.vision.transforms.RandomLighting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.model_zoo.html">model_zoo.vision</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.get_model.html">mxnet.gluon.model_zoo.vision.get_model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet18_v1.html">mxnet.gluon.model_zoo.vision.resnet18_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet34_v1.html">mxnet.gluon.model_zoo.vision.resnet34_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet50_v1.html">mxnet.gluon.model_zoo.vision.resnet50_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet101_v1.html">mxnet.gluon.model_zoo.vision.resnet101_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet152_v1.html">mxnet.gluon.model_zoo.vision.resnet152_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet18_v2.html">mxnet.gluon.model_zoo.vision.resnet18_v2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet34_v2.html">mxnet.gluon.model_zoo.vision.resnet34_v2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet50_v2.html">mxnet.gluon.model_zoo.vision.resnet50_v2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet101_v2.html">mxnet.gluon.model_zoo.vision.resnet101_v2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet152_v2.html">mxnet.gluon.model_zoo.vision.resnet152_v2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.ResNetV1.html">mxnet.gluon.model_zoo.vision.ResNetV1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.ResNetV2.html">mxnet.gluon.model_zoo.vision.ResNetV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.BasicBlockV1.html">mxnet.gluon.model_zoo.vision.BasicBlockV1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.BasicBlockV2.html">mxnet.gluon.model_zoo.vision.BasicBlockV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.BottleneckV1.html">mxnet.gluon.model_zoo.vision.BottleneckV1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.BottleneckV2.html">mxnet.gluon.model_zoo.vision.BottleneckV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.get_resnet.html">mxnet.gluon.model_zoo.vision.get_resnet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg11.html">mxnet.gluon.model_zoo.vision.vgg11</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg13.html">mxnet.gluon.model_zoo.vision.vgg13</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg16.html">mxnet.gluon.model_zoo.vision.vgg16</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg19.html">mxnet.gluon.model_zoo.vision.vgg19</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg11_bn.html">mxnet.gluon.model_zoo.vision.vgg11_bn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg13_bn.html">mxnet.gluon.model_zoo.vision.vgg13_bn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg16_bn.html">mxnet.gluon.model_zoo.vision.vgg16_bn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg19_bn.html">mxnet.gluon.model_zoo.vision.vgg19_bn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.VGG.html">mxnet.gluon.model_zoo.vision.VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.get_vgg.html">mxnet.gluon.model_zoo.vision.get_vgg</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.alexnet.html">mxnet.gluon.model_zoo.vision.alexnet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.AlexNet.html">mxnet.gluon.model_zoo.vision.AlexNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.densenet121.html">mxnet.gluon.model_zoo.vision.densenet121</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.densenet161.html">mxnet.gluon.model_zoo.vision.densenet161</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.densenet169.html">mxnet.gluon.model_zoo.vision.densenet169</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.densenet201.html">mxnet.gluon.model_zoo.vision.densenet201</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.DenseNet.html">mxnet.gluon.model_zoo.vision.DenseNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.squeezenet1_0.html">mxnet.gluon.model_zoo.vision.squeezenet1_0</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.squeezenet1_1.html">mxnet.gluon.model_zoo.vision.squeezenet1_1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.SqueezeNet.html">mxnet.gluon.model_zoo.vision.SqueezeNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.inception_v3.html">mxnet.gluon.model_zoo.vision.inception_v3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.Inception3.html">mxnet.gluon.model_zoo.vision.Inception3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet1_0.html">mxnet.gluon.model_zoo.vision.mobilenet1_0</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet0_75.html">mxnet.gluon.model_zoo.vision.mobilenet0_75</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet0_5.html">mxnet.gluon.model_zoo.vision.mobilenet0_5</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet0_25.html">mxnet.gluon.model_zoo.vision.mobilenet0_25</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0.html">mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75.html">mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet_v2_0_5.html">mxnet.gluon.model_zoo.vision.mobilenet_v2_0_5</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25.html">mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.MobileNet.html">mxnet.gluon.model_zoo.vision.MobileNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.MobileNetV2.html">mxnet.gluon.model_zoo.vision.MobileNetV2</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.utils.html">utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.utils.split_data.html">mxnet.gluon.utils.split_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.utils.split_and_load.html">mxnet.gluon.utils.split_and_load</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.utils.clip_global_norm.html">mxnet.gluon.utils.clip_global_norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.utils.download.html">mxnet.gluon.utils.download</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.utils.check_sha1.html">mxnet.gluon.utils.check_sha1</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gluon-related/index.html">Gluon related modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.autograd.html">mxnet.autograd</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.backward.html">mxnet.autograd.backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.get_symbol.html">mxnet.autograd.get_symbol</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.grad.html">mxnet.autograd.grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.is_recording.html">mxnet.autograd.is_recording</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.is_training.html">mxnet.autograd.is_training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.mark_variables.html">mxnet.autograd.mark_variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.pause.html">mxnet.autograd.pause</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.predict_mode.html">mxnet.autograd.predict_mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.record.html">mxnet.autograd.record</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.set_recording.html">mxnet.autograd.set_recording</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.set_training.html">mxnet.autograd.set_training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.train_mode.html">mxnet.autograd.train_mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.Function.html">mxnet.autograd.Function</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.image.html">mxnet.image</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.imdecode.html">mxnet.image.imdecode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.scale_down.html">mxnet.image.scale_down</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.resize_short.html">mxnet.image.resize_short</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.fixed_crop.html">mxnet.image.fixed_crop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.random_crop.html">mxnet.image.random_crop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.center_crop.html">mxnet.image.center_crop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.color_normalize.html">mxnet.image.color_normalize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.random_size_crop.html">mxnet.image.random_size_crop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.ImageIter.html">mxnet.image.ImageIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.CreateAugmenter.html">mxnet.image.CreateAugmenter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.Augmenter.html">mxnet.image.Augmenter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.SequentialAug.html">mxnet.image.SequentialAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.RandomOrderAug.html">mxnet.image.RandomOrderAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.ResizeAug.html">mxnet.image.ResizeAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.ForceResizeAug.html">mxnet.image.ForceResizeAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.RandomCropAug.html">mxnet.image.RandomCropAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.RandomSizedCropAug.html">mxnet.image.RandomSizedCropAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.CenterCropAug.html">mxnet.image.CenterCropAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.BrightnessJitterAug.html">mxnet.image.BrightnessJitterAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.ContrastJitterAug.html">mxnet.image.ContrastJitterAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.SaturationJitterAug.html">mxnet.image.SaturationJitterAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.HueJitterAug.html">mxnet.image.HueJitterAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.ColorJitterAug.html">mxnet.image.ColorJitterAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.LightingAug.html">mxnet.image.LightingAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.ColorNormalizeAug.html">mxnet.image.ColorNormalizeAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.RandomGrayAug.html">mxnet.image.RandomGrayAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.HorizontalFlipAug.html">mxnet.image.HorizontalFlipAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.CastAug.html">mxnet.image.CastAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.ImageDetIter.html">mxnet.image.ImageDetIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.CreateDetAugmenter.html">mxnet.image.CreateDetAugmenter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.DetBorrowAug.html">mxnet.image.DetBorrowAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.DetRandomSelectAug.html">mxnet.image.DetRandomSelectAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.DetHorizontalFlipAug.html">mxnet.image.DetHorizontalFlipAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.DetRandomCropAug.html">mxnet.image.DetRandomCropAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.DetRandomPadAug.html">mxnet.image.DetRandomPadAug</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.io.html">mxnet.io</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.NDArrayIter.html">mxnet.io.NDArrayIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.CSVIter.html">mxnet.io.CSVIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.LibSVMIter.html">mxnet.io.LibSVMIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.MNISTIter.html">mxnet.io.MNISTIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.ImageDetRecordIter.html">mxnet.io.ImageDetRecordIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.ImageRecordIter.html">mxnet.io.ImageRecordIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.ImageRecordIter_v1.html">mxnet.io.ImageRecordIter_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.ImageRecordUInt8Iter.html">mxnet.io.ImageRecordUInt8Iter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.ImageRecordUInt8Iter_v1.html">mxnet.io.ImageRecordUInt8Iter_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.DataBatch.html">mxnet.io.DataBatch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.DataDesc.html">mxnet.io.DataDesc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.DataIter.html">mxnet.io.DataIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.MXDataIter.html">mxnet.io.MXDataIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.PrefetchingIter.html">mxnet.io.PrefetchingIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.ResizeIter.html">mxnet.io.ResizeIter</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.recordio.html">mxnet.recordio</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.recordio.MXIndexedRecordIO.html">mxnet.recordio.MXIndexedRecordIO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.recordio.MXRecordIO.html">mxnet.recordio.MXRecordIO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.recordio.IRHeader.html">mxnet.recordio.IRHeader</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.recordio.pack.html">mxnet.recordio.pack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.recordio.pack_img.html">mxnet.recordio.pack_img</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.recordio.unpack.html">mxnet.recordio.unpack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.recordio.unpack_img.html">mxnet.recordio.unpack_img</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.kvstore.html">mxnet.kvstore</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/mxnet.kvstore.create.html">create</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/mxnet.kvstore.KVStore.html">KVStore</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.init.html">mxnet.kvstore.KVStore.init</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.pull.html">mxnet.kvstore.KVStore.pull</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.push.html">mxnet.kvstore.KVStore.push</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.row_sparse_pull.html">mxnet.kvstore.KVStore.row_sparse_pull</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.load_optimizer_states.html">mxnet.kvstore.KVStore.load_optimizer_states</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.save_optimizer_states.html">mxnet.kvstore.KVStore.save_optimizer_states</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.set_gradient_compression.html">mxnet.kvstore.KVStore.set_gradient_compression</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.set_optimizer.html">mxnet.kvstore.KVStore.set_optimizer</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.num_workers.html">mxnet.kvstore.KVStore.num_workers</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.rank.html">mxnet.kvstore.KVStore.rank</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.type.html">mxnet.kvstore.KVStore.type</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.optimizer.html">mxnet.optimizer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.AdaDelta.html">mxnet.optimizer.AdaDelta</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.AdaGrad.html">mxnet.optimizer.AdaGrad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Adam.html">mxnet.optimizer.Adam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Adamax.html">mxnet.optimizer.Adamax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.DCASGD.html">mxnet.optimizer.DCASGD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.FTML.html">mxnet.optimizer.FTML</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Ftrl.html">mxnet.optimizer.Ftrl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.LBSGD.html">mxnet.optimizer.LBSGD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.NAG.html">mxnet.optimizer.NAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Nadam.html">mxnet.optimizer.Nadam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Optimizer.html">mxnet.optimizer.Optimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.RMSProp.html">mxnet.optimizer.RMSProp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.SGD.html">mxnet.optimizer.SGD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.SGLD.html">mxnet.optimizer.SGLD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Signum.html">mxnet.optimizer.Signum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Updater.html">mxnet.optimizer.Updater</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.random.html">mxnet.random</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.random.seed.html">mxnet.random.seed</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.profiler.html">mxnet.profiler</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.set_config.html">mxnet.profiler.set_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.set_kvstore_handle.html">mxnet.profiler.set_kvstore_handle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.set_state.html">mxnet.profiler.set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.profiler_set_config.html">mxnet.profiler.profiler_set_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.profiler_set_state.html">mxnet.profiler.profiler_set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.pause.html">mxnet.profiler.pause</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.resume.html">mxnet.profiler.resume</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.dump.html">mxnet.profiler.dump</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.dump_profile.html">mxnet.profiler.dump_profile</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.dumps.html">mxnet.profiler.dumps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.Counter.html">mxnet.profiler.Counter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.Domain.html">mxnet.profiler.Domain</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.Event.html">mxnet.profiler.Event</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.Frame.html">mxnet.profiler.Frame</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.Marker.html">mxnet.profiler.Marker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.Task.html">mxnet.profiler.Task</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.context.html">mxnet.context</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.context.cpu.html">mxnet.context.cpu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.context.cpu_pinned.html">mxnet.context.cpu_pinned</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.context.current_context.html">mxnet.context.current_context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.context.gpu.html">mxnet.context.gpu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.context.num_gpus.html">mxnet.context.num_gpus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.context.Context.html">mxnet.context.Context</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.initializer.html">mxnet.initializer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Bilinear.html">mxnet.initializer.Bilinear</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Constant.html">mxnet.initializer.Constant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.FusedRNN.html">mxnet.initializer.FusedRNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.InitDesc.html">mxnet.initializer.InitDesc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Initializer.html">mxnet.initializer.Initializer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.LSTMBias.html">mxnet.initializer.LSTMBias</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Load.html">mxnet.initializer.Load</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.MSRAPrelu.html">mxnet.initializer.MSRAPrelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Mixed.html">mxnet.initializer.Mixed</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Normal.html">mxnet.initializer.Normal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.One.html">mxnet.initializer.One</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Orthogonal.html">mxnet.initializer.Orthogonal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Uniform.html">mxnet.initializer.Uniform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Xavier.html">mxnet.initializer.Xavier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Zero.html">mxnet.initializer.Zero</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.register.html">mxnet.initializer.register</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.lr_scheduler.html">mxnet.lr_scheduler</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.lr_scheduler.LRScheduler.html">mxnet.lr_scheduler.LRScheduler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.lr_scheduler.FactorScheduler.html">mxnet.lr_scheduler.FactorScheduler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.lr_scheduler.MultiFactorScheduler.html">mxnet.lr_scheduler.MultiFactorScheduler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.lr_scheduler.PolyScheduler.html">mxnet.lr_scheduler.PolyScheduler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.lr_scheduler.CosineScheduler.html">mxnet.lr_scheduler.CosineScheduler</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.metric.html">mxnet.metric</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.Accuracy.html">mxnet.metric.Accuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.Caffe.html">mxnet.metric.Caffe</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.CompositeEvalMetric.html">mxnet.metric.CompositeEvalMetric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.CrossEntropy.html">mxnet.metric.CrossEntropy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.CustomMetric.html">mxnet.metric.CustomMetric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.EvalMetric.html">mxnet.metric.EvalMetric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.F1.html">mxnet.metric.F1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.Loss.html">mxnet.metric.Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.MAE.html">mxnet.metric.MAE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.MCC.html">mxnet.metric.MCC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.MSE.html">mxnet.metric.MSE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.NegativeLogLikelihood.html">mxnet.metric.NegativeLogLikelihood</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.PearsonCorrelation.html">mxnet.metric.PearsonCorrelation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.Perplexity.html">mxnet.metric.Perplexity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.RMSE.html">mxnet.metric.RMSE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.TopKAccuracy.html">mxnet.metric.TopKAccuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.Torch.html">mxnet.metric.Torch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.check_label_shapes.html">mxnet.metric.check_label_shapes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.create.html">mxnet.metric.create</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.np.html">mxnet.metric.np</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/symbol/index.html">mxnet.symbol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/symbol/mxnet.symbol.Symbol.html">Symbol</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__call__.html">mxnet.symbol.Symbol.__call__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__add__.html">mxnet.symbol.Symbol.__add__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__sub__.html">mxnet.symbol.Symbol.__sub__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__rsub__.html">mxnet.symbol.Symbol.__rsub__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__neg__.html">mxnet.symbol.Symbol.__neg__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__mul__.html">mxnet.symbol.Symbol.__mul__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__div__.html">mxnet.symbol.Symbol.__div__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__rdiv__.html">mxnet.symbol.Symbol.__rdiv__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__mod__.html">mxnet.symbol.Symbol.__mod__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__rmod__.html">mxnet.symbol.Symbol.__rmod__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__pow__.html">mxnet.symbol.Symbol.__pow__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.sin.html">mxnet.symbol.Symbol.sin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.cos.html">mxnet.symbol.Symbol.cos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.tan.html">mxnet.symbol.Symbol.tan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.arcsin.html">mxnet.symbol.Symbol.arcsin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.arccos.html">mxnet.symbol.Symbol.arccos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.arctan.html">mxnet.symbol.Symbol.arctan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.degrees.html">mxnet.symbol.Symbol.degrees</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.radians.html">mxnet.symbol.Symbol.radians</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.sinh.html">mxnet.symbol.Symbol.sinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.cosh.html">mxnet.symbol.Symbol.cosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.tanh.html">mxnet.symbol.Symbol.tanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.arcsinh.html">mxnet.symbol.Symbol.arcsinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.arccosh.html">mxnet.symbol.Symbol.arccosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.arctanh.html">mxnet.symbol.Symbol.arctanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.exp.html">mxnet.symbol.Symbol.exp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.expm1.html">mxnet.symbol.Symbol.expm1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.log.html">mxnet.symbol.Symbol.log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.log10.html">mxnet.symbol.Symbol.log10</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.log2.html">mxnet.symbol.Symbol.log2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.log1p.html">mxnet.symbol.Symbol.log1p</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.sqrt.html">mxnet.symbol.Symbol.sqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.rsqrt.html">mxnet.symbol.Symbol.rsqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.cbrt.html">mxnet.symbol.Symbol.cbrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.rcbrt.html">mxnet.symbol.Symbol.rcbrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.square.html">mxnet.symbol.Symbol.square</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.relu.html">mxnet.symbol.Symbol.relu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.sigmoid.html">mxnet.symbol.Symbol.sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.softmax.html">mxnet.symbol.Symbol.softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.log_softmax.html">mxnet.symbol.Symbol.log_softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__lt__.html">mxnet.symbol.Symbol.__lt__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__le__.html">mxnet.symbol.Symbol.__le__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__gt__.html">mxnet.symbol.Symbol.__gt__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__ge__.html">mxnet.symbol.Symbol.__ge__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__eq__.html">mxnet.symbol.Symbol.__eq__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__ne__.html">mxnet.symbol.Symbol.__ne__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.zeros_like.html">mxnet.symbol.Symbol.zeros_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.ones_like.html">mxnet.symbol.Symbol.ones_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.diag.html">mxnet.symbol.Symbol.diag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.astype.html">mxnet.symbol.Symbol.astype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.shape_array.html">mxnet.symbol.Symbol.shape_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.size_array.html">mxnet.symbol.Symbol.size_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.reshape.html">mxnet.symbol.Symbol.reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.reshape_like.html">mxnet.symbol.Symbol.reshape_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.flatten.html">mxnet.symbol.Symbol.flatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.expand_dims.html">mxnet.symbol.Symbol.expand_dims</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.broadcast_to.html">mxnet.symbol.Symbol.broadcast_to</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.broadcast_axes.html">mxnet.symbol.Symbol.broadcast_axes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.broadcast_like.html">mxnet.symbol.Symbol.broadcast_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.tile.html">mxnet.symbol.Symbol.tile</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.pad.html">mxnet.symbol.Symbol.pad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.transpose.html">mxnet.symbol.Symbol.transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.swapaxes.html">mxnet.symbol.Symbol.swapaxes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.flip.html">mxnet.symbol.Symbol.flip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.depth_to_space.html">mxnet.symbol.Symbol.depth_to_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.space_to_depth.html">mxnet.symbol.Symbol.space_to_depth</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.sum.html">mxnet.symbol.Symbol.sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.nansum.html">mxnet.symbol.Symbol.nansum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.prod.html">mxnet.symbol.Symbol.prod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.nanprod.html">mxnet.symbol.Symbol.nanprod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.mean.html">mxnet.symbol.Symbol.mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.max.html">mxnet.symbol.Symbol.max</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.min.html">mxnet.symbol.Symbol.min</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.norm.html">mxnet.symbol.Symbol.norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.round.html">mxnet.symbol.Symbol.round</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.rint.html">mxnet.symbol.Symbol.rint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.fix.html">mxnet.symbol.Symbol.fix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.floor.html">mxnet.symbol.Symbol.floor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.ceil.html">mxnet.symbol.Symbol.ceil</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.trunc.html">mxnet.symbol.Symbol.trunc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.sort.html">mxnet.symbol.Symbol.sort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.argsort.html">mxnet.symbol.Symbol.argsort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.topk.html">mxnet.symbol.Symbol.topk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.argmax.html">mxnet.symbol.Symbol.argmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.argmin.html">mxnet.symbol.Symbol.argmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.argmax_channel.html">mxnet.symbol.Symbol.argmax_channel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.name.html">mxnet.symbol.Symbol.name</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.list_arguments.html">mxnet.symbol.Symbol.list_arguments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.list_outputs.html">mxnet.symbol.Symbol.list_outputs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.list_auxiliary_states.html">mxnet.symbol.Symbol.list_auxiliary_states</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.list_attr.html">mxnet.symbol.Symbol.list_attr</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.attr.html">mxnet.symbol.Symbol.attr</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.attr_dict.html">mxnet.symbol.Symbol.attr_dict</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.slice.html">mxnet.symbol.Symbol.slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.slice_axis.html">mxnet.symbol.Symbol.slice_axis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.slice_like.html">mxnet.symbol.Symbol.slice_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.take.html">mxnet.symbol.Symbol.take</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.one_hot.html">mxnet.symbol.Symbol.one_hot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.pick.html">mxnet.symbol.Symbol.pick</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__getitem__.html">mxnet.symbol.Symbol.__getitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__iter__.html">mxnet.symbol.Symbol.__iter__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.get_internals.html">mxnet.symbol.Symbol.get_internals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.get_children.html">mxnet.symbol.Symbol.get_children</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.infer_type.html">mxnet.symbol.Symbol.infer_type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.infer_shape.html">mxnet.symbol.Symbol.infer_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.infer_shape_partial.html">mxnet.symbol.Symbol.infer_shape_partial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.bind.html">mxnet.symbol.Symbol.bind</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.simple_bind.html">mxnet.symbol.Symbol.simple_bind</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.save.html">mxnet.symbol.Symbol.save</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.tojson.html">mxnet.symbol.Symbol.tojson</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.debug_str.html">mxnet.symbol.Symbol.debug_str</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.clip.html">mxnet.symbol.Symbol.clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.sign.html">mxnet.symbol.Symbol.sign</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/symbol-related/index.html">Symbol related modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/symbol-related/mxnet.callback.html">mxnet.callback</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.callback.do_checkpoint.html">mxnet.callback.do_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.callback.log_train_metric.html">mxnet.callback.log_train_metric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.callback.module_checkpoint.html">mxnet.callback.module_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.callback.LogValidationMetricsCallback.html">mxnet.callback.LogValidationMetricsCallback</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.callback.ProgressBar.html">mxnet.callback.ProgressBar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.callback.Speedometer.html">mxnet.callback.Speedometer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/symbol-related/mxnet.module.html">mxnet.module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.module.BaseModule.html">mxnet.module.BaseModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.module.BucketingModule.html">mxnet.module.BucketingModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.module.Module.html">mxnet.module.Module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.module.PythonLossModule.html">mxnet.module.PythonLossModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.module.PythonModule.html">mxnet.module.PythonModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.module.SequentialModule.html">mxnet.module.SequentialModule</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/symbol-related/mxnet.monitor.html">mxnet.monitor</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.monitor.Monitor.html">mxnet.monitor.Monitor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/symbol-related/mxnet.visualization.html">mxnet.visualization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.visualization.plot_network.html">mxnet.visualization.plot_network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.visualization.print_summary.html">mxnet.visualization.print_summary</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/advanced/index.html">Advanced modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/advanced/mxnet.executor.html">mxnet.executor</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.executor.Executor.html">mxnet.executor.Executor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/advanced/mxnet.kvstore_server.html">mxnet.kvstore_server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.kvstore_server.KVStoreServer.html">mxnet.kvstore_server.KVStoreServer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/advanced/mxnet.engine.html">mxnet.engine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.engine.bulk.html">mxnet.engine.bulk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.engine.set_bulk_size.html">mxnet.engine.set_bulk_size</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/advanced/mxnet.executor_manager.html">mxnet.executor_manager</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.executor_manager.DataParallelExecutorGroup.html">mxnet.executor_manager.DataParallelExecutorGroup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.executor_manager.DataParallelExecutorManager.html">mxnet.executor_manager.DataParallelExecutorManager</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/advanced/mxnet.rtc.html">mxnet.rtc</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.rtc.CudaKernel.html">mxnet.rtc.CudaKernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.rtc.CudaModule.html">mxnet.rtc.CudaModule</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/advanced/mxnet.test_utils.html">mxnet.test_utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.almost_equal.html">mxnet.test_utils.almost_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.almost_equal_ignore_nan.html">mxnet.test_utils.almost_equal_ignore_nan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.assert_almost_equal.html">mxnet.test_utils.assert_almost_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.assert_almost_equal_ignore_nan.html">mxnet.test_utils.assert_almost_equal_ignore_nan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.assert_exception.html">mxnet.test_utils.assert_exception</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.assign_each.html">mxnet.test_utils.assign_each</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.assign_each2.html">mxnet.test_utils.assign_each2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.check_consistency.html">mxnet.test_utils.check_consistency</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.check_numeric_gradient.html">mxnet.test_utils.check_numeric_gradient</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.check_speed.html">mxnet.test_utils.check_speed</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.check_symbolic_backward.html">mxnet.test_utils.check_symbolic_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.check_symbolic_forward.html">mxnet.test_utils.check_symbolic_forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.chi_square_check.html">mxnet.test_utils.chi_square_check</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.create_sparse_array.html">mxnet.test_utils.create_sparse_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.create_sparse_array_zd.html">mxnet.test_utils.create_sparse_array_zd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.default_context.html">mxnet.test_utils.default_context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.default_dtype.html">mxnet.test_utils.default_dtype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.discard_stderr.html">mxnet.test_utils.discard_stderr</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.download.html">mxnet.test_utils.download</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.find_max_violation.html">mxnet.test_utils.find_max_violation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.gen_buckets_probs_with_ppf.html">mxnet.test_utils.gen_buckets_probs_with_ppf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_atol.html">mxnet.test_utils.get_atol</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_bz2_data.html">mxnet.test_utils.get_bz2_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_cifar10.html">mxnet.test_utils.get_cifar10</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_im2rec_path.html">mxnet.test_utils.get_im2rec_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_mnist.html">mxnet.test_utils.get_mnist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_mnist_iterator.html">mxnet.test_utils.get_mnist_iterator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_mnist_pkl.html">mxnet.test_utils.get_mnist_pkl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_mnist_ubyte.html">mxnet.test_utils.get_mnist_ubyte</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_rtol.html">mxnet.test_utils.get_rtol</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_zip_data.html">mxnet.test_utils.get_zip_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.list_gpus.html">mxnet.test_utils.list_gpus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.mean_check.html">mxnet.test_utils.mean_check</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.np_reduce.html">mxnet.test_utils.np_reduce</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.numeric_grad.html">mxnet.test_utils.numeric_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.rand_ndarray.html">mxnet.test_utils.rand_ndarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.rand_shape_2d.html">mxnet.test_utils.rand_shape_2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.rand_shape_3d.html">mxnet.test_utils.rand_shape_3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.rand_shape_nd.html">mxnet.test_utils.rand_shape_nd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.rand_sparse_ndarray.html">mxnet.test_utils.rand_sparse_ndarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.random_arrays.html">mxnet.test_utils.random_arrays</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.random_sample.html">mxnet.test_utils.random_sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.retry.html">mxnet.test_utils.retry</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.same.html">mxnet.test_utils.same</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.same_array.html">mxnet.test_utils.same_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.set_default_context.html">mxnet.test_utils.set_default_context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.set_env_var.html">mxnet.test_utils.set_env_var</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.shuffle_csr_column_indices.html">mxnet.test_utils.shuffle_csr_column_indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.simple_forward.html">mxnet.test_utils.simple_forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.var_check.html">mxnet.test_utils.var_check</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.verify_generator.html">mxnet.test_utils.verify_generator</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/advanced/mxnet.util.html">mxnet.util</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.util.makedirs.html">mxnet.util.makedirs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>
        <main class="mdl-layout__content" tabIndex="0">

	<script type="text/javascript" src="../../../_static/sphinx_materialdesign_theme.js "></script>
    <header class="mdl-layout__drawer">      
    
      <div class="globaltoc">
        <span class="mdl-layout-title toc">Table Of Contents</span>
        
        
            
            <nav class="mdl-navigation">
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/index.html">Python Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/getting-started/index.html">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/index.html">Crash Course</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/1-ndarray.html">Manipulate data with <code class="docutils literal notranslate"><span class="pre">ndarray</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/2-nn.html">Create a neural network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/3-autograd.html">Automatic differentiation with <code class="docutils literal notranslate"><span class="pre">autograd</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/4-train.html">Train the neural network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/5-predict.html">Predict with a pre-trained model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/crash-course/6-use_gpus.html">Use GPUs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/getting-started/to-mxnet/index.html">Moving to MXNet from Other Frameworks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/getting-started/to-mxnet/pytorch.html">PyTorch vs Apache MXNet</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/packages/index.html">Packages</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/gluon/index.html">Gluon</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/custom_layer_beginners.html">How to write a custom layer in Apache MxNet Gluon API</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/data.html">Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/image-augmentation.html">Image Augmentation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/nn.html">Layers and Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/normalization/normalization.html">Normalization Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/activations/activations.html">Activation Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/custom-loss/custom-loss.html">Custom Loss Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/init.html">Initialization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/init.html#Conclusion">Conclusion</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/init.html#Recommended-Next-Steps">Recommended Next Steps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/parameters.html">Parameter Management</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/trainer.html">Trainer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/naming.html">Naming of Gluon Parameter and Blocks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/custom-layer.html">Custom Layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/customop.html">Creating custom operators with numpy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/hybridize.html">Hybridize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/image/index.html">Image Tutorials</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/mnist.html">Handwritten Digit Recognition</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../tutorials/packages/gluon/image/pretrained_models.html">Using pre-trained models in MXNet</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/text/index.html">Text Tutorials</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/packages/gluon/text/index.html#language-model">Language Model</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/ndarray/index.html">NDArray</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/symbol/index.html">Symbol</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/autograd/autograd.html">Automatic Differentiation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/packages/onnx/index.html">ONNX</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/performance/index.html">Performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/performance/compression/index.html">Compression</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/performance/compression/int8.html">Deploy with int-8</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/performance/backend/index.html">Accelerated Backend Tools</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/deploy/index.html">Deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/export/index.html">Export</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/inference/index.html">Inference</a><ul class="simple">
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/index.html">Run on AWS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/use_ec2.html">Run on an EC2 Instance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../tutorials/deploy/run-on-aws/use_sagemaker.html">Run on Amazon SageMaker</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../tutorials/extend/index.html">Customization</a><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api/index.html">Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api/ndarray/index.html">mxnet.ndarray</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/ndarray/mxnet.ndarray.NDArray.html">NDArray</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.context.html">mxnet.ndarray.NDArray.context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.dtype.html">mxnet.ndarray.NDArray.dtype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.grad.html">mxnet.ndarray.NDArray.grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.handle.html">mxnet.ndarray.NDArray.handle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.ndim.html">mxnet.ndarray.NDArray.ndim</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.shape.html">mxnet.ndarray.NDArray.shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.size.html">mxnet.ndarray.NDArray.size</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.stype.html">mxnet.ndarray.NDArray.stype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.writable.html">mxnet.ndarray.NDArray.writable</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.ones_like.html">mxnet.ndarray.NDArray.ones_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.zeros_like.html">mxnet.ndarray.NDArray.zeros_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.as_in_context.html">mxnet.ndarray.NDArray.as_in_context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.asnumpy.html">mxnet.ndarray.NDArray.asnumpy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.asscalar.html">mxnet.ndarray.NDArray.asscalar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.astype.html">mxnet.ndarray.NDArray.astype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.copy.html">mxnet.ndarray.NDArray.copy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.copyto.html">mxnet.ndarray.NDArray.copyto</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.tostype.html">mxnet.ndarray.NDArray.tostype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.diag.html">mxnet.ndarray.NDArray.diag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.expand_dims.html">mxnet.ndarray.NDArray.expand_dims</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.flatten.html">mxnet.ndarray.NDArray.flatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.reshape.html">mxnet.ndarray.NDArray.reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.reshape_like.html">mxnet.ndarray.NDArray.reshape_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.shape_array.html">mxnet.ndarray.NDArray.shape_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.size_array.html">mxnet.ndarray.NDArray.size_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.split.html">mxnet.ndarray.NDArray.split</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.broadcast_to.html">mxnet.ndarray.NDArray.broadcast_to</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.broadcast_axes.html">mxnet.ndarray.NDArray.broadcast_axes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.broadcast_like.html">mxnet.ndarray.NDArray.broadcast_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.pad.html">mxnet.ndarray.NDArray.pad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.repeat.html">mxnet.ndarray.NDArray.repeat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.tile.html">mxnet.ndarray.NDArray.tile</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.depth_to_space.html">mxnet.ndarray.NDArray.depth_to_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.flip.html">mxnet.ndarray.NDArray.flip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.swapaxes.html">mxnet.ndarray.NDArray.swapaxes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.space_to_depth.html">mxnet.ndarray.NDArray.space_to_depth</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.T.html">mxnet.ndarray.NDArray.T</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.transpose.html">mxnet.ndarray.NDArray.transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.argmax.html">mxnet.ndarray.NDArray.argmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.argmax_channel.html">mxnet.ndarray.NDArray.argmax_channel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.argmin.html">mxnet.ndarray.NDArray.argmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.argsort.html">mxnet.ndarray.NDArray.argsort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.sort.html">mxnet.ndarray.NDArray.sort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.topk.html">mxnet.ndarray.NDArray.topk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__getitem__.html">mxnet.ndarray.NDArray.__getitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__setitem__.html">mxnet.ndarray.NDArray.__setitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.one_hot.html">mxnet.ndarray.NDArray.one_hot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.pick.html">mxnet.ndarray.NDArray.pick</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.slice.html">mxnet.ndarray.NDArray.slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.slice_axis.html">mxnet.ndarray.NDArray.slice_axis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.slice_like.html">mxnet.ndarray.NDArray.slice_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.take.html">mxnet.ndarray.NDArray.take</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.wait_to_read.html">mxnet.ndarray.NDArray.wait_to_read</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__add__.html">mxnet.ndarray.NDArray.__add__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__div__.html">mxnet.ndarray.NDArray.__div__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__neg__.html">mxnet.ndarray.NDArray.__neg__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__mod__.html">mxnet.ndarray.NDArray.__mod__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__mul__.html">mxnet.ndarray.NDArray.__mul__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__pow__.html">mxnet.ndarray.NDArray.__pow__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__rdiv__.html">mxnet.ndarray.NDArray.__rdiv__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__rmod__.html">mxnet.ndarray.NDArray.__rmod__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__rsub__.html">mxnet.ndarray.NDArray.__rsub__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__sub__.html">mxnet.ndarray.NDArray.__sub__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.ceil.html">mxnet.ndarray.NDArray.ceil</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.fix.html">mxnet.ndarray.NDArray.fix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.floor.html">mxnet.ndarray.NDArray.floor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.rint.html">mxnet.ndarray.NDArray.rint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.round.html">mxnet.ndarray.NDArray.round</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.trunc.html">mxnet.ndarray.NDArray.trunc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.max.html">mxnet.ndarray.NDArray.max</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.mean.html">mxnet.ndarray.NDArray.mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.min.html">mxnet.ndarray.NDArray.min</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.nanprod.html">mxnet.ndarray.NDArray.nanprod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.nansum.html">mxnet.ndarray.NDArray.nansum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.norm.html">mxnet.ndarray.NDArray.norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.prod.html">mxnet.ndarray.NDArray.prod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.sum.html">mxnet.ndarray.NDArray.sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__iadd__.html">mxnet.ndarray.NDArray.__iadd__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__idiv__.html">mxnet.ndarray.NDArray.__idiv__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__imod__.html">mxnet.ndarray.NDArray.__imod__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__imul__.html">mxnet.ndarray.NDArray.__imul__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__isub__.html">mxnet.ndarray.NDArray.__isub__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__eq__.html">mxnet.ndarray.NDArray.__eq__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__ge__.html">mxnet.ndarray.NDArray.__ge__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__gt__.html">mxnet.ndarray.NDArray.__gt__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__le__.html">mxnet.ndarray.NDArray.__le__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__lt__.html">mxnet.ndarray.NDArray.__lt__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.__ne__.html">mxnet.ndarray.NDArray.__ne__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.arccos.html">mxnet.ndarray.NDArray.arccos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.arcsin.html">mxnet.ndarray.NDArray.arcsin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.arctan.html">mxnet.ndarray.NDArray.arctan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.cos.html">mxnet.ndarray.NDArray.cos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.degrees.html">mxnet.ndarray.NDArray.degrees</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.radians.html">mxnet.ndarray.NDArray.radians</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.sin.html">mxnet.ndarray.NDArray.sin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.tan.html">mxnet.ndarray.NDArray.tan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.arccosh.html">mxnet.ndarray.NDArray.arccosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.arcsinh.html">mxnet.ndarray.NDArray.arcsinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.arctanh.html">mxnet.ndarray.NDArray.arctanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.cosh.html">mxnet.ndarray.NDArray.cosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.sinh.html">mxnet.ndarray.NDArray.sinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.tanh.html">mxnet.ndarray.NDArray.tanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.exp.html">mxnet.ndarray.NDArray.exp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.expm1.html">mxnet.ndarray.NDArray.expm1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.log.html">mxnet.ndarray.NDArray.log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.log1p.html">mxnet.ndarray.NDArray.log1p</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.log10.html">mxnet.ndarray.NDArray.log10</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.log2.html">mxnet.ndarray.NDArray.log2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.cbrt.html">mxnet.ndarray.NDArray.cbrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.rcbrt.html">mxnet.ndarray.NDArray.rcbrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.reciprocal.html">mxnet.ndarray.NDArray.reciprocal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.rsqrt.html">mxnet.ndarray.NDArray.rsqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.square.html">mxnet.ndarray.NDArray.square</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.sqrt.html">mxnet.ndarray.NDArray.sqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.clip.html">mxnet.ndarray.NDArray.clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.sign.html">mxnet.ndarray.NDArray.sign</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.log_softmax.html">mxnet.ndarray.NDArray.log_softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.relu.html">mxnet.ndarray.NDArray.relu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.sigmoid.html">mxnet.ndarray.NDArray.sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.NDArray.softmax.html">mxnet.ndarray.NDArray.softmax</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/ndarray/routines.html">Routines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.arange.html">mxnet.ndarray.arange</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.array.html">mxnet.ndarray.array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.diag.html">mxnet.ndarray.diag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.empty.html">mxnet.ndarray.empty</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.full.html">mxnet.ndarray.full</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.load.html">mxnet.ndarray.load</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.ones.html">mxnet.ndarray.ones</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.ones_like.html">mxnet.ndarray.ones_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.save.html">mxnet.ndarray.save</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.zeros.html">mxnet.ndarray.zeros</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.zeros_like.html">mxnet.ndarray.zeros_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.cast.html">mxnet.ndarray.cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.flatten.html">mxnet.ndarray.flatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.expand_dims.html">mxnet.ndarray.expand_dims</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.reshape.html">mxnet.ndarray.reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.reshape_like.html">mxnet.ndarray.reshape_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.shape_array.html">mxnet.ndarray.shape_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.size_array.html">mxnet.ndarray.size_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.broadcast_axes.html">mxnet.ndarray.broadcast_axes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.broadcast_like.html">mxnet.ndarray.broadcast_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.broadcast_to.html">mxnet.ndarray.broadcast_to</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.pad.html">mxnet.ndarray.pad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.repeat.html">mxnet.ndarray.repeat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.tile.html">mxnet.ndarray.tile</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.depth_to_space.html">mxnet.ndarray.depth_to_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.flip.html">mxnet.ndarray.flip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.space_to_depth.html">mxnet.ndarray.space_to_depth</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.swapaxes.html">mxnet.ndarray.swapaxes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.transpose.html">mxnet.ndarray.transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.concat.html">mxnet.ndarray.concat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.split.html">mxnet.ndarray.split</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.stack.html">mxnet.ndarray.stack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.batch_take.html">mxnet.ndarray.batch_take</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.one_hot.html">mxnet.ndarray.one_hot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.pick.html">mxnet.ndarray.pick</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.ravel_multi_index.html">mxnet.ndarray.ravel_multi_index</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.slice.html">mxnet.ndarray.slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.slice_axis.html">mxnet.ndarray.slice_axis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.slice_like.html">mxnet.ndarray.slice_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.take.html">mxnet.ndarray.take</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.unravel_index.html">mxnet.ndarray.unravel_index</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.where.html">mxnet.ndarray.where</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.SequenceLast.html">mxnet.ndarray.SequenceLast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.SequenceMask.html">mxnet.ndarray.SequenceMask</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.SequenceReverse.html">mxnet.ndarray.SequenceReverse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.add.html">mxnet.ndarray.add</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.add_n.html">mxnet.ndarray.add_n</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.batch_dot.html">mxnet.ndarray.batch_dot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.divide.html">mxnet.ndarray.divide</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.dot.html">mxnet.ndarray.dot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.modulo.html">mxnet.ndarray.modulo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.multiply.html">mxnet.ndarray.multiply</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.negative.html">mxnet.ndarray.negative</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.subtract.html">mxnet.ndarray.subtract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.arccos.html">mxnet.ndarray.arccos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.arcsin.html">mxnet.ndarray.arcsin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.arctan.html">mxnet.ndarray.arctan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.broadcast_hypot.html">mxnet.ndarray.broadcast_hypot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.degrees.html">mxnet.ndarray.degrees</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.cos.html">mxnet.ndarray.cos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.radians.html">mxnet.ndarray.radians</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sin.html">mxnet.ndarray.sin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.tan.html">mxnet.ndarray.tan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.arcsinh.html">mxnet.ndarray.arcsinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.arccosh.html">mxnet.ndarray.arccosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.arctanh.html">mxnet.ndarray.arctanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.cosh.html">mxnet.ndarray.cosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sinh.html">mxnet.ndarray.sinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.tanh.html">mxnet.ndarray.tanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.max.html">mxnet.ndarray.max</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.min.html">mxnet.ndarray.min</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.mean.html">mxnet.ndarray.mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.nanprod.html">mxnet.ndarray.nanprod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.nansum.html">mxnet.ndarray.nansum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.norm.html">mxnet.ndarray.norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.prod.html">mxnet.ndarray.prod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sum.html">mxnet.ndarray.sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.ceil.html">mxnet.ndarray.ceil</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.fix.html">mxnet.ndarray.fix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.floor.html">mxnet.ndarray.floor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.round.html">mxnet.ndarray.round</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.rint.html">mxnet.ndarray.rint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.trunc.html">mxnet.ndarray.trunc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.exp.html">mxnet.ndarray.exp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.expm1.html">mxnet.ndarray.expm1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.log.html">mxnet.ndarray.log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.log1p.html">mxnet.ndarray.log1p</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.log10.html">mxnet.ndarray.log10</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.log2.html">mxnet.ndarray.log2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.cbrt.html">mxnet.ndarray.cbrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.power.html">mxnet.ndarray.power</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.rcbrt.html">mxnet.ndarray.rcbrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.reciprocal.html">mxnet.ndarray.reciprocal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.rsqrt.html">mxnet.ndarray.rsqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.square.html">mxnet.ndarray.square</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sqrt.html">mxnet.ndarray.sqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.equal.html">mxnet.ndarray.equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.greater.html">mxnet.ndarray.greater</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.greater_equal.html">mxnet.ndarray.greater_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.lesser.html">mxnet.ndarray.lesser</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.lesser_equal.html">mxnet.ndarray.lesser_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.not_equal.html">mxnet.ndarray.not_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.logical_and.html">mxnet.ndarray.logical_and</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.logical_not.html">mxnet.ndarray.logical_not</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.logical_or.html">mxnet.ndarray.logical_or</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.logical_xor.html">mxnet.ndarray.logical_xor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.argmax.html">mxnet.ndarray.argmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.argmin.html">mxnet.ndarray.argmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.argsort.html">mxnet.ndarray.argsort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sort.html">mxnet.ndarray.sort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.topk.html">mxnet.ndarray.topk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.exponential.html">mxnet.ndarray.random.exponential</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.gamma.html">mxnet.ndarray.random.gamma</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.generalized_negative_binomial.html">mxnet.ndarray.random.generalized_negative_binomial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.multinomial.html">mxnet.ndarray.random.multinomial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.negative_binomial.html">mxnet.ndarray.random.negative_binomial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.normal.html">mxnet.ndarray.random.normal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.poisson.html">mxnet.ndarray.random.poisson</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.randint.html">mxnet.ndarray.random.randint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.randn.html">mxnet.ndarray.random.randn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.shuffle.html">mxnet.ndarray.random.shuffle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.random.uniform.html">mxnet.ndarray.random.uniform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.gelqf.html">mxnet.ndarray.linalg.gelqf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.gemm.html">mxnet.ndarray.linalg.gemm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.gemm2.html">mxnet.ndarray.linalg.gemm2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.potrf.html">mxnet.ndarray.linalg.potrf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.potri.html">mxnet.ndarray.linalg.potri</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.sumlogdiag.html">mxnet.ndarray.linalg.sumlogdiag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.syevd.html">mxnet.ndarray.linalg.syevd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.syrk.html">mxnet.ndarray.linalg.syrk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.trmm.html">mxnet.ndarray.linalg.trmm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.linalg.trsm.html">mxnet.ndarray.linalg.trsm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.abs.html">mxnet.ndarray.abs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.clip.html">mxnet.ndarray.clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.gamma.html">mxnet.ndarray.gamma</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.gammaln.html">mxnet.ndarray.gammaln</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.maximum.html">mxnet.ndarray.maximum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.minimum.html">mxnet.ndarray.minimum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sign.html">mxnet.ndarray.sign</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Activation.html">mxnet.ndarray.Activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.BatchNorm.html">mxnet.ndarray.BatchNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.BilinearSampler.html">mxnet.ndarray.BilinearSampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.BlockGrad.html">mxnet.ndarray.BlockGrad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Convolution.html">mxnet.ndarray.Convolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Correlation.html">mxnet.ndarray.Correlation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Custom.html">mxnet.ndarray.Custom</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Deconvolution.html">mxnet.ndarray.Deconvolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Dropout.html">mxnet.ndarray.Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Embedding.html">mxnet.ndarray.Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.FullyConnected.html">mxnet.ndarray.FullyConnected</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.GridGenerator.html">mxnet.ndarray.GridGenerator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.IdentityAttachKLSparseReg.html">mxnet.ndarray.IdentityAttachKLSparseReg</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.InstanceNorm.html">mxnet.ndarray.InstanceNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.L2Normalization.html">mxnet.ndarray.L2Normalization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.LayerNorm.html">mxnet.ndarray.LayerNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.LeakyReLU.html">mxnet.ndarray.LeakyReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.LinearRegressionOutput.html">mxnet.ndarray.LinearRegressionOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.log_softmax.html">mxnet.ndarray.log_softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.LogisticRegressionOutput.html">mxnet.ndarray.LogisticRegressionOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.LRN.html">mxnet.ndarray.LRN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.MAERegressionOutput.html">mxnet.ndarray.MAERegressionOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.MakeLoss.html">mxnet.ndarray.MakeLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.Pooling.html">mxnet.ndarray.Pooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.relu.html">mxnet.ndarray.relu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.ROIPooling.html">mxnet.ndarray.ROIPooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.RNN.html">mxnet.ndarray.RNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sigmoid.html">mxnet.ndarray.sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.smooth_l1.html">mxnet.ndarray.smooth_l1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.softmax.html">mxnet.ndarray.softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.softmax_cross_entropy.html">mxnet.ndarray.softmax_cross_entropy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.SoftmaxOutput.html">mxnet.ndarray.SoftmaxOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.SoftmaxActivation.html">mxnet.ndarray.SoftmaxActivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.SpatialTransformer.html">mxnet.ndarray.SpatialTransformer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.SVMOutput.html">mxnet.ndarray.SVMOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.UpSampling.html">mxnet.ndarray.UpSampling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.count_sketch.html">mxnet.ndarray.contrib.count_sketch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.getnnz.html">mxnet.ndarray.contrib.getnnz</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.index_copy.html">mxnet.ndarray.contrib.index_copy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.fft.html">mxnet.ndarray.contrib.fft</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.ifft.html">mxnet.ndarray.contrib.ifft</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.dequantize.html">mxnet.ndarray.contrib.dequantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.quantize.html">mxnet.ndarray.contrib.quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.AdaptiveAvgPooling2D.html">mxnet.ndarray.contrib.AdaptiveAvgPooling2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.BilinearResize2D.html">mxnet.ndarray.contrib.BilinearResize2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.ctc_loss.html">mxnet.ndarray.contrib.ctc_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.DeformableConvolution.html">mxnet.ndarray.contrib.DeformableConvolution</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.DeformablePSROIPooling.html">mxnet.ndarray.contrib.DeformablePSROIPooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.MultiBoxDetection.html">mxnet.ndarray.contrib.MultiBoxDetection</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.MultiBoxPrior.html">mxnet.ndarray.contrib.MultiBoxPrior</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.MultiBoxTarget.html">mxnet.ndarray.contrib.MultiBoxTarget</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.MultiProposal.html">mxnet.ndarray.contrib.MultiProposal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.Proposal.html">mxnet.ndarray.contrib.Proposal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.PSROIPooling.html">mxnet.ndarray.contrib.PSROIPooling</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.ROIAlign.html">mxnet.ndarray.contrib.ROIAlign</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.cond.html">mxnet.ndarray.contrib.cond</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.foreach.html">mxnet.ndarray.contrib.foreach</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.contrib.while_loop.html">mxnet.ndarray.contrib.while_loop</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/ndarray/mxnet.ndarray.sparse.CSRNDArray.html">CSRNDArray</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.context.html">mxnet.ndarray.sparse.CSRNDArray.context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.data.html">mxnet.ndarray.sparse.CSRNDArray.data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.dtype.html">mxnet.ndarray.sparse.CSRNDArray.dtype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.indices.html">mxnet.ndarray.sparse.CSRNDArray.indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.indptr.html">mxnet.ndarray.sparse.CSRNDArray.indptr</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.shape.html">mxnet.ndarray.sparse.CSRNDArray.shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.stype.html">mxnet.ndarray.sparse.CSRNDArray.stype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.zeros_like.html">mxnet.ndarray.sparse.CSRNDArray.zeros_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.as_in_context.html">mxnet.ndarray.sparse.CSRNDArray.as_in_context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.asnumpy.html">mxnet.ndarray.sparse.CSRNDArray.asnumpy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.asscalar.html">mxnet.ndarray.sparse.CSRNDArray.asscalar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.asscipy.html">mxnet.ndarray.sparse.CSRNDArray.asscipy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.astype.html">mxnet.ndarray.sparse.CSRNDArray.astype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.copy.html">mxnet.ndarray.sparse.CSRNDArray.copy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.copyto.html">mxnet.ndarray.sparse.CSRNDArray.copyto</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.tostype.html">mxnet.ndarray.sparse.CSRNDArray.tostype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.check_format.html">mxnet.ndarray.sparse.CSRNDArray.check_format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.mean.html">mxnet.ndarray.sparse.CSRNDArray.mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.norm.html">mxnet.ndarray.sparse.CSRNDArray.norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.sum.html">mxnet.ndarray.sparse.CSRNDArray.sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.__getitem__.html">mxnet.ndarray.sparse.CSRNDArray.__getitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.__setitem__.html">mxnet.ndarray.sparse.CSRNDArray.__setitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.slice.html">mxnet.ndarray.sparse.CSRNDArray.slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.concat.html">mxnet.ndarray.sparse.concat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.wait_to_read.html">mxnet.ndarray.sparse.CSRNDArray.wait_to_read</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.ceil.html">mxnet.ndarray.sparse.CSRNDArray.ceil</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.fix.html">mxnet.ndarray.sparse.CSRNDArray.fix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.floor.html">mxnet.ndarray.sparse.CSRNDArray.floor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.round.html">mxnet.ndarray.sparse.CSRNDArray.round</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.rint.html">mxnet.ndarray.sparse.CSRNDArray.rint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.trunc.html">mxnet.ndarray.sparse.CSRNDArray.trunc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.arcsin.html">mxnet.ndarray.sparse.CSRNDArray.arcsin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.arctan.html">mxnet.ndarray.sparse.CSRNDArray.arctan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.degrees.html">mxnet.ndarray.sparse.CSRNDArray.degrees</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.radians.html">mxnet.ndarray.sparse.CSRNDArray.radians</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.sin.html">mxnet.ndarray.sparse.CSRNDArray.sin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.tan.html">mxnet.ndarray.sparse.CSRNDArray.tan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.arcsinh.html">mxnet.ndarray.sparse.CSRNDArray.arcsinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.arctanh.html">mxnet.ndarray.sparse.CSRNDArray.arctanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.sinh.html">mxnet.ndarray.sparse.CSRNDArray.sinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.tanh.html">mxnet.ndarray.sparse.CSRNDArray.tanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.expm1.html">mxnet.ndarray.sparse.CSRNDArray.expm1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.log1p.html">mxnet.ndarray.sparse.CSRNDArray.log1p</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.sqrt.html">mxnet.ndarray.sparse.CSRNDArray.sqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.square.html">mxnet.ndarray.sparse.CSRNDArray.square</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.abs.html">mxnet.ndarray.sparse.CSRNDArray.abs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.clip.html">mxnet.ndarray.sparse.CSRNDArray.clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.CSRNDArray.sign.html">mxnet.ndarray.sparse.CSRNDArray.sign</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/ndarray/mxnet.ndarray.sparse.RowSparseNDArray.html">RowSparseNDArray</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.context.html">mxnet.ndarray.sparse.RowSparseNDArray.context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.data.html">mxnet.ndarray.sparse.RowSparseNDArray.data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.dtype.html">mxnet.ndarray.sparse.RowSparseNDArray.dtype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.indices.html">mxnet.ndarray.sparse.RowSparseNDArray.indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.shape.html">mxnet.ndarray.sparse.RowSparseNDArray.shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.stype.html">mxnet.ndarray.sparse.RowSparseNDArray.stype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.as_in_context.html">mxnet.ndarray.sparse.RowSparseNDArray.as_in_context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.asnumpy.html">mxnet.ndarray.sparse.RowSparseNDArray.asnumpy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.asscalar.html">mxnet.ndarray.sparse.RowSparseNDArray.asscalar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.astype.html">mxnet.ndarray.sparse.RowSparseNDArray.astype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.copy.html">mxnet.ndarray.sparse.RowSparseNDArray.copy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.copyto.html">mxnet.ndarray.sparse.RowSparseNDArray.copyto</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.tostype.html">mxnet.ndarray.sparse.RowSparseNDArray.tostype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.check_format.html">mxnet.ndarray.sparse.RowSparseNDArray.check_format</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.zeros_like.html">mxnet.ndarray.sparse.RowSparseNDArray.zeros_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.norm.html">mxnet.ndarray.sparse.RowSparseNDArray.norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.ceil.html">mxnet.ndarray.sparse.RowSparseNDArray.ceil</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.fix.html">mxnet.ndarray.sparse.RowSparseNDArray.fix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.floor.html">mxnet.ndarray.sparse.RowSparseNDArray.floor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.rint.html">mxnet.ndarray.sparse.RowSparseNDArray.rint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.round.html">mxnet.ndarray.sparse.RowSparseNDArray.round</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.trunc.html">mxnet.ndarray.sparse.RowSparseNDArray.trunc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.arcsin.html">mxnet.ndarray.sparse.RowSparseNDArray.arcsin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.arctan.html">mxnet.ndarray.sparse.RowSparseNDArray.arctan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.degrees.html">mxnet.ndarray.sparse.RowSparseNDArray.degrees</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.radians.html">mxnet.ndarray.sparse.RowSparseNDArray.radians</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.sin.html">mxnet.ndarray.sparse.RowSparseNDArray.sin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.tan.html">mxnet.ndarray.sparse.RowSparseNDArray.tan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.arcsinh.html">mxnet.ndarray.sparse.RowSparseNDArray.arcsinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.arctanh.html">mxnet.ndarray.sparse.RowSparseNDArray.arctanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.sinh.html">mxnet.ndarray.sparse.RowSparseNDArray.sinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.tanh.html">mxnet.ndarray.sparse.RowSparseNDArray.tanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.expm1.html">mxnet.ndarray.sparse.RowSparseNDArray.expm1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.log1p.html">mxnet.ndarray.sparse.RowSparseNDArray.log1p</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.sqrt.html">mxnet.ndarray.sparse.RowSparseNDArray.sqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.square.html">mxnet.ndarray.sparse.RowSparseNDArray.square</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.__getitem__.html">mxnet.ndarray.sparse.RowSparseNDArray.__getitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.__setitem__.html">mxnet.ndarray.sparse.RowSparseNDArray.__setitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.retain.html">mxnet.ndarray.sparse.RowSparseNDArray.retain</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.wait_to_read.html">mxnet.ndarray.sparse.RowSparseNDArray.wait_to_read</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.abs.html">mxnet.ndarray.sparse.RowSparseNDArray.abs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.clip.html">mxnet.ndarray.sparse.RowSparseNDArray.clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.RowSparseNDArray.sign.html">mxnet.ndarray.sparse.RowSparseNDArray.sign</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/ndarray/sparse_routines.html">Sparse routines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.array.html">mxnet.ndarray.sparse.array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.csr_matrix.html">mxnet.ndarray.sparse.csr_matrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.empty.html">mxnet.ndarray.sparse.empty</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.row_sparse_array.html">mxnet.ndarray.sparse.row_sparse_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.zeros.html">mxnet.ndarray.sparse.zeros</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.zeros_like.html">mxnet.ndarray.sparse.zeros_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.cast_storage.html">mxnet.ndarray.sparse.cast_storage</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.retain.html">mxnet.ndarray.sparse.retain</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.slice.html">mxnet.ndarray.sparse.slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.where.html">mxnet.ndarray.sparse.where</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.add_n.html">mxnet.ndarray.sparse.add_n</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.broadcast_add.html">mxnet.ndarray.sparse.broadcast_add</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.broadcast_div.html">mxnet.ndarray.sparse.broadcast_div</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.broadcast_mul.html">mxnet.ndarray.sparse.broadcast_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.broadcast_sub.html">mxnet.ndarray.sparse.broadcast_sub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.dot.html">mxnet.ndarray.sparse.dot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.elemwise_add.html">mxnet.ndarray.sparse.elemwise_add</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.elemwise_mul.html">mxnet.ndarray.sparse.elemwise_mul</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.elemwise_sub.html">mxnet.ndarray.sparse.elemwise_sub</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.negative.html">mxnet.ndarray.sparse.negative</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.arcsin.html">mxnet.ndarray.sparse.arcsin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.arctan.html">mxnet.ndarray.sparse.arctan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.degrees.html">mxnet.ndarray.sparse.degrees</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.radians.html">mxnet.ndarray.sparse.radians</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.sin.html">mxnet.ndarray.sparse.sin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.tan.html">mxnet.ndarray.sparse.tan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.arcsinh.html">mxnet.ndarray.sparse.arcsinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.arctanh.html">mxnet.ndarray.sparse.arctanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.sinh.html">mxnet.ndarray.sparse.sinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.tanh.html">mxnet.ndarray.sparse.tanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.mean.html">mxnet.ndarray.sparse.mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.norm.html">mxnet.ndarray.sparse.norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.sum.html">mxnet.ndarray.sparse.sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.ceil.html">mxnet.ndarray.sparse.ceil</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.fix.html">mxnet.ndarray.sparse.fix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.floor.html">mxnet.ndarray.sparse.floor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.rint.html">mxnet.ndarray.sparse.rint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.round.html">mxnet.ndarray.sparse.round</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.trunc.html">mxnet.ndarray.sparse.trunc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.expm1.html">mxnet.ndarray.sparse.expm1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.log1p.html">mxnet.ndarray.sparse.log1p</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.sqrt.html">mxnet.ndarray.sparse.sqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.square.html">mxnet.ndarray.sparse.square</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.abs.html">mxnet.ndarray.sparse.abs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.sign.html">mxnet.ndarray.sparse.sign</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.adam_update.html">mxnet.ndarray.sparse.adam_update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.adagrad_update.html">mxnet.ndarray.sparse.adagrad_update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.sgd_mom_update.html">mxnet.ndarray.sparse.sgd_mom_update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.sgd_update.html">mxnet.ndarray.sparse.sgd_update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.Embedding.html">mxnet.ndarray.sparse.Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.LinearRegressionOutput.html">mxnet.ndarray.sparse.LinearRegressionOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.LogisticRegressionOutput.html">mxnet.ndarray.sparse.LogisticRegressionOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.make_loss.html">mxnet.ndarray.sparse.make_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/ndarray/_autogen/mxnet.ndarray.sparse.stop_gradient.html">mxnet.ndarray.sparse.stop_gradient</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gluon/index.html">mxnet.gluon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/nn.html">nn and contrib.nn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.nn.Block.html">Block</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.initialize.html">mxnet.gluon.nn.Block.initialize</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.save_parameters.html">mxnet.gluon.nn.Block.save_parameters</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.load_parameters.html">mxnet.gluon.nn.Block.load_parameters</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.collect_params.html">mxnet.gluon.nn.Block.collect_params</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.cast.html">mxnet.gluon.nn.Block.cast</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.apply.html">mxnet.gluon.nn.Block.apply</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.forward.html">mxnet.gluon.nn.Block.forward</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.summary.html">mxnet.gluon.nn.Block.summary</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.name_scope.html">mxnet.gluon.nn.Block.name_scope</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.register_child.html">mxnet.gluon.nn.Block.register_child</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.register_forward_hook.html">mxnet.gluon.nn.Block.register_forward_hook</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.register_forward_pre_hook.html">mxnet.gluon.nn.Block.register_forward_pre_hook</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.save_params.html">mxnet.gluon.nn.Block.save_params</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Block.load_params.html">mxnet.gluon.nn.Block.load_params</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.nn.HybridBlock.html">HybridBlock</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.nn.SymbolBlock.html">SymbolBlock</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Sequential.html">mxnet.gluon.nn.Sequential</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.HybridSequential.html">mxnet.gluon.nn.HybridSequential</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.nn.Concurrent.html">mxnet.gluon.contrib.nn.Concurrent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.nn.HybridConcurrent.html">mxnet.gluon.contrib.nn.HybridConcurrent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Dense.html">mxnet.gluon.nn.Dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Activation.html">mxnet.gluon.nn.Activation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Dropout.html">mxnet.gluon.nn.Dropout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Flatten.html">mxnet.gluon.nn.Flatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Lambda.html">mxnet.gluon.nn.Lambda</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.HybridLambda.html">mxnet.gluon.nn.HybridLambda</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Conv1D.html">mxnet.gluon.nn.Conv1D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Conv2D.html">mxnet.gluon.nn.Conv2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Conv3D.html">mxnet.gluon.nn.Conv3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Conv1DTranspose.html">mxnet.gluon.nn.Conv1DTranspose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Conv2DTranspose.html">mxnet.gluon.nn.Conv2DTranspose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Conv3DTranspose.html">mxnet.gluon.nn.Conv3DTranspose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.MaxPool1D.html">mxnet.gluon.nn.MaxPool1D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.MaxPool2D.html">mxnet.gluon.nn.MaxPool2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.MaxPool3D.html">mxnet.gluon.nn.MaxPool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.AvgPool1D.html">mxnet.gluon.nn.AvgPool1D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.AvgPool2D.html">mxnet.gluon.nn.AvgPool2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.AvgPool3D.html">mxnet.gluon.nn.AvgPool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.GlobalMaxPool1D.html">mxnet.gluon.nn.GlobalMaxPool1D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.GlobalMaxPool2D.html">mxnet.gluon.nn.GlobalMaxPool2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.GlobalMaxPool3D.html">mxnet.gluon.nn.GlobalMaxPool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.GlobalAvgPool1D.html">mxnet.gluon.nn.GlobalAvgPool1D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.GlobalAvgPool2D.html">mxnet.gluon.nn.GlobalAvgPool2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.GlobalAvgPool3D.html">mxnet.gluon.nn.GlobalAvgPool3D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.ReflectionPad2D.html">mxnet.gluon.nn.ReflectionPad2D</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.BatchNorm.html">mxnet.gluon.nn.BatchNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.InstanceNorm.html">mxnet.gluon.nn.InstanceNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.LayerNorm.html">mxnet.gluon.nn.LayerNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.nn.SyncBatchNorm.html">mxnet.gluon.contrib.nn.SyncBatchNorm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Embedding.html">mxnet.gluon.nn.Embedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.nn.SparseEmbedding.html">mxnet.gluon.contrib.nn.SparseEmbedding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.LeakyReLU.html">mxnet.gluon.nn.LeakyReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.PReLU.html">mxnet.gluon.nn.PReLU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.ELU.html">mxnet.gluon.nn.ELU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.SELU.html">mxnet.gluon.nn.SELU</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.nn.Swish.html">mxnet.gluon.nn.Swish</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/rnn.html">rnn and contrib.rnn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.LSTMCell.html">mxnet.gluon.rnn.LSTMCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.GRUCell.html">mxnet.gluon.rnn.GRUCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.RecurrentCell.html">mxnet.gluon.rnn.RecurrentCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.SequentialRNNCell.html">mxnet.gluon.rnn.SequentialRNNCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.BidirectionalCell.html">mxnet.gluon.rnn.BidirectionalCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.DropoutCell.html">mxnet.gluon.rnn.DropoutCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.ZoneoutCell.html">mxnet.gluon.rnn.ZoneoutCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.ResidualCell.html">mxnet.gluon.rnn.ResidualCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv1DRNNCell.html">mxnet.gluon.contrib.rnn.Conv1DRNNCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv2DRNNCell.html">mxnet.gluon.contrib.rnn.Conv2DRNNCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv3DRNNCell.html">mxnet.gluon.contrib.rnn.Conv3DRNNCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv1DLSTMCell.html">mxnet.gluon.contrib.rnn.Conv1DLSTMCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv2DLSTMCell.html">mxnet.gluon.contrib.rnn.Conv2DLSTMCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv3DLSTMCell.html">mxnet.gluon.contrib.rnn.Conv3DLSTMCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv1DGRUCell.html">mxnet.gluon.contrib.rnn.Conv1DGRUCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv2DGRUCell.html">mxnet.gluon.contrib.rnn.Conv2DGRUCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.Conv3DGRUCell.html">mxnet.gluon.contrib.rnn.Conv3DGRUCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.VariationalDropoutCell.html">mxnet.gluon.contrib.rnn.VariationalDropoutCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.contrib.rnn.LSTMPCell.html">mxnet.gluon.contrib.rnn.LSTMPCell</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.RNN.html">mxnet.gluon.rnn.RNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.LSTM.html">mxnet.gluon.rnn.LSTM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.rnn.GRU.html">mxnet.gluon.rnn.GRU</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.loss.html"><code class="docutils literal notranslate"><span class="pre">loss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.Loss.html">mxnet.gluon.loss.Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.L2Loss.html">mxnet.gluon.loss.L2Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.L1Loss.html">mxnet.gluon.loss.L1Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.SigmoidBinaryCrossEntropyLoss.html">mxnet.gluon.loss.SigmoidBinaryCrossEntropyLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.SoftmaxCrossEntropyLoss.html">mxnet.gluon.loss.SoftmaxCrossEntropyLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.KLDivLoss.html">mxnet.gluon.loss.KLDivLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.HuberLoss.html">mxnet.gluon.loss.HuberLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.HingeLoss.html">mxnet.gluon.loss.HingeLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.SquaredHingeLoss.html">mxnet.gluon.loss.SquaredHingeLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.LogisticLoss.html">mxnet.gluon.loss.LogisticLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.TripletLoss.html">mxnet.gluon.loss.TripletLoss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.loss.CTCLoss.html">mxnet.gluon.loss.CTCLoss</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.parameter.html">Parameter</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.initialize.html">mxnet.gluon.Parameter.initialize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.data.html">mxnet.gluon.Parameter.data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.list_data.html">mxnet.gluon.Parameter.list_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.list_row_sparse_data.html">mxnet.gluon.Parameter.list_row_sparse_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.row_sparse_data.html">mxnet.gluon.Parameter.row_sparse_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.set_data.html">mxnet.gluon.Parameter.set_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.shape.html">mxnet.gluon.Parameter.shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.grad.html">mxnet.gluon.Parameter.grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.list_grad.html">mxnet.gluon.Parameter.list_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.zero_grad.html">mxnet.gluon.Parameter.zero_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.grad_req.html">mxnet.gluon.Parameter.grad_req</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.cast.html">mxnet.gluon.Parameter.cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.list_ctx.html">mxnet.gluon.Parameter.list_ctx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.reset_ctx.html">mxnet.gluon.Parameter.reset_ctx</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Parameter.var.html">mxnet.gluon.Parameter.var</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.Trainer.html">Trainer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Trainer.step.html">mxnet.gluon.Trainer.step</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Trainer.allreduce_grads.html">mxnet.gluon.Trainer.allreduce_grads</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Trainer.update.html">mxnet.gluon.Trainer.update</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Trainer.load_states.html">mxnet.gluon.Trainer.load_states</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Trainer.save_states.html">mxnet.gluon.Trainer.save_states</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Trainer.learning_rate.html">mxnet.gluon.Trainer.learning_rate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.Trainer.set_learning_rate.html">mxnet.gluon.Trainer.set_learning_rate</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.data.html">data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.Dataset.html">mxnet.gluon.data.Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.ArrayDataset.html">mxnet.gluon.data.ArrayDataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.RecordFileDataset.html">mxnet.gluon.data.RecordFileDataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.Sampler.html">mxnet.gluon.data.Sampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.SequentialSampler.html">mxnet.gluon.data.SequentialSampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.RandomSampler.html">mxnet.gluon.data.RandomSampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.BatchSampler.html">mxnet.gluon.data.BatchSampler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.DataLoader.html">mxnet.gluon.data.DataLoader</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.data.vision.html">data.vision</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.datasets.MNIST.html">mxnet.gluon.data.vision.datasets.MNIST</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.datasets.FashionMNIST.html">mxnet.gluon.data.vision.datasets.FashionMNIST</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.datasets.CIFAR10.html">mxnet.gluon.data.vision.datasets.CIFAR10</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.datasets.CIFAR100.html">mxnet.gluon.data.vision.datasets.CIFAR100</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.datasets.ImageRecordDataset.html">mxnet.gluon.data.vision.datasets.ImageRecordDataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.datasets.ImageFolderDataset.html">mxnet.gluon.data.vision.datasets.ImageFolderDataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.Compose.html">mxnet.gluon.data.vision.transforms.Compose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.Cast.html">mxnet.gluon.data.vision.transforms.Cast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.ToTensor.html">mxnet.gluon.data.vision.transforms.ToTensor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.Normalize.html">mxnet.gluon.data.vision.transforms.Normalize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomResizedCrop.html">mxnet.gluon.data.vision.transforms.RandomResizedCrop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.CenterCrop.html">mxnet.gluon.data.vision.transforms.CenterCrop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.Resize.html">mxnet.gluon.data.vision.transforms.Resize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomFlipLeftRight.html">mxnet.gluon.data.vision.transforms.RandomFlipLeftRight</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomFlipTopBottom.html">mxnet.gluon.data.vision.transforms.RandomFlipTopBottom</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomBrightness.html">mxnet.gluon.data.vision.transforms.RandomBrightness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomContrast.html">mxnet.gluon.data.vision.transforms.RandomContrast</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomSaturation.html">mxnet.gluon.data.vision.transforms.RandomSaturation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomHue.html">mxnet.gluon.data.vision.transforms.RandomHue</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomColorJitter.html">mxnet.gluon.data.vision.transforms.RandomColorJitter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.data.vision.transforms.RandomLighting.html">mxnet.gluon.data.vision.transforms.RandomLighting</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.model_zoo.html">model_zoo.vision</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.get_model.html">mxnet.gluon.model_zoo.vision.get_model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet18_v1.html">mxnet.gluon.model_zoo.vision.resnet18_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet34_v1.html">mxnet.gluon.model_zoo.vision.resnet34_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet50_v1.html">mxnet.gluon.model_zoo.vision.resnet50_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet101_v1.html">mxnet.gluon.model_zoo.vision.resnet101_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet152_v1.html">mxnet.gluon.model_zoo.vision.resnet152_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet18_v2.html">mxnet.gluon.model_zoo.vision.resnet18_v2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet34_v2.html">mxnet.gluon.model_zoo.vision.resnet34_v2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet50_v2.html">mxnet.gluon.model_zoo.vision.resnet50_v2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet101_v2.html">mxnet.gluon.model_zoo.vision.resnet101_v2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.resnet152_v2.html">mxnet.gluon.model_zoo.vision.resnet152_v2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.ResNetV1.html">mxnet.gluon.model_zoo.vision.ResNetV1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.ResNetV2.html">mxnet.gluon.model_zoo.vision.ResNetV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.BasicBlockV1.html">mxnet.gluon.model_zoo.vision.BasicBlockV1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.BasicBlockV2.html">mxnet.gluon.model_zoo.vision.BasicBlockV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.BottleneckV1.html">mxnet.gluon.model_zoo.vision.BottleneckV1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.BottleneckV2.html">mxnet.gluon.model_zoo.vision.BottleneckV2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.get_resnet.html">mxnet.gluon.model_zoo.vision.get_resnet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg11.html">mxnet.gluon.model_zoo.vision.vgg11</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg13.html">mxnet.gluon.model_zoo.vision.vgg13</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg16.html">mxnet.gluon.model_zoo.vision.vgg16</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg19.html">mxnet.gluon.model_zoo.vision.vgg19</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg11_bn.html">mxnet.gluon.model_zoo.vision.vgg11_bn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg13_bn.html">mxnet.gluon.model_zoo.vision.vgg13_bn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg16_bn.html">mxnet.gluon.model_zoo.vision.vgg16_bn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.vgg19_bn.html">mxnet.gluon.model_zoo.vision.vgg19_bn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.VGG.html">mxnet.gluon.model_zoo.vision.VGG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.get_vgg.html">mxnet.gluon.model_zoo.vision.get_vgg</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.alexnet.html">mxnet.gluon.model_zoo.vision.alexnet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.AlexNet.html">mxnet.gluon.model_zoo.vision.AlexNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.densenet121.html">mxnet.gluon.model_zoo.vision.densenet121</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.densenet161.html">mxnet.gluon.model_zoo.vision.densenet161</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.densenet169.html">mxnet.gluon.model_zoo.vision.densenet169</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.densenet201.html">mxnet.gluon.model_zoo.vision.densenet201</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.DenseNet.html">mxnet.gluon.model_zoo.vision.DenseNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.squeezenet1_0.html">mxnet.gluon.model_zoo.vision.squeezenet1_0</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.squeezenet1_1.html">mxnet.gluon.model_zoo.vision.squeezenet1_1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.SqueezeNet.html">mxnet.gluon.model_zoo.vision.SqueezeNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.inception_v3.html">mxnet.gluon.model_zoo.vision.inception_v3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.Inception3.html">mxnet.gluon.model_zoo.vision.Inception3</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet1_0.html">mxnet.gluon.model_zoo.vision.mobilenet1_0</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet0_75.html">mxnet.gluon.model_zoo.vision.mobilenet0_75</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet0_5.html">mxnet.gluon.model_zoo.vision.mobilenet0_5</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet0_25.html">mxnet.gluon.model_zoo.vision.mobilenet0_25</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0.html">mxnet.gluon.model_zoo.vision.mobilenet_v2_1_0</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75.html">mxnet.gluon.model_zoo.vision.mobilenet_v2_0_75</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet_v2_0_5.html">mxnet.gluon.model_zoo.vision.mobilenet_v2_0_5</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25.html">mxnet.gluon.model_zoo.vision.mobilenet_v2_0_25</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.MobileNet.html">mxnet.gluon.model_zoo.vision.MobileNet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.model_zoo.vision.MobileNetV2.html">mxnet.gluon.model_zoo.vision.MobileNetV2</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon/mxnet.gluon.utils.html">utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.utils.split_data.html">mxnet.gluon.utils.split_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.utils.split_and_load.html">mxnet.gluon.utils.split_and_load</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.utils.clip_global_norm.html">mxnet.gluon.utils.clip_global_norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.utils.download.html">mxnet.gluon.utils.download</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon/_autogen/mxnet.gluon.utils.check_sha1.html">mxnet.gluon.utils.check_sha1</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/gluon-related/index.html">Gluon related modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.autograd.html">mxnet.autograd</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.backward.html">mxnet.autograd.backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.get_symbol.html">mxnet.autograd.get_symbol</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.grad.html">mxnet.autograd.grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.is_recording.html">mxnet.autograd.is_recording</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.is_training.html">mxnet.autograd.is_training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.mark_variables.html">mxnet.autograd.mark_variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.pause.html">mxnet.autograd.pause</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.predict_mode.html">mxnet.autograd.predict_mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.record.html">mxnet.autograd.record</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.set_recording.html">mxnet.autograd.set_recording</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.set_training.html">mxnet.autograd.set_training</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.train_mode.html">mxnet.autograd.train_mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.autograd.Function.html">mxnet.autograd.Function</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.image.html">mxnet.image</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.imdecode.html">mxnet.image.imdecode</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.scale_down.html">mxnet.image.scale_down</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.resize_short.html">mxnet.image.resize_short</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.fixed_crop.html">mxnet.image.fixed_crop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.random_crop.html">mxnet.image.random_crop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.center_crop.html">mxnet.image.center_crop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.color_normalize.html">mxnet.image.color_normalize</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.random_size_crop.html">mxnet.image.random_size_crop</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.ImageIter.html">mxnet.image.ImageIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.CreateAugmenter.html">mxnet.image.CreateAugmenter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.Augmenter.html">mxnet.image.Augmenter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.SequentialAug.html">mxnet.image.SequentialAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.RandomOrderAug.html">mxnet.image.RandomOrderAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.ResizeAug.html">mxnet.image.ResizeAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.ForceResizeAug.html">mxnet.image.ForceResizeAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.RandomCropAug.html">mxnet.image.RandomCropAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.RandomSizedCropAug.html">mxnet.image.RandomSizedCropAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.CenterCropAug.html">mxnet.image.CenterCropAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.BrightnessJitterAug.html">mxnet.image.BrightnessJitterAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.ContrastJitterAug.html">mxnet.image.ContrastJitterAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.SaturationJitterAug.html">mxnet.image.SaturationJitterAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.HueJitterAug.html">mxnet.image.HueJitterAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.ColorJitterAug.html">mxnet.image.ColorJitterAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.LightingAug.html">mxnet.image.LightingAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.ColorNormalizeAug.html">mxnet.image.ColorNormalizeAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.RandomGrayAug.html">mxnet.image.RandomGrayAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.HorizontalFlipAug.html">mxnet.image.HorizontalFlipAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.CastAug.html">mxnet.image.CastAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.ImageDetIter.html">mxnet.image.ImageDetIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.CreateDetAugmenter.html">mxnet.image.CreateDetAugmenter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.DetBorrowAug.html">mxnet.image.DetBorrowAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.DetRandomSelectAug.html">mxnet.image.DetRandomSelectAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.DetHorizontalFlipAug.html">mxnet.image.DetHorizontalFlipAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.DetRandomCropAug.html">mxnet.image.DetRandomCropAug</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.image.DetRandomPadAug.html">mxnet.image.DetRandomPadAug</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.io.html">mxnet.io</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.NDArrayIter.html">mxnet.io.NDArrayIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.CSVIter.html">mxnet.io.CSVIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.LibSVMIter.html">mxnet.io.LibSVMIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.MNISTIter.html">mxnet.io.MNISTIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.ImageDetRecordIter.html">mxnet.io.ImageDetRecordIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.ImageRecordIter.html">mxnet.io.ImageRecordIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.ImageRecordIter_v1.html">mxnet.io.ImageRecordIter_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.ImageRecordUInt8Iter.html">mxnet.io.ImageRecordUInt8Iter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.ImageRecordUInt8Iter_v1.html">mxnet.io.ImageRecordUInt8Iter_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.DataBatch.html">mxnet.io.DataBatch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.DataDesc.html">mxnet.io.DataDesc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.DataIter.html">mxnet.io.DataIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.MXDataIter.html">mxnet.io.MXDataIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.PrefetchingIter.html">mxnet.io.PrefetchingIter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.io.ResizeIter.html">mxnet.io.ResizeIter</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.recordio.html">mxnet.recordio</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.recordio.MXIndexedRecordIO.html">mxnet.recordio.MXIndexedRecordIO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.recordio.MXRecordIO.html">mxnet.recordio.MXRecordIO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.recordio.IRHeader.html">mxnet.recordio.IRHeader</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.recordio.pack.html">mxnet.recordio.pack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.recordio.pack_img.html">mxnet.recordio.pack_img</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.recordio.unpack.html">mxnet.recordio.unpack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.recordio.unpack_img.html">mxnet.recordio.unpack_img</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.kvstore.html">mxnet.kvstore</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/mxnet.kvstore.create.html">create</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/mxnet.kvstore.KVStore.html">KVStore</a><ul>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.init.html">mxnet.kvstore.KVStore.init</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.pull.html">mxnet.kvstore.KVStore.pull</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.push.html">mxnet.kvstore.KVStore.push</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.row_sparse_pull.html">mxnet.kvstore.KVStore.row_sparse_pull</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.load_optimizer_states.html">mxnet.kvstore.KVStore.load_optimizer_states</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.save_optimizer_states.html">mxnet.kvstore.KVStore.save_optimizer_states</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.set_gradient_compression.html">mxnet.kvstore.KVStore.set_gradient_compression</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.set_optimizer.html">mxnet.kvstore.KVStore.set_optimizer</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.num_workers.html">mxnet.kvstore.KVStore.num_workers</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.rank.html">mxnet.kvstore.KVStore.rank</a></li>
<li class="toctree-l5"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.kvstore.KVStore.type.html">mxnet.kvstore.KVStore.type</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.optimizer.html">mxnet.optimizer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.AdaDelta.html">mxnet.optimizer.AdaDelta</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.AdaGrad.html">mxnet.optimizer.AdaGrad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Adam.html">mxnet.optimizer.Adam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Adamax.html">mxnet.optimizer.Adamax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.DCASGD.html">mxnet.optimizer.DCASGD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.FTML.html">mxnet.optimizer.FTML</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Ftrl.html">mxnet.optimizer.Ftrl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.LBSGD.html">mxnet.optimizer.LBSGD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.NAG.html">mxnet.optimizer.NAG</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Nadam.html">mxnet.optimizer.Nadam</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Optimizer.html">mxnet.optimizer.Optimizer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.RMSProp.html">mxnet.optimizer.RMSProp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.SGD.html">mxnet.optimizer.SGD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.SGLD.html">mxnet.optimizer.SGLD</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Signum.html">mxnet.optimizer.Signum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Updater.html">mxnet.optimizer.Updater</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.random.html">mxnet.random</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.random.seed.html">mxnet.random.seed</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.profiler.html">mxnet.profiler</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.set_config.html">mxnet.profiler.set_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.set_kvstore_handle.html">mxnet.profiler.set_kvstore_handle</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.set_state.html">mxnet.profiler.set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.profiler_set_config.html">mxnet.profiler.profiler_set_config</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.profiler_set_state.html">mxnet.profiler.profiler_set_state</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.pause.html">mxnet.profiler.pause</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.resume.html">mxnet.profiler.resume</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.dump.html">mxnet.profiler.dump</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.dump_profile.html">mxnet.profiler.dump_profile</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.dumps.html">mxnet.profiler.dumps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.Counter.html">mxnet.profiler.Counter</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.Domain.html">mxnet.profiler.Domain</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.Event.html">mxnet.profiler.Event</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.Frame.html">mxnet.profiler.Frame</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.Marker.html">mxnet.profiler.Marker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.profiler.Task.html">mxnet.profiler.Task</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.context.html">mxnet.context</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.context.cpu.html">mxnet.context.cpu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.context.cpu_pinned.html">mxnet.context.cpu_pinned</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.context.current_context.html">mxnet.context.current_context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.context.gpu.html">mxnet.context.gpu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.context.num_gpus.html">mxnet.context.num_gpus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.context.Context.html">mxnet.context.Context</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.initializer.html">mxnet.initializer</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Bilinear.html">mxnet.initializer.Bilinear</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Constant.html">mxnet.initializer.Constant</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.FusedRNN.html">mxnet.initializer.FusedRNN</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.InitDesc.html">mxnet.initializer.InitDesc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Initializer.html">mxnet.initializer.Initializer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.LSTMBias.html">mxnet.initializer.LSTMBias</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Load.html">mxnet.initializer.Load</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.MSRAPrelu.html">mxnet.initializer.MSRAPrelu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Mixed.html">mxnet.initializer.Mixed</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Normal.html">mxnet.initializer.Normal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.One.html">mxnet.initializer.One</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Orthogonal.html">mxnet.initializer.Orthogonal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Uniform.html">mxnet.initializer.Uniform</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Xavier.html">mxnet.initializer.Xavier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.Zero.html">mxnet.initializer.Zero</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.initializer.register.html">mxnet.initializer.register</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.lr_scheduler.html">mxnet.lr_scheduler</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.lr_scheduler.LRScheduler.html">mxnet.lr_scheduler.LRScheduler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.lr_scheduler.FactorScheduler.html">mxnet.lr_scheduler.FactorScheduler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.lr_scheduler.MultiFactorScheduler.html">mxnet.lr_scheduler.MultiFactorScheduler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.lr_scheduler.PolyScheduler.html">mxnet.lr_scheduler.PolyScheduler</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.lr_scheduler.CosineScheduler.html">mxnet.lr_scheduler.CosineScheduler</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/gluon-related/mxnet.metric.html">mxnet.metric</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.Accuracy.html">mxnet.metric.Accuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.Caffe.html">mxnet.metric.Caffe</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.CompositeEvalMetric.html">mxnet.metric.CompositeEvalMetric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.CrossEntropy.html">mxnet.metric.CrossEntropy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.CustomMetric.html">mxnet.metric.CustomMetric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.EvalMetric.html">mxnet.metric.EvalMetric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.F1.html">mxnet.metric.F1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.Loss.html">mxnet.metric.Loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.MAE.html">mxnet.metric.MAE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.MCC.html">mxnet.metric.MCC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.MSE.html">mxnet.metric.MSE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.NegativeLogLikelihood.html">mxnet.metric.NegativeLogLikelihood</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.PearsonCorrelation.html">mxnet.metric.PearsonCorrelation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.Perplexity.html">mxnet.metric.Perplexity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.RMSE.html">mxnet.metric.RMSE</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.TopKAccuracy.html">mxnet.metric.TopKAccuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.Torch.html">mxnet.metric.Torch</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.check_label_shapes.html">mxnet.metric.check_label_shapes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.create.html">mxnet.metric.create</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/gluon-related/_autogen/mxnet.metric.np.html">mxnet.metric.np</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/symbol/index.html">mxnet.symbol</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/symbol/mxnet.symbol.Symbol.html">Symbol</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__call__.html">mxnet.symbol.Symbol.__call__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__add__.html">mxnet.symbol.Symbol.__add__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__sub__.html">mxnet.symbol.Symbol.__sub__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__rsub__.html">mxnet.symbol.Symbol.__rsub__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__neg__.html">mxnet.symbol.Symbol.__neg__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__mul__.html">mxnet.symbol.Symbol.__mul__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__div__.html">mxnet.symbol.Symbol.__div__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__rdiv__.html">mxnet.symbol.Symbol.__rdiv__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__mod__.html">mxnet.symbol.Symbol.__mod__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__rmod__.html">mxnet.symbol.Symbol.__rmod__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__pow__.html">mxnet.symbol.Symbol.__pow__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.sin.html">mxnet.symbol.Symbol.sin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.cos.html">mxnet.symbol.Symbol.cos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.tan.html">mxnet.symbol.Symbol.tan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.arcsin.html">mxnet.symbol.Symbol.arcsin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.arccos.html">mxnet.symbol.Symbol.arccos</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.arctan.html">mxnet.symbol.Symbol.arctan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.degrees.html">mxnet.symbol.Symbol.degrees</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.radians.html">mxnet.symbol.Symbol.radians</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.sinh.html">mxnet.symbol.Symbol.sinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.cosh.html">mxnet.symbol.Symbol.cosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.tanh.html">mxnet.symbol.Symbol.tanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.arcsinh.html">mxnet.symbol.Symbol.arcsinh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.arccosh.html">mxnet.symbol.Symbol.arccosh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.arctanh.html">mxnet.symbol.Symbol.arctanh</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.exp.html">mxnet.symbol.Symbol.exp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.expm1.html">mxnet.symbol.Symbol.expm1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.log.html">mxnet.symbol.Symbol.log</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.log10.html">mxnet.symbol.Symbol.log10</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.log2.html">mxnet.symbol.Symbol.log2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.log1p.html">mxnet.symbol.Symbol.log1p</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.sqrt.html">mxnet.symbol.Symbol.sqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.rsqrt.html">mxnet.symbol.Symbol.rsqrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.cbrt.html">mxnet.symbol.Symbol.cbrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.rcbrt.html">mxnet.symbol.Symbol.rcbrt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.square.html">mxnet.symbol.Symbol.square</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.relu.html">mxnet.symbol.Symbol.relu</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.sigmoid.html">mxnet.symbol.Symbol.sigmoid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.softmax.html">mxnet.symbol.Symbol.softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.log_softmax.html">mxnet.symbol.Symbol.log_softmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__lt__.html">mxnet.symbol.Symbol.__lt__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__le__.html">mxnet.symbol.Symbol.__le__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__gt__.html">mxnet.symbol.Symbol.__gt__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__ge__.html">mxnet.symbol.Symbol.__ge__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__eq__.html">mxnet.symbol.Symbol.__eq__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__ne__.html">mxnet.symbol.Symbol.__ne__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.zeros_like.html">mxnet.symbol.Symbol.zeros_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.ones_like.html">mxnet.symbol.Symbol.ones_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.diag.html">mxnet.symbol.Symbol.diag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.astype.html">mxnet.symbol.Symbol.astype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.shape_array.html">mxnet.symbol.Symbol.shape_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.size_array.html">mxnet.symbol.Symbol.size_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.reshape.html">mxnet.symbol.Symbol.reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.reshape_like.html">mxnet.symbol.Symbol.reshape_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.flatten.html">mxnet.symbol.Symbol.flatten</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.expand_dims.html">mxnet.symbol.Symbol.expand_dims</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.broadcast_to.html">mxnet.symbol.Symbol.broadcast_to</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.broadcast_axes.html">mxnet.symbol.Symbol.broadcast_axes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.broadcast_like.html">mxnet.symbol.Symbol.broadcast_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.tile.html">mxnet.symbol.Symbol.tile</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.pad.html">mxnet.symbol.Symbol.pad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.transpose.html">mxnet.symbol.Symbol.transpose</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.swapaxes.html">mxnet.symbol.Symbol.swapaxes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.flip.html">mxnet.symbol.Symbol.flip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.depth_to_space.html">mxnet.symbol.Symbol.depth_to_space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.space_to_depth.html">mxnet.symbol.Symbol.space_to_depth</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.sum.html">mxnet.symbol.Symbol.sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.nansum.html">mxnet.symbol.Symbol.nansum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.prod.html">mxnet.symbol.Symbol.prod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.nanprod.html">mxnet.symbol.Symbol.nanprod</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.mean.html">mxnet.symbol.Symbol.mean</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.max.html">mxnet.symbol.Symbol.max</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.min.html">mxnet.symbol.Symbol.min</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.norm.html">mxnet.symbol.Symbol.norm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.round.html">mxnet.symbol.Symbol.round</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.rint.html">mxnet.symbol.Symbol.rint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.fix.html">mxnet.symbol.Symbol.fix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.floor.html">mxnet.symbol.Symbol.floor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.ceil.html">mxnet.symbol.Symbol.ceil</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.trunc.html">mxnet.symbol.Symbol.trunc</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.sort.html">mxnet.symbol.Symbol.sort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.argsort.html">mxnet.symbol.Symbol.argsort</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.topk.html">mxnet.symbol.Symbol.topk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.argmax.html">mxnet.symbol.Symbol.argmax</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.argmin.html">mxnet.symbol.Symbol.argmin</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.argmax_channel.html">mxnet.symbol.Symbol.argmax_channel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.name.html">mxnet.symbol.Symbol.name</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.list_arguments.html">mxnet.symbol.Symbol.list_arguments</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.list_outputs.html">mxnet.symbol.Symbol.list_outputs</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.list_auxiliary_states.html">mxnet.symbol.Symbol.list_auxiliary_states</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.list_attr.html">mxnet.symbol.Symbol.list_attr</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.attr.html">mxnet.symbol.Symbol.attr</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.attr_dict.html">mxnet.symbol.Symbol.attr_dict</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.slice.html">mxnet.symbol.Symbol.slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.slice_axis.html">mxnet.symbol.Symbol.slice_axis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.slice_like.html">mxnet.symbol.Symbol.slice_like</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.take.html">mxnet.symbol.Symbol.take</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.one_hot.html">mxnet.symbol.Symbol.one_hot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.pick.html">mxnet.symbol.Symbol.pick</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__getitem__.html">mxnet.symbol.Symbol.__getitem__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.__iter__.html">mxnet.symbol.Symbol.__iter__</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.get_internals.html">mxnet.symbol.Symbol.get_internals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.get_children.html">mxnet.symbol.Symbol.get_children</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.infer_type.html">mxnet.symbol.Symbol.infer_type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.infer_shape.html">mxnet.symbol.Symbol.infer_shape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.infer_shape_partial.html">mxnet.symbol.Symbol.infer_shape_partial</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.bind.html">mxnet.symbol.Symbol.bind</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.simple_bind.html">mxnet.symbol.Symbol.simple_bind</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.save.html">mxnet.symbol.Symbol.save</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.tojson.html">mxnet.symbol.Symbol.tojson</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.debug_str.html">mxnet.symbol.Symbol.debug_str</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.clip.html">mxnet.symbol.Symbol.clip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol/_autogen/mxnet.symbol.Symbol.sign.html">mxnet.symbol.Symbol.sign</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/symbol-related/index.html">Symbol related modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/symbol-related/mxnet.callback.html">mxnet.callback</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.callback.do_checkpoint.html">mxnet.callback.do_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.callback.log_train_metric.html">mxnet.callback.log_train_metric</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.callback.module_checkpoint.html">mxnet.callback.module_checkpoint</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.callback.LogValidationMetricsCallback.html">mxnet.callback.LogValidationMetricsCallback</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.callback.ProgressBar.html">mxnet.callback.ProgressBar</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.callback.Speedometer.html">mxnet.callback.Speedometer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/symbol-related/mxnet.module.html">mxnet.module</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.module.BaseModule.html">mxnet.module.BaseModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.module.BucketingModule.html">mxnet.module.BucketingModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.module.Module.html">mxnet.module.Module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.module.PythonLossModule.html">mxnet.module.PythonLossModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.module.PythonModule.html">mxnet.module.PythonModule</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.module.SequentialModule.html">mxnet.module.SequentialModule</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/symbol-related/mxnet.monitor.html">mxnet.monitor</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.monitor.Monitor.html">mxnet.monitor.Monitor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/symbol-related/mxnet.visualization.html">mxnet.visualization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.visualization.plot_network.html">mxnet.visualization.plot_network</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/symbol-related/_autogen/mxnet.visualization.print_summary.html">mxnet.visualization.print_summary</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api/advanced/index.html">Advanced modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api/advanced/mxnet.executor.html">mxnet.executor</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.executor.Executor.html">mxnet.executor.Executor</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/advanced/mxnet.kvstore_server.html">mxnet.kvstore_server</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.kvstore_server.KVStoreServer.html">mxnet.kvstore_server.KVStoreServer</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/advanced/mxnet.engine.html">mxnet.engine</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.engine.bulk.html">mxnet.engine.bulk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.engine.set_bulk_size.html">mxnet.engine.set_bulk_size</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/advanced/mxnet.executor_manager.html">mxnet.executor_manager</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.executor_manager.DataParallelExecutorGroup.html">mxnet.executor_manager.DataParallelExecutorGroup</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.executor_manager.DataParallelExecutorManager.html">mxnet.executor_manager.DataParallelExecutorManager</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/advanced/mxnet.rtc.html">mxnet.rtc</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.rtc.CudaKernel.html">mxnet.rtc.CudaKernel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.rtc.CudaModule.html">mxnet.rtc.CudaModule</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/advanced/mxnet.test_utils.html">mxnet.test_utils</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.almost_equal.html">mxnet.test_utils.almost_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.almost_equal_ignore_nan.html">mxnet.test_utils.almost_equal_ignore_nan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.assert_almost_equal.html">mxnet.test_utils.assert_almost_equal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.assert_almost_equal_ignore_nan.html">mxnet.test_utils.assert_almost_equal_ignore_nan</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.assert_exception.html">mxnet.test_utils.assert_exception</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.assign_each.html">mxnet.test_utils.assign_each</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.assign_each2.html">mxnet.test_utils.assign_each2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.check_consistency.html">mxnet.test_utils.check_consistency</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.check_numeric_gradient.html">mxnet.test_utils.check_numeric_gradient</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.check_speed.html">mxnet.test_utils.check_speed</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.check_symbolic_backward.html">mxnet.test_utils.check_symbolic_backward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.check_symbolic_forward.html">mxnet.test_utils.check_symbolic_forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.chi_square_check.html">mxnet.test_utils.chi_square_check</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.create_sparse_array.html">mxnet.test_utils.create_sparse_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.create_sparse_array_zd.html">mxnet.test_utils.create_sparse_array_zd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.default_context.html">mxnet.test_utils.default_context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.default_dtype.html">mxnet.test_utils.default_dtype</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.discard_stderr.html">mxnet.test_utils.discard_stderr</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.download.html">mxnet.test_utils.download</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.find_max_violation.html">mxnet.test_utils.find_max_violation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.gen_buckets_probs_with_ppf.html">mxnet.test_utils.gen_buckets_probs_with_ppf</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_atol.html">mxnet.test_utils.get_atol</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_bz2_data.html">mxnet.test_utils.get_bz2_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_cifar10.html">mxnet.test_utils.get_cifar10</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_im2rec_path.html">mxnet.test_utils.get_im2rec_path</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_mnist.html">mxnet.test_utils.get_mnist</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_mnist_iterator.html">mxnet.test_utils.get_mnist_iterator</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_mnist_pkl.html">mxnet.test_utils.get_mnist_pkl</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_mnist_ubyte.html">mxnet.test_utils.get_mnist_ubyte</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_rtol.html">mxnet.test_utils.get_rtol</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.get_zip_data.html">mxnet.test_utils.get_zip_data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.list_gpus.html">mxnet.test_utils.list_gpus</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.mean_check.html">mxnet.test_utils.mean_check</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.np_reduce.html">mxnet.test_utils.np_reduce</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.numeric_grad.html">mxnet.test_utils.numeric_grad</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.rand_ndarray.html">mxnet.test_utils.rand_ndarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.rand_shape_2d.html">mxnet.test_utils.rand_shape_2d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.rand_shape_3d.html">mxnet.test_utils.rand_shape_3d</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.rand_shape_nd.html">mxnet.test_utils.rand_shape_nd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.rand_sparse_ndarray.html">mxnet.test_utils.rand_sparse_ndarray</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.random_arrays.html">mxnet.test_utils.random_arrays</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.random_sample.html">mxnet.test_utils.random_sample</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.retry.html">mxnet.test_utils.retry</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.same.html">mxnet.test_utils.same</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.same_array.html">mxnet.test_utils.same_array</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.set_default_context.html">mxnet.test_utils.set_default_context</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.set_env_var.html">mxnet.test_utils.set_env_var</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.shuffle_csr_column_indices.html">mxnet.test_utils.shuffle_csr_column_indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.simple_forward.html">mxnet.test_utils.simple_forward</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.var_check.html">mxnet.test_utils.var_check</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.test_utils.verify_generator.html">mxnet.test_utils.verify_generator</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api/advanced/mxnet.util.html">mxnet.util</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api/advanced/_autogen/mxnet.util.makedirs.html">mxnet.util.makedirs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        
        </div>
    
</header>

    <div class="document">
        <div class="page-content">
        
  <h1>Source code for mxnet.optimizer.optimizer</h1><div class="highlight"><pre>
<span></span><span class="c1"># coding: utf-8</span>
<span class="c1"># Licensed to the Apache Software Foundation (ASF) under one</span>
<span class="c1"># or more contributor license agreements.  See the NOTICE file</span>
<span class="c1"># distributed with this work for additional information</span>
<span class="c1"># regarding copyright ownership.  The ASF licenses this file</span>
<span class="c1"># to you under the Apache License, Version 2.0 (the</span>
<span class="c1"># &quot;License&quot;); you may not use this file except in compliance</span>
<span class="c1"># with the License.  You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#   http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing,</span>
<span class="c1"># software distributed under the License is distributed on an</span>
<span class="c1"># &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY</span>
<span class="c1"># KIND, either express or implied.  See the License for the</span>
<span class="c1"># specific language governing permissions and limitations</span>
<span class="c1"># under the License.</span>

<span class="c1"># pylint: disable=too-many-lines</span>
<span class="sd">&quot;&quot;&quot;Weight updating functions.&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="k">import</span> <span class="n">py_str</span>
<span class="kn">from</span> <span class="nn">..ndarray</span> <span class="k">import</span> <span class="p">(</span><span class="n">NDArray</span><span class="p">,</span> <span class="n">zeros</span><span class="p">,</span> <span class="n">clip</span><span class="p">,</span> <span class="n">sqrt</span><span class="p">,</span> <span class="n">cast</span><span class="p">,</span> <span class="n">maximum</span><span class="p">,</span> <span class="nb">abs</span> <span class="k">as</span> <span class="n">NDabs</span><span class="p">,</span> <span class="n">array</span><span class="p">,</span> <span class="n">multiply</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">..ndarray</span> <span class="k">import</span> <span class="p">(</span><span class="n">sgd_update</span><span class="p">,</span> <span class="n">sgd_mom_update</span><span class="p">,</span> <span class="n">adam_update</span><span class="p">,</span> <span class="n">rmsprop_update</span><span class="p">,</span> <span class="n">rmspropalex_update</span><span class="p">,</span>
                       <span class="n">mp_sgd_update</span><span class="p">,</span> <span class="n">mp_sgd_mom_update</span><span class="p">,</span> <span class="n">square</span><span class="p">,</span> <span class="n">ftrl_update</span><span class="p">,</span> <span class="n">ftml_update</span><span class="p">,</span>
                       <span class="n">signsgd_update</span><span class="p">,</span> <span class="n">signum_update</span><span class="p">,</span> <span class="n">nag_mom_update</span><span class="p">,</span> <span class="n">mp_nag_mom_update</span><span class="p">,</span>
                       <span class="n">multi_sgd_update</span><span class="p">,</span> <span class="n">multi_sgd_mom_update</span><span class="p">,</span> <span class="n">multi_mp_sgd_update</span><span class="p">,</span>
                       <span class="n">multi_mp_sgd_mom_update</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">..ndarray</span> <span class="k">import</span> <span class="n">sparse</span>
<span class="kn">from</span> <span class="nn">..random</span> <span class="k">import</span> <span class="n">normal</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;AdaDelta&#39;</span><span class="p">,</span> <span class="s1">&#39;AdaGrad&#39;</span><span class="p">,</span> <span class="s1">&#39;Adam&#39;</span><span class="p">,</span> <span class="s1">&#39;Adamax&#39;</span><span class="p">,</span> <span class="s1">&#39;DCASGD&#39;</span><span class="p">,</span> <span class="s1">&#39;FTML&#39;</span><span class="p">,</span> <span class="s1">&#39;Ftrl&#39;</span><span class="p">,</span> <span class="s1">&#39;LBSGD&#39;</span><span class="p">,</span>
    <span class="s1">&#39;NAG&#39;</span><span class="p">,</span> <span class="s1">&#39;NDabs&#39;</span><span class="p">,</span> <span class="s1">&#39;Nadam&#39;</span><span class="p">,</span> <span class="s1">&#39;Optimizer&#39;</span><span class="p">,</span> <span class="s1">&#39;RMSProp&#39;</span><span class="p">,</span> <span class="s1">&#39;SGD&#39;</span><span class="p">,</span> <span class="s1">&#39;SGLD&#39;</span><span class="p">,</span> <span class="s1">&#39;Signum&#39;</span><span class="p">,</span>
    <span class="s1">&#39;Test&#39;</span><span class="p">,</span> <span class="s1">&#39;Updater&#39;</span><span class="p">,</span> <span class="s1">&#39;ccSGD&#39;</span><span class="p">,</span> <span class="s1">&#39;create&#39;</span><span class="p">,</span> <span class="s1">&#39;get_updater&#39;</span><span class="p">,</span> <span class="s1">&#39;register&#39;</span>
<span class="p">]</span>

<span class="k">def</span> <span class="nf">_flatten_list</span><span class="p">(</span><span class="n">nested_list</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">sublist</span> <span class="ow">in</span> <span class="n">nested_list</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sublist</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">Optimizer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The base class inherited by all optimizers.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    rescale_grad : float, optional, default 1.0</span>
<span class="sd">        Multiply the gradient with `rescale_grad` before updating. Often</span>
<span class="sd">        choose to be ``1.0/batch_size``.</span>

<span class="sd">    param_idx2name : dict from int to string, optional, default None</span>
<span class="sd">        A dictionary that maps int index to string name.</span>

<span class="sd">    clip_gradient : float, optional, default None</span>
<span class="sd">        Clip the gradient by projecting onto the box ``[-clip_gradient, clip_gradient]``.</span>

<span class="sd">    learning_rate : float, optional, default 0.01</span>
<span class="sd">        The initial learning rate.</span>

<span class="sd">    lr_scheduler : LRScheduler, optional, default None</span>
<span class="sd">        The learning rate scheduler.</span>

<span class="sd">    wd : float, optional, default 0.0</span>
<span class="sd">        The weight decay (or L2 regularization) coefficient. Modifies objective</span>
<span class="sd">        by adding a penalty for having large weights.</span>

<span class="sd">    sym: Symbol, optional, default None</span>
<span class="sd">        The Symbol this optimizer is applying to.</span>

<span class="sd">    begin_num_update : int, optional, default 0</span>
<span class="sd">        The initial number of updates.</span>

<span class="sd">    multi_precision : bool, optional, default False</span>
<span class="sd">       Flag to control the internal precision of the optimizer.</span>
<span class="sd">       False: results in using the same precision as the weights (default),</span>
<span class="sd">       True: makes internal 32-bit copy of the weights and applies gradients</span>
<span class="sd">       in 32-bit precision even if actual weights used in the model have lower precision.</span>
<span class="sd">       Turning this on can improve convergence and accuracy when training with float16.</span>

<span class="sd">    param_dict : dict of int -&gt; gluon.Parameter, default None</span>
<span class="sd">        Dictionary of parameter index to gluon.Parameter, used to lookup parameter attributes</span>
<span class="sd">        such as lr_mult, wd_mult, etc. param_dict shall not be deep copied.</span>

<span class="sd">    Properties</span>
<span class="sd">    ----------</span>
<span class="sd">    learning_rate : float</span>
<span class="sd">        The current learning rate of the optimizer. Given an Optimizer object</span>
<span class="sd">        optimizer, its learning rate can be accessed as optimizer.learning_rate.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rescale_grad</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">param_idx2name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>
                 <span class="n">clip_gradient</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                 <span class="n">lr_scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sym</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">begin_num_update</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">multi_precision</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">param_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span> <span class="o">=</span> <span class="n">rescale_grad</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span>
        <span class="k">if</span> <span class="n">lr_scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">base_lr</span> <span class="o">=</span> <span class="n">learning_rate</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">wd</span> <span class="o">=</span> <span class="n">wd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_mult</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wd_mult</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">begin_num_update</span> <span class="o">=</span> <span class="n">begin_num_update</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_update</span> <span class="o">=</span> <span class="n">begin_num_update</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_all_index_update_counts</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span> <span class="p">:</span> <span class="p">{}}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_index_update_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_all_index_update_counts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span> <span class="o">=</span> <span class="n">clip_gradient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multi_precision</span> <span class="o">=</span> <span class="n">multi_precision</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_num</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="n">param_idx2name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">param_idx2name</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param_idx2name</span><span class="p">,</span> <span class="nb">dict</span><span class="p">),</span> \
            <span class="s1">&#39;param_idx2name should be a dict of param indexes to names.&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">idx2name</span> <span class="o">=</span> <span class="n">param_idx2name</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sym_info</span> <span class="o">=</span> <span class="p">(</span><span class="n">sym</span><span class="o">.</span><span class="n">attr_dict</span><span class="p">(),</span> <span class="n">sym</span><span class="o">.</span><span class="n">list_arguments</span><span class="p">())</span> <span class="k">if</span> <span class="n">sym</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_dict</span> <span class="o">=</span> <span class="n">param_dict</span> <span class="k">if</span> <span class="n">param_dict</span> <span class="k">else</span> <span class="p">{}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_lr_mult</span><span class="p">({})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_wd_mult</span><span class="p">({})</span>

    <span class="n">opt_registry</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">register</span><span class="p">(</span><span class="n">klass</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Registers a new optimizer.</span>

<span class="sd">        Once an optimizer is registered, we can create an instance of this</span>
<span class="sd">        optimizer with `create_optimizer` later.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>

<span class="sd">        &gt;&gt;&gt; @mx.optimizer.Optimizer.register</span>
<span class="sd">        ... class MyOptimizer(mx.optimizer.Optimizer):</span>
<span class="sd">        ...     pass</span>
<span class="sd">        &gt;&gt;&gt; optim = mx.optimizer.Optimizer.create_optimizer(&#39;MyOptimizer&#39;)</span>
<span class="sd">        &gt;&gt;&gt; print(type(optim))</span>
<span class="sd">        &lt;class &#39;__main__.MyOptimizer&#39;&gt;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">klass</span><span class="p">,</span> <span class="nb">type</span><span class="p">))</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">klass</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">Optimizer</span><span class="o">.</span><span class="n">opt_registry</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;WARNING: New optimizer </span><span class="si">%s</span><span class="s1">.</span><span class="si">%s</span><span class="s1"> is overriding &#39;</span>
                          <span class="s1">&#39;existing optimizer </span><span class="si">%s</span><span class="s1">.</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>
                          <span class="p">(</span><span class="n">klass</span><span class="o">.</span><span class="vm">__module__</span><span class="p">,</span> <span class="n">klass</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                           <span class="n">Optimizer</span><span class="o">.</span><span class="n">opt_registry</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="vm">__module__</span><span class="p">,</span>
                           <span class="n">Optimizer</span><span class="o">.</span><span class="n">opt_registry</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="vm">__name__</span><span class="p">))</span>
        <span class="n">Optimizer</span><span class="o">.</span><span class="n">opt_registry</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">klass</span>
        <span class="k">return</span> <span class="n">klass</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">create_optimizer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Instantiates an optimizer with a given name and kwargs.</span>

<span class="sd">        .. note:: We can use the alias `create` for ``Optimizer.create_optimizer``.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        name: str</span>
<span class="sd">            Name of the optimizer. Should be the name</span>
<span class="sd">            of a subclass of Optimizer. Case insensitive.</span>

<span class="sd">        kwargs: dict</span>
<span class="sd">            Parameters for the optimizer.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Optimizer</span>
<span class="sd">            An instantiated optimizer.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; sgd = mx.optimizer.Optimizer.create_optimizer(&#39;sgd&#39;)</span>
<span class="sd">        &gt;&gt;&gt; type(sgd)</span>
<span class="sd">        &lt;class &#39;mxnet.optimizer.SGD&#39;&gt;</span>
<span class="sd">        &gt;&gt;&gt; adam = mx.optimizer.create(&#39;adam&#39;, learning_rate=.1)</span>
<span class="sd">        &gt;&gt;&gt; type(adam)</span>
<span class="sd">        &lt;class &#39;mxnet.optimizer.Adam&#39;&gt;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">Optimizer</span><span class="o">.</span><span class="n">opt_registry</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Optimizer</span><span class="o">.</span><span class="n">opt_registry</span><span class="p">[</span><span class="n">name</span><span class="o">.</span><span class="n">lower</span><span class="p">()](</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot find optimizer </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">name</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_update</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Creates auxiliary state for a given weight.</span>

<span class="sd">        Some optimizers require additional states, e.g. as momentum, in addition</span>
<span class="sd">        to gradients in order to update weights. This function creates state</span>
<span class="sd">        for a given weight which will be used in `update`. This function is</span>
<span class="sd">        called only once for each weight.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        index : int</span>
<span class="sd">            An unique index to identify the weight.</span>
<span class="sd">        weight : NDArray</span>
<span class="sd">            The weight.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        state : any obj</span>
<span class="sd">            The state associated with the weight.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">create_state_multi_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Creates auxiliary state for a given weight, including FP32 high</span>
<span class="sd">        precision copy if original weight is FP16.</span>

<span class="sd">        This method is provided to perform automatic mixed precision training</span>
<span class="sd">        for optimizers that do not support it themselves.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        index : int</span>
<span class="sd">            An unique index to identify the weight.</span>
<span class="sd">        weight : NDArray</span>
<span class="sd">            The weight.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        state : any obj</span>
<span class="sd">            The state associated with the weight.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">weight_master_copy</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_precision</span> <span class="ow">and</span> <span class="n">weight</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float16</span><span class="p">:</span>
            <span class="n">weight_master_copy</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">weight_master_copy</span><span class="p">,)</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_state</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight_master_copy</span><span class="p">),)</span>
        <span class="k">if</span> <span class="n">weight</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float16</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_precision</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Accumulating with float16 in optimizer can lead to &quot;</span>
                          <span class="s2">&quot;poor accuracy or slow convergence. &quot;</span>
                          <span class="s2">&quot;Consider using multi_precision=True option of the &quot;</span>
                          <span class="s2">&quot;optimizer&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_state</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Updates the given parameter using the corresponding gradient and state.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        index : int</span>
<span class="sd">            The unique index of the parameter into the individual learning</span>
<span class="sd">            rates and weight decays. Learning rates and weight decay</span>
<span class="sd">            may be set via `set_lr_mult()` and `set_wd_mult()`, respectively.</span>
<span class="sd">        weight : NDArray</span>
<span class="sd">            The parameter to be updated.</span>
<span class="sd">        grad : NDArray</span>
<span class="sd">            The gradient of the objective with respect to this parameter.</span>
<span class="sd">        state : any obj</span>
<span class="sd">            The state returned by `create_state()`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">update_multi_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Updates the given parameter using the corresponding gradient and state.</span>
<span class="sd">        Mixed precision version.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        index : int</span>
<span class="sd">            The unique index of the parameter into the individual learning</span>
<span class="sd">            rates and weight decays. Learning rates and weight decay</span>
<span class="sd">            may be set via `set_lr_mult()` and `set_wd_mult()`, respectively.</span>
<span class="sd">        weight : NDArray</span>
<span class="sd">            The parameter to be updated.</span>
<span class="sd">        grad : NDArray</span>
<span class="sd">            The gradient of the objective with respect to this parameter.</span>
<span class="sd">        state : any obj</span>
<span class="sd">            The state returned by `create_state()`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_precision</span> <span class="ow">and</span> <span class="n">weight</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float16</span><span class="p">:</span>
            <span class="c1"># Wrapper for mixed precision</span>
            <span class="n">weight_master_copy</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">original_state</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">grad32</span> <span class="o">=</span> <span class="n">grad</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight_master_copy</span><span class="p">,</span> <span class="n">grad32</span><span class="p">,</span> <span class="n">original_state</span><span class="p">)</span>
            <span class="n">cast</span><span class="p">(</span><span class="n">weight_master_copy</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets a new learning rate of the optimizer.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lr : float</span>
<span class="sd">            The new learning rate of the optimizer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="c1"># pylint: disable=no-else-raise</span>
            <span class="k">raise</span> <span class="ne">UserWarning</span><span class="p">(</span><span class="s2">&quot;LRScheduler of the optimizer has already been &quot;</span>
                              <span class="s2">&quot;defined. Note that set_learning_rate can mutate &quot;</span>
                              <span class="s2">&quot;the value of the learning rate of the optimizer &quot;</span>
                              <span class="s2">&quot;only when the LRScheduler of the optimizer is &quot;</span>
                              <span class="s2">&quot;undefined.&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>

    <span class="k">def</span> <span class="nf">set_lr_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args_lrscale</span><span class="p">):</span> <span class="c1"># pylint: disable=unused-argument</span>
        <span class="sd">&quot;&quot;&quot;[DEPRECATED] Sets lr scale. Use set_lr_mult instead.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">DeprecationWarning</span>

    <span class="k">def</span> <span class="nf">set_lr_mult</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args_lr_mult</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets an individual learning rate multiplier for each parameter.</span>

<span class="sd">        If you specify a learning rate multiplier for a parameter, then</span>
<span class="sd">        the learning rate for the parameter will be set as the product of</span>
<span class="sd">        the global learning rate `self.lr` and its multiplier.</span>

<span class="sd">        .. note:: The default learning rate multiplier of a `Variable`</span>
<span class="sd">            can be set with `lr_mult` argument in the constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        args_lr_mult : dict of str/int to float</span>
<span class="sd">            For each of its key-value entries, the learning rate multipler for the</span>
<span class="sd">            parameter specified in the key will be set as the given value.</span>

<span class="sd">            You can specify the parameter with either its name or its index.</span>
<span class="sd">            If you use the name, you should pass `sym` in the constructor,</span>
<span class="sd">            and the name you specified in the key of `args_lr_mult` should match</span>
<span class="sd">            the name of the parameter in `sym`. If you use the index, it should</span>
<span class="sd">            correspond to the index of the parameter used in the `update` method.</span>

<span class="sd">            Specifying a parameter by its index is only supported for backward</span>
<span class="sd">            compatibility, and we recommend to use the name instead.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_mult</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sym_info</span><span class="p">:</span>
            <span class="n">attr</span><span class="p">,</span> <span class="n">arg_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sym_info</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">arg_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">attr</span> <span class="ow">and</span> <span class="s1">&#39;__lr_mult__&#39;</span> <span class="ow">in</span> <span class="n">attr</span><span class="p">[</span><span class="n">name</span><span class="p">]:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">lr_mult</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">attr</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="s1">&#39;__lr_mult__&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_mult</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">args_lr_mult</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_wd_mult</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args_wd_mult</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets an individual weight decay multiplier for each parameter.</span>

<span class="sd">        By default, if `param_idx2name` was provided in the</span>
<span class="sd">        constructor, the weight decay multipler is set as 0 for all</span>
<span class="sd">        parameters whose name don&#39;t end with ``_weight`` or</span>
<span class="sd">        ``_gamma``.</span>

<span class="sd">        .. note:: The default weight decay multiplier for a `Variable`</span>
<span class="sd">            can be set with its `wd_mult` argument in the constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        args_wd_mult : dict of string/int to float</span>
<span class="sd">            For each of its key-value entries, the weight decay multipler for the</span>
<span class="sd">            parameter specified in the key will be set as the given value.</span>

<span class="sd">            You can specify the parameter with either its name or its index.</span>
<span class="sd">            If you use the name, you should pass `sym` in the constructor,</span>
<span class="sd">            and the name you specified in the key of `args_lr_mult` should match</span>
<span class="sd">            the name of the parameter in `sym`. If you use the index, it should</span>
<span class="sd">            correspond to the index of the parameter used in the `update` method.</span>

<span class="sd">            Specifying a parameter by its index is only supported for backward</span>
<span class="sd">            compatibility, and we recommend to use the name instead.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wd_mult</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx2name</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_weight&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">n</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_gamma&#39;</span><span class="p">)):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">wd_mult</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sym_info</span><span class="p">:</span>
            <span class="n">attr</span><span class="p">,</span> <span class="n">arg_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sym_info</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">arg_names</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">attr</span> <span class="ow">and</span> <span class="s1">&#39;__wd_mult__&#39;</span> <span class="ow">in</span> <span class="n">attr</span><span class="p">[</span><span class="n">name</span><span class="p">]:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">wd_mult</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">attr</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="s1">&#39;__wd_mult__&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wd_mult</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">args_wd_mult</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_set_current_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device_id</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets the number of the currently handled device.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        device_id : int</span>
<span class="sd">            The number of current device.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">device_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_all_index_update_counts</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_all_index_update_counts</span><span class="p">[</span><span class="n">device_id</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_index_update_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_all_index_update_counts</span><span class="p">[</span><span class="n">device_id</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_update_count</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Updates num_update.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        index : int or list of int</span>
<span class="sd">            The index to be updated.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">index</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_index_update_count</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_index_update_count</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">begin_num_update</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_index_update_count</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_update</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_index_update_count</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_update</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_lrs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Gets the learning rates given the indices of the weights.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        indices : list of int</span>
<span class="sd">            Indices corresponding to weights.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        lrs : list of float</span>
<span class="sd">            Learning rates for those indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_update</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span>

        <span class="n">lrs</span> <span class="o">=</span> <span class="p">[</span><span class="n">lr</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">indices</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_dict</span><span class="p">:</span>
                <span class="n">lrs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_dict</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">lr_mult</span>
            <span class="k">elif</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_mult</span><span class="p">:</span>
                <span class="n">lrs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_mult</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx2name</span><span class="p">:</span>
                <span class="n">lrs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_mult</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx2name</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lrs</span>

    <span class="k">def</span> <span class="nf">_get_lr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Gets the learning rate given the index of the weight.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        index : int</span>
<span class="sd">            The index corresponding to the weight.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        lr : float</span>
<span class="sd">            Learning rate for this index.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lrs</span><span class="p">([</span><span class="n">index</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_get_wds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Gets weight decays for indices.</span>
<span class="sd">        Returns 0 for non-weights if the name of weights are provided for `__init__`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        indices : list of int</span>
<span class="sd">            Indices of weights.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        wds : list of float</span>
<span class="sd">            Weight decays for those indices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">wds</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">wd</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">indices</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_dict</span><span class="p">:</span>
                <span class="n">wds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_dict</span><span class="p">[</span><span class="n">index</span><span class="p">]</span><span class="o">.</span><span class="n">wd_mult</span>
            <span class="k">elif</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">wd_mult</span><span class="p">:</span>
                <span class="n">wds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wd_mult</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx2name</span><span class="p">:</span>
                <span class="n">wds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wd_mult</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx2name</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">wds</span>

    <span class="k">def</span> <span class="nf">_get_wd</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Gets weight decay for index.</span>
<span class="sd">        Returns 0 for non-weights if the name of weights are provided for `__init__`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        index : int</span>
<span class="sd">            The index of weight.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        wd : float</span>
<span class="sd">            Weight decay for this index.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wds</span><span class="p">([</span><span class="n">index</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1"># do not include param_dict in the state</span>
        <span class="k">del</span> <span class="n">ret</span><span class="p">[</span><span class="s1">&#39;param_dict&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">ret</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span> <span class="o">=</span> <span class="n">state</span>
        <span class="c1"># param_dict needs to be explicitly set by the trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_dict</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># convenience wrapper for Optimizer.Register</span>
<span class="n">register</span> <span class="o">=</span> <span class="n">Optimizer</span><span class="o">.</span><span class="n">register</span>   <span class="c1"># pylint: disable=invalid-name</span>

<span class="c1"># pylint: disable=line-too-long</span>
<span class="nd">@register</span>
<span class="k">class</span> <span class="nc">SGD</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The SGD optimizer with momentum and weight decay.</span>

<span class="sd">    If the storage types of grad is ``row_sparse`` and ``lazy_update`` is True, \</span>
<span class="sd">    **lazy updates** are applied by::</span>

<span class="sd">        for row in grad.indices:</span>
<span class="sd">            rescaled_grad[row] = lr * (rescale_grad * clip(grad[row], clip_gradient) + wd * weight[row])</span>
<span class="sd">            state[row] = momentum[row] * state[row] + rescaled_grad[row]</span>
<span class="sd">            weight[row] = weight[row] - state[row]</span>

<span class="sd">    The sparse update only updates the momentum for the weights whose row_sparse</span>
<span class="sd">    gradient indices appear in the current batch, rather than updating it for all</span>
<span class="sd">    indices. Compared with the original update, it can provide large</span>
<span class="sd">    improvements in model training throughput for some applications. However, it</span>
<span class="sd">    provides slightly different semantics than the original update, and</span>
<span class="sd">    may lead to different empirical results.</span>

<span class="sd">    In the case when ``update_on_kvstore`` is set to False (either globally via</span>
<span class="sd">    MXNET_UPDATE_ON_KVSTORE=0 environment variable or as a parameter in</span>
<span class="sd">    :class:`~mxnet.gluon.Trainer`) SGD optimizer can perform aggregated update</span>
<span class="sd">    of parameters, which may lead to improved performance. The aggregation size</span>
<span class="sd">    is controlled by MXNET_OPTIMIZER_AGGREGATION_SIZE environment variable and</span>
<span class="sd">    defaults to 4.</span>

<span class="sd">    Otherwise, **standard updates** are applied by::</span>

<span class="sd">        rescaled_grad = lr * (rescale_grad * clip(grad, clip_gradient) + wd * weight)</span>
<span class="sd">        state = momentum * state + rescaled_grad</span>
<span class="sd">        weight = weight - state</span>

<span class="sd">    For details of the update algorithm see</span>
<span class="sd">    :class:`~mxnet.ndarray.sgd_update` and :class:`~mxnet.ndarray.sgd_mom_update`.</span>

<span class="sd">    This optimizer accepts the following parameters in addition to those accepted</span>
<span class="sd">    by :class:`.Optimizer`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    momentum : float, optional</span>
<span class="sd">        The momentum value.</span>
<span class="sd">    lazy_update : bool, optional</span>
<span class="sd">        Default is True. If True, lazy updates are applied \</span>
<span class="sd">        if the storage types of weight and grad are both ``row_sparse``.</span>
<span class="sd">    multi_precision: bool, optional</span>
<span class="sd">        Flag to control the internal precision of the optimizer.</span>
<span class="sd">        False: results in using the same precision as the weights (default),</span>
<span class="sd">        True: makes internal 32-bit copy of the weights and applies gradients</span>
<span class="sd">        in 32-bit precision even if actual weights used in the model have lower precision.</span>
<span class="sd">        Turning this on can improve convergence and accuracy when training with float16.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">lazy_update</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SGD</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lazy_update</span> <span class="o">=</span> <span class="n">lazy_update</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_num</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;MXNET_OPTIMIZER_AGGREGATION_SIZE&#39;</span><span class="p">,</span> <span class="s2">&quot;4&quot;</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">create_state_multi_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="n">weight_master_copy</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_precision</span> <span class="ow">and</span> <span class="n">weight</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float16</span><span class="p">:</span>
            <span class="n">weight_master_copy</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_state</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight_master_copy</span><span class="p">),</span> <span class="n">weight_master_copy</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">weight</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float16</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_precision</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Accumulating with float16 in optimizer can lead to &quot;</span>
                          <span class="s2">&quot;poor accuracy or slow convergence. &quot;</span>
                          <span class="s2">&quot;Consider using multi_precision=True option of the &quot;</span>
                          <span class="s2">&quot;SGD optimizer&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_state</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="n">momentum</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">stype</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">stype</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lazy_update</span> <span class="k">else</span> <span class="s1">&#39;default&#39;</span>
            <span class="n">momentum</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="n">stype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">momentum</span>

    <span class="k">def</span> <span class="nf">_update_impl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">multi_precision</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">aggregate</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">indices</span><span class="p">]</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">weights</span><span class="p">]</span>
            <span class="n">grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">grads</span><span class="p">]</span>
            <span class="n">states</span> <span class="o">=</span> <span class="p">[</span><span class="n">states</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
            <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
            <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
            <span class="n">aggregate</span> <span class="o">=</span> <span class="p">(</span><span class="n">aggregate</span> <span class="ow">and</span>
                         <span class="n">weight</span><span class="o">.</span><span class="n">stype</span> <span class="o">==</span> <span class="s1">&#39;default&#39;</span> <span class="ow">and</span>
                         <span class="n">grad</span><span class="o">.</span><span class="n">stype</span> <span class="o">==</span> <span class="s1">&#39;default&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_count</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        <span class="n">lrs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lrs</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        <span class="n">wds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wds</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>

        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;rescale_grad&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span><span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;momentum&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;clip_gradient&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span>

        <span class="k">if</span> <span class="n">aggregate</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">multi_precision</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">multi_sgd_mom_update</span><span class="p">(</span><span class="o">*</span><span class="n">_flatten_list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">states</span><span class="p">)),</span> <span class="n">out</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
                                         <span class="n">num_weights</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span> <span class="n">lrs</span><span class="o">=</span><span class="n">lrs</span><span class="p">,</span> <span class="n">wds</span><span class="o">=</span><span class="n">wds</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">multi_sgd_update</span><span class="p">(</span><span class="o">*</span><span class="n">_flatten_list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">grads</span><span class="p">)),</span> <span class="n">out</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span>
                                     <span class="n">num_weights</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span> <span class="n">lrs</span><span class="o">=</span><span class="n">lrs</span><span class="p">,</span> <span class="n">wds</span><span class="o">=</span><span class="n">wds</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">multi_mp_sgd_mom_update</span><span class="p">(</span><span class="o">*</span><span class="n">_flatten_list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="o">*</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">states</span><span class="p">))),</span>
                                            <span class="n">out</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">num_weights</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span>
                                            <span class="n">lrs</span><span class="o">=</span><span class="n">lrs</span><span class="p">,</span> <span class="n">wds</span><span class="o">=</span><span class="n">wds</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">multi_mp_sgd_update</span><span class="p">(</span><span class="o">*</span><span class="n">_flatten_list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span>
                                                           <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">states</span><span class="p">))[</span><span class="mi">1</span><span class="p">])),</span>
                                        <span class="n">out</span><span class="o">=</span><span class="n">weights</span><span class="p">,</span> <span class="n">num_weights</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span>
                                        <span class="n">lrs</span><span class="o">=</span><span class="n">lrs</span><span class="p">,</span> <span class="n">wds</span><span class="o">=</span><span class="n">wds</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">wd</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">states</span><span class="p">,</span> <span class="n">lrs</span><span class="p">,</span> <span class="n">wds</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">multi_precision</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">sgd_mom_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
                                       <span class="n">lazy_update</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lazy_update</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">sgd_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">lazy_update</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lazy_update</span><span class="p">,</span>
                                   <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">mp_sgd_mom_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
                                          <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">mp_sgd_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
                                      <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_impl</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">multi_precision</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update_multi_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="n">use_multi_precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_precision</span> <span class="ow">and</span> <span class="n">weight</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float16</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">use_multi_precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_precision</span> <span class="ow">and</span> <span class="n">weight</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float16</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_impl</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span>
                          <span class="n">multi_precision</span><span class="o">=</span><span class="n">use_multi_precision</span><span class="p">)</span>

<span class="nd">@register</span>
<span class="k">class</span> <span class="nc">Signum</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;The Signum optimizer that takes the sign of gradient or momentum.</span>

<span class="sd">    The optimizer updates the weight by::</span>

<span class="sd">        rescaled_grad = rescale_grad * clip(grad, clip_gradient) + wd * weight</span>
<span class="sd">        state = momentum * state + (1-momentum)*rescaled_grad</span>
<span class="sd">        weight = (1 - lr * wd_lh) * weight - lr * sign(state)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Jeremy Bernstein, Yu-Xiang Wang, Kamyar Azizzadenesheli &amp; Anima Anandkumar. (2018).</span>
<span class="sd">    signSGD: Compressed Optimisation for Non-Convex Problems. In ICML&#39;18.</span>

<span class="sd">    See: https://arxiv.org/abs/1802.04434</span>

<span class="sd">    For details of the update algorithm see</span>
<span class="sd">    :class:`~mxnet.ndarray.signsgd_update` and :class:`~mxnet.ndarray.signum_update`.</span>

<span class="sd">    This optimizer accepts the following parameters in addition to those accepted</span>
<span class="sd">    by :class:`.Optimizer`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    momentum : float, optional</span>
<span class="sd">       The momentum value.</span>
<span class="sd">    wd_lh : float, optional</span>
<span class="sd">       The amount of decoupled weight decay regularization, see details in the original paper at:\</span>
<span class="sd">       https://arxiv.org/abs/1711.05101</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">wd_lh</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Signum</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wd_lh</span> <span class="o">=</span> <span class="n">wd_lh</span>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="n">momentum</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">momentum</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">stype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">momentum</span>

    <span class="k">def</span> <span class="nf">_update_impl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_count</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lr</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">wd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wd</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;rescale_grad&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span><span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;momentum&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;clip_gradient&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">wd_lh</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;wd_lh&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wd_lh</span>

        <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">signum_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
                          <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">signsgd_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
                           <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_impl</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>

<div class="viewcode-block" id="FTML"><a class="viewcode-back" href="../../../api/gluon-related/_autogen/mxnet.optimizer.FTML.html#mxnet.optimizer.FTML">[docs]</a><span class="nd">@register</span>
<span class="k">class</span> <span class="nc">FTML</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The FTML optimizer.</span>

<span class="sd">    This class implements the optimizer described in</span>
<span class="sd">    *FTML - Follow the Moving Leader in Deep Learning*,</span>
<span class="sd">    available at http://proceedings.mlr.press/v70/zheng17a/zheng17a.pdf.</span>

<span class="sd">    Denote time step by t. The optimizer updates the weight by::</span>

<span class="sd">        rescaled_grad = clip(grad * rescale_grad + wd * weight, clip_gradient)</span>
<span class="sd">        v = beta2 * v + (1 - beta2) * square(rescaled_grad)</span>
<span class="sd">        d_t = (1 - power(beta1, t)) / lr * square_root(v / (1 - power(beta2, t))) + epsilon)</span>
<span class="sd">        z = beta1 * z + (1 - beta1) * rescaled_grad - (d_t - beta1 * d_(t-1)) * weight</span>
<span class="sd">        weight = - z / d_t</span>

<span class="sd">    For details of the update algorithm, see :class:`~mxnet.ndarray.ftml_update`.</span>

<span class="sd">    This optimizer accepts the following parameters in addition to those accepted</span>
<span class="sd">    by :class:`.Optimizer`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    beta1 : float, optional</span>
<span class="sd">        0 &lt; beta1 &lt; 1. Generally close to 0.5.</span>
<span class="sd">    beta2 : float, optional</span>
<span class="sd">        0 &lt; beta2 &lt; 1. Generally close to 1.</span>
<span class="sd">    epsilon : float, optional</span>
<span class="sd">        Small value to avoid division by 0.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="FTML.__init__"><a class="viewcode-back" href="../../../api/gluon-related/_autogen/mxnet.optimizer.FTML.html#mxnet.optimizer.FTML.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FTML</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">=</span> <span class="n">beta1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">=</span> <span class="n">beta2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span></div>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="c1"># d_0</span>
                <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="c1"># v_0</span>
                <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span> <span class="c1"># z_0</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_count</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lr</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">wd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wd</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_index_update_count</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;beta1&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">,</span> <span class="s1">&#39;beta2&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span>
                  <span class="s1">&#39;rescale_grad&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span><span class="p">,</span> <span class="s1">&#39;t&#39;</span><span class="p">:</span> <span class="n">t</span><span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;clip_grad&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span>

        <span class="n">prev_d</span><span class="p">,</span> <span class="n">prev_v</span><span class="p">,</span> <span class="n">prev_z</span> <span class="o">=</span> <span class="n">state</span>
        <span class="n">ftml_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">prev_d</span><span class="p">,</span> <span class="n">prev_v</span><span class="p">,</span> <span class="n">prev_z</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
                    <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<span class="nd">@register</span>
<span class="k">class</span> <span class="nc">LBSGD</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The Large Batch SGD optimizer with momentum and weight decay.</span>

<span class="sd">    The optimizer updates the weight by::</span>

<span class="sd">        state = momentum * state + lr * rescale_grad * clip(grad, clip_gradient) + wd * weight</span>
<span class="sd">        weight = weight - state</span>

<span class="sd">    For details of the update algorithm see :class:`~mxnet.ndarray.sgd_update`</span>
<span class="sd">    and :class:`~mxnet.ndarray.sgd_mom_update`.</span>
<span class="sd">    In addition to the SGD updates the LBSGD optimizer uses the LARS, Layer-wise</span>
<span class="sd">    Adaptive Rate Scaling, algorithm to have a separate learning rate for each</span>
<span class="sd">    layer of the network, which leads to better stability over large batch sizes.</span>

<span class="sd">    This optimizer accepts the following parameters in addition to those accepted</span>
<span class="sd">    by :class:`.Optimizer`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    momentum : float, optional</span>
<span class="sd">        The momentum value.</span>
<span class="sd">    multi_precision: bool, optional</span>
<span class="sd">        Flag to control the internal precision of the optimizer.</span>
<span class="sd">        False: results in using the same precision as the weights (default),</span>
<span class="sd">        True: makes internal 32-bit copy of the weights and applies gradients</span>
<span class="sd">        in 32-bit precision even if actual weights used in the model have lower precision.</span>
<span class="sd">        Turning this on can improve convergence and accuracy when training with float16.</span>

<span class="sd">    warmup_strategy: string (&#39;linear&#39;, &#39;power2&#39;, &#39;sqrt&#39;. , &#39;lars&#39;   default : &#39;linear&#39;)</span>
<span class="sd">    warmup_epochs: unsigned, default: 5</span>
<span class="sd">    batch_scale:   unsigned, default: 1 (same as batch size*numworkers)</span>
<span class="sd">    updates_per_epoch: updates_per_epoch (default: 32, Default might not reflect true number batches per epoch. Used for warmup.)</span>
<span class="sd">    begin_epoch: unsigned, default 0, starting epoch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">multi_precision</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">warmup_strategy</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span>
                 <span class="n">warmup_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">updates_per_epoch</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">begin_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LBSGD</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Running Large-Batch SGD Algorithm&#39;</span><span class="p">)</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;(Batch_scale=</span><span class="si">%f</span><span class="s1">, warmup_epochs=</span><span class="si">%d</span><span class="s1">, warmup_strategy=</span><span class="si">%s</span><span class="s1">, updates_per_epoch=</span><span class="si">%d</span><span class="s1">)&#39;</span><span class="p">,</span>
                     <span class="n">batch_scale</span><span class="p">,</span> <span class="n">warmup_epochs</span><span class="p">,</span> <span class="n">warmup_strategy</span><span class="p">,</span> <span class="n">updates_per_epoch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multi_precision</span> <span class="o">=</span> <span class="n">multi_precision</span>
        <span class="c1"># new user parameters for large batch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warmup_strategy</span> <span class="o">=</span> <span class="n">warmup_strategy</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">warmup_epochs</span> <span class="o">=</span> <span class="n">warmup_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_scale</span> <span class="o">=</span> <span class="n">batch_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">updates_per_epoch</span> <span class="o">=</span> <span class="n">updates_per_epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_updates</span> <span class="o">=</span> <span class="n">begin_epoch</span> <span class="o">*</span> <span class="n">updates_per_epoch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_epochs</span> <span class="o">=</span> <span class="n">num_epochs</span>
        <span class="c1"># addl internal usage parameters and storage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lbmult</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cumgrads</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c1"># for adaptive lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adaptive</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">admult</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># adaptation constant</span>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="n">momentum</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">weight_master_copy</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_precision</span> <span class="ow">and</span> <span class="n">weight</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float16</span><span class="p">:</span>
            <span class="n">weight_master_copy</span> <span class="o">=</span> <span class="n">array</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
                <span class="n">momentum</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                                 <span class="n">stype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">stype</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">momentum</span><span class="p">,</span> <span class="n">weight_master_copy</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">weight</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float16</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_precision</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Accumulating with float16 in optimizer can lead to &quot;</span>
                          <span class="s2">&quot;poor accuracy or slow convergence. &quot;</span>
                          <span class="s2">&quot;Consider using multi_precision=True option of the &quot;</span>
                          <span class="s2">&quot;SGD optimizer&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">momentum</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">stype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">momentum</span>

    <span class="k">def</span> <span class="nf">_get_lbmult</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nup</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns lr scaling factor for large batch according to warmup schedule</span>
<span class="sd">        (to be implemented)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">nwup</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_epochs</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">updates_per_epoch</span>
        <span class="n">strategy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_strategy</span>
        <span class="n">maxmult</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_scale</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">nup</span> <span class="o">&gt;=</span> <span class="n">nwup</span><span class="p">:</span>
            <span class="n">mult</span> <span class="o">=</span> <span class="n">maxmult</span>
        <span class="k">elif</span> <span class="n">nwup</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">mult</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">strategy</span> <span class="o">==</span> <span class="s1">&#39;linear&#39;</span><span class="p">):</span>
                <span class="n">mult</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="p">(</span><span class="n">maxmult</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">nup</span> <span class="o">/</span> <span class="n">nwup</span>
            <span class="k">elif</span> <span class="p">(</span><span class="n">strategy</span> <span class="o">==</span> <span class="s1">&#39;power2&#39;</span><span class="p">):</span>
                <span class="n">mult</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="p">(</span><span class="n">maxmult</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">nup</span><span class="o">*</span><span class="n">nup</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">nwup</span><span class="o">*</span><span class="n">nwup</span><span class="p">)</span>
            <span class="k">elif</span> <span class="p">(</span><span class="n">strategy</span> <span class="o">==</span> <span class="s1">&#39;sqrt&#39;</span><span class="p">):</span>
                <span class="n">mult</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">+</span> <span class="p">(</span><span class="n">maxmult</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">nup</span><span class="p">)</span> <span class="o">/</span> <span class="n">nwup</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">mult</span> <span class="o">=</span> <span class="mf">1.0</span>
        <span class="k">return</span> <span class="n">mult</span>

    <span class="k">def</span> <span class="nf">_get_lars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">wd</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a scaling factor for the learning rate for this layer</span>
<span class="sd">        default is 1</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">weight2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_l2norm</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">grad2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_l2norm</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
        <span class="n">lars</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">weight2</span> <span class="o">/</span> <span class="p">(</span><span class="n">grad2</span> <span class="o">+</span> <span class="n">wd</span> <span class="o">*</span> <span class="n">weight2</span> <span class="o">+</span> <span class="mf">1e-18</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">lars</span> <span class="o">&lt;</span> <span class="mf">0.01</span><span class="p">:</span>
            <span class="n">lars</span> <span class="o">=</span> <span class="mf">0.01</span>
        <span class="k">elif</span> <span class="n">lars</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">:</span>
            <span class="n">lars</span> <span class="o">=</span> <span class="mi">100</span>
        <span class="k">return</span> <span class="n">lars</span>

    <span class="k">def</span> <span class="nf">_l2norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="s2">&quot;inner product implementation&quot;</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">multiply</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">norm</span>

    <span class="k">def</span> <span class="nf">_reset_cum_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="s2">&quot;called every macro-batch to reset cumulated gradients to 0 for a given index&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cumgrads</span><span class="p">[</span><span class="n">index</span><span class="p">][</span><span class="s1">&#39;cum_grad&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">_get_cum_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="s2">&quot;get the cumulated gradient for index&quot;</span>
        <span class="k">if</span> <span class="n">index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cumgrads</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cumgrads</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">_put_cum_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">cgrad</span><span class="p">):</span>
        <span class="s2">&quot;store cumulated gradient for index&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cumgrads</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">cgrad</span>

    <span class="k">def</span> <span class="nf">_cumulate_gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="s2">&quot;Cumulate gradients for large-batch emulation. Cumulated by index (layer)&quot;</span>
        <span class="n">cgrad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_cum_gradient</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cgrad</span><span class="p">:</span>
            <span class="n">num_cums</span> <span class="o">=</span> <span class="n">cgrad</span><span class="p">[</span><span class="s1">&#39;num_cums&#39;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">num_cums</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">cum_grad</span> <span class="o">=</span> <span class="n">cgrad</span><span class="p">[</span><span class="s1">&#39;cum_grad&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">grad</span>
                <span class="n">num_cums</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">cum_grad</span> <span class="o">=</span> <span class="n">grad</span>
                <span class="n">num_cums</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_updates</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cum_grad</span> <span class="o">=</span> <span class="n">grad</span>
            <span class="n">num_cums</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_updates</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">cgrad</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;cum_grad&#39;</span><span class="p">:</span> <span class="n">cum_grad</span><span class="p">,</span> <span class="s1">&#39;num_cums&#39;</span><span class="p">:</span> <span class="n">num_cums</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_put_cum_gradient</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">cgrad</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cgrad</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">assert</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="k">assert</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>

        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lr</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">wd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wd</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_count</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

        <span class="c1"># new stuff for large batch</span>
        <span class="n">cgrad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cumulate_gradient</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">cgrad</span><span class="p">[</span><span class="s1">&#39;num_cums&#39;</span><span class="p">]</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_scale</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">cgrad</span><span class="p">[</span><span class="s1">&#39;cum_grad&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_scale</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">warmup_strategy</span> <span class="o">==</span> <span class="s1">&#39;lars&#39;</span><span class="p">:</span>
                <span class="n">lbmult</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lars</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">wd</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">lbmult</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lbmult</span><span class="p">(</span><span class="n">cgrad</span><span class="p">[</span><span class="s1">&#39;num_cums&#39;</span><span class="p">])</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">lbmult</span>
            <span class="c1"># do the regular sgd update flow</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;rescale_grad&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span><span class="p">}</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;momentum&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">:</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;clip_gradient&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span>
            <span class="n">use_multi_precision</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">use_multi_precision</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">sgd_mom_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">sgd_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">mp_sgd_mom_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span>
                                      <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">mp_sgd_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="c1"># reset update count and cumulated gradient per large batch</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_reset_cum_gradient</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">sgd_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="c1"># pylint: enable=line-too-long</span>
<div class="viewcode-block" id="DCASGD"><a class="viewcode-back" href="../../../api/gluon-related/_autogen/mxnet.optimizer.DCASGD.html#mxnet.optimizer.DCASGD">[docs]</a><span class="nd">@register</span>
<span class="k">class</span> <span class="nc">DCASGD</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The DCASGD optimizer.</span>

<span class="sd">    This class implements the optimizer described in *Asynchronous Stochastic Gradient Descent</span>
<span class="sd">    with Delay Compensation for Distributed Deep Learning*,</span>
<span class="sd">    available at https://arxiv.org/abs/1609.08326.</span>

<span class="sd">    This optimizer accepts the following parameters in addition to those accepted</span>
<span class="sd">    by :class:`.Optimizer`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    momentum : float, optional</span>
<span class="sd">       The momentum value.</span>

<span class="sd">    lamda : float, optional</span>
<span class="sd">       Scale DC value.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="DCASGD.__init__"><a class="viewcode-back" href="../../../api/gluon-related/_autogen/mxnet.optimizer.DCASGD.html#mxnet.optimizer.DCASGD.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">lamda</span><span class="o">=</span><span class="mf">0.04</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DCASGD</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_previous</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lamda</span> <span class="o">=</span> <span class="n">lamda</span></div>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span>
                    <span class="n">weight</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>  <span class="c1"># previous weight</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="c1"># momentum</span>
                    <span class="n">weight</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>  <span class="c1"># previous weight</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_count</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lr</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">wd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wd</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

        <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">clip</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">)</span>

        <span class="n">mom</span><span class="p">,</span> <span class="n">previous_weight</span> <span class="o">=</span> <span class="n">state</span>
        <span class="k">if</span> <span class="n">mom</span><span class="p">:</span>
            <span class="n">mom</span><span class="p">[:]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span>
            <span class="n">mom</span><span class="p">[:]</span> <span class="o">+=</span> <span class="o">-</span><span class="n">lr</span> <span class="o">*</span> <span class="p">(</span><span class="n">grad</span> <span class="o">+</span> <span class="n">wd</span> <span class="o">*</span> <span class="n">weight</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">lamda</span> \
                             <span class="o">*</span> <span class="n">grad</span> <span class="o">*</span> <span class="n">grad</span> <span class="o">*</span> <span class="p">(</span><span class="n">weight</span> <span class="o">-</span> <span class="n">previous_weight</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="n">mom</span> <span class="o">=</span> <span class="o">-</span><span class="n">lr</span> <span class="o">*</span> <span class="p">(</span><span class="n">grad</span> <span class="o">+</span> <span class="n">wd</span> <span class="o">*</span> <span class="n">weight</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">lamda</span> \
                         <span class="o">*</span> <span class="n">grad</span> <span class="o">*</span> <span class="n">grad</span> <span class="o">*</span> <span class="p">(</span><span class="n">weight</span> <span class="o">-</span> <span class="n">previous_weight</span><span class="p">))</span>
        <span class="n">previous_weight</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">weight</span>
        <span class="n">weight</span><span class="p">[:]</span> <span class="o">+=</span> <span class="n">mom</span></div>

<span class="nd">@register</span>
<span class="k">class</span> <span class="nc">NAG</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Nesterov accelerated gradient.</span>

<span class="sd">    This optimizer updates each weight by::</span>

<span class="sd">        state = momentum * state + grad + wd * weight</span>
<span class="sd">        weight = weight - (lr * (grad + momentum * state))</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    momentum : float, optional</span>
<span class="sd">       The momentum value.</span>
<span class="sd">    multi_precision: bool, optional</span>
<span class="sd">        Flag to control the internal precision of the optimizer.</span>
<span class="sd">        False: results in using the same precision as the weights (default),</span>
<span class="sd">        True: makes internal 32-bit copy of the weights and applies gradients</span>
<span class="sd">        in 32-bit precision even if actual weights used in the model have lower precision.</span>
<span class="sd">        Turning this on can improve convergence and accuracy when training with float16.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">NAG</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">=</span> <span class="n">momentum</span>

    <span class="k">def</span> <span class="nf">create_state_multi_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="n">weight_master_copy</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_precision</span> <span class="ow">and</span> <span class="n">weight</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float16</span><span class="p">:</span>
            <span class="n">weight_master_copy</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">create_state</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight_master_copy</span><span class="p">),</span> <span class="n">weight_master_copy</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">weight</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float16</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_precision</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Accumulating with float16 in optimizer can lead to &quot;</span>
                          <span class="s2">&quot;poor accuracy or slow convergence. &quot;</span>
                          <span class="s2">&quot;Consider using multi_precision=True option of the &quot;</span>
                          <span class="s2">&quot;NAG optimizer&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_state</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="n">momentum</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">momentum</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">momentum</span>

    <span class="k">def</span> <span class="nf">_update_impl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">multi_precision</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_count</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lr</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">wd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wd</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;rescale_grad&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span><span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;momentum&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">momentum</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;clip_gradient&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">multi_precision</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">nag_mom_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">sgd_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">mp_nag_mom_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
                                  <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">mp_sgd_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
                              <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_impl</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">multi_precision</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update_multi_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">use_multi_precision</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_precision</span> <span class="ow">and</span> <span class="n">weight</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float16</span> \
                                <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_impl</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span>
                          <span class="n">multi_precision</span><span class="o">=</span><span class="n">use_multi_precision</span><span class="p">)</span>


<span class="nd">@register</span>
<span class="k">class</span> <span class="nc">SGLD</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Stochastic Gradient Riemannian Langevin Dynamics.</span>

<span class="sd">    This class implements the optimizer described in the paper *Stochastic Gradient</span>
<span class="sd">    Riemannian Langevin Dynamics on the Probability Simplex*, available at</span>
<span class="sd">    https://papers.nips.cc/paper/4883-stochastic-gradient-riemannian-langevin-dynamics-on-the-probability-simplex.pdf.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SGLD</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_count</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lr</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">wd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wd</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

        <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">clip</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">)</span>
        <span class="n">weight</span><span class="p">[:]</span> <span class="o">+=</span> <span class="o">-</span> <span class="n">lr</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">grad</span> <span class="o">+</span> <span class="n">wd</span> <span class="o">*</span> <span class="n">weight</span><span class="p">)</span>
        <span class="n">weight</span><span class="p">[:]</span> <span class="o">+=</span> <span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">lr</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                            <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">ctx</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>



<span class="nd">@register</span>  <span class="c1"># pylint: disable=invalid-name</span>
<span class="k">class</span> <span class="nc">ccSGD</span><span class="p">(</span><span class="n">SGD</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;[DEPRECATED] Same as `SGD`. Left here for backward compatibility.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ccSGD</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="Adam"><a class="viewcode-back" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Adam.html#mxnet.optimizer.Adam">[docs]</a><span class="nd">@register</span>
<span class="k">class</span> <span class="nc">Adam</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The Adam optimizer.</span>

<span class="sd">    This class implements the optimizer described in *Adam: A Method for</span>
<span class="sd">    Stochastic Optimization*, available at http://arxiv.org/abs/1412.6980.</span>

<span class="sd">    If the storage types of grad is ``row_sparse``, and ``lazy_update`` is True, \</span>
<span class="sd">    **lazy updates** at step t are applied by::</span>

<span class="sd">        for row in grad.indices:</span>
<span class="sd">            rescaled_grad[row] = clip(grad[row] * rescale_grad + wd * weight[row], clip_gradient)</span>
<span class="sd">            m[row] = beta1 * m[row] + (1 - beta1) * rescaled_grad[row]</span>
<span class="sd">            v[row] = beta2 * v[row] + (1 - beta2) * (rescaled_grad[row]**2)</span>
<span class="sd">            lr = learning_rate * sqrt(1 - beta1**t) / (1 - beta2**t)</span>
<span class="sd">            w[row] = w[row] - lr * m[row] / (sqrt(v[row]) + epsilon)</span>

<span class="sd">    The lazy update only updates the mean and var for the weights whose row_sparse</span>
<span class="sd">    gradient indices appear in the current batch, rather than updating it for all indices.</span>
<span class="sd">    Compared with the original update, it can provide large improvements in model training</span>
<span class="sd">    throughput for some applications. However, it provides slightly different semantics than</span>
<span class="sd">    the original update, and may lead to different empirical results.</span>

<span class="sd">    Otherwise, **standard updates** at step t are applied by::</span>

<span class="sd">        rescaled_grad = clip(grad * rescale_grad + wd * weight, clip_gradient)</span>
<span class="sd">        m = beta1 * m + (1 - beta1) * rescaled_grad</span>
<span class="sd">        v = beta2 * v + (1 - beta2) * (rescaled_grad**2)</span>
<span class="sd">        lr = learning_rate * sqrt(1 - beta1**t) / (1 - beta2**t)</span>
<span class="sd">        w = w - lr * m / (sqrt(v) + epsilon)</span>

<span class="sd">    This optimizer accepts the following parameters in addition to those accepted</span>
<span class="sd">    by :class:`.Optimizer`.</span>

<span class="sd">    For details of the update algorithm, see :class:`~mxnet.ndarray.adam_update`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    beta1 : float, optional</span>
<span class="sd">        Exponential decay rate for the first moment estimates.</span>
<span class="sd">    beta2 : float, optional</span>
<span class="sd">        Exponential decay rate for the second moment estimates.</span>
<span class="sd">    epsilon : float, optional</span>
<span class="sd">        Small value to avoid division by 0.</span>
<span class="sd">    lazy_update : bool, optional</span>
<span class="sd">       Default is True. If True, lazy updates are applied \</span>
<span class="sd">       if the storage types of weight and grad are both ``row_sparse``.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="Adam.__init__"><a class="viewcode-back" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Adam.html#mxnet.optimizer.Adam.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
                 <span class="n">lazy_update</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Adam</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">=</span> <span class="n">beta1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">=</span> <span class="n">beta2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lazy_update</span> <span class="o">=</span> <span class="n">lazy_update</span></div>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="n">stype</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">stype</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lazy_update</span> <span class="k">else</span> <span class="s1">&#39;default&#39;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                      <span class="n">stype</span><span class="o">=</span><span class="n">stype</span><span class="p">),</span>  <span class="c1"># mean</span>
                <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                      <span class="n">stype</span><span class="o">=</span><span class="n">stype</span><span class="p">))</span>  <span class="c1"># variance</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_count</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lr</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">wd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wd</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_index_update_count</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">coef1</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="o">**</span><span class="n">t</span>
        <span class="n">coef2</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="o">**</span><span class="n">t</span>
        <span class="n">lr</span> <span class="o">*=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">coef2</span><span class="p">)</span><span class="o">/</span><span class="n">coef1</span>

        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;beta1&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">,</span> <span class="s1">&#39;beta2&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span>
                  <span class="s1">&#39;rescale_grad&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span><span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;clip_gradient&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span>

        <span class="n">mean</span><span class="p">,</span> <span class="n">var</span> <span class="o">=</span> <span class="n">state</span>
        <span class="n">adam_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
                    <span class="n">lazy_update</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">lazy_update</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<div class="viewcode-block" id="AdaGrad"><a class="viewcode-back" href="../../../api/gluon-related/_autogen/mxnet.optimizer.AdaGrad.html#mxnet.optimizer.AdaGrad">[docs]</a><span class="nd">@register</span>
<span class="k">class</span> <span class="nc">AdaGrad</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;AdaGrad optimizer.</span>

<span class="sd">    This class implements the AdaGrad optimizer described in *Adaptive Subgradient</span>
<span class="sd">    Methods for Online Learning and Stochastic Optimization*, and available at</span>
<span class="sd">    http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf.</span>

<span class="sd">    This optimizer updates each weight by::</span>

<span class="sd">        grad = clip(grad * rescale_grad, clip_gradient)</span>
<span class="sd">        history += square(grad)</span>
<span class="sd">        div = grad / sqrt(history + float_stable_eps)</span>
<span class="sd">        weight += (div + weight * wd) * -lr</span>

<span class="sd">    This optimizer accepts the following parameters in addition to those accepted</span>
<span class="sd">    by :class:`.Optimizer`.</span>

<span class="sd">    See Also</span>
<span class="sd">    ----------</span>
<span class="sd">    :meth:`mxnet.ndarray.sparse.adagrad_update`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    eps: float, optional</span>
<span class="sd">        Initial value of the history accumulator. Avoids division by 0.</span>

<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="AdaGrad.__init__"><a class="viewcode-back" href="../../../api/gluon-related/_autogen/mxnet.optimizer.AdaGrad.html#mxnet.optimizer.AdaGrad.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AdaGrad</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">float_stable_eps</span> <span class="o">=</span> <span class="n">eps</span></div>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">stype</span><span class="p">)</span>  <span class="c1"># history</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_count</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lr</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">wd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wd</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

        <span class="n">is_sparse</span> <span class="o">=</span> <span class="n">grad</span><span class="o">.</span><span class="n">stype</span> <span class="o">==</span> <span class="s1">&#39;row_sparse&#39;</span>
        <span class="n">history</span> <span class="o">=</span> <span class="n">state</span>

        <span class="k">if</span> <span class="n">is_sparse</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">float_stable_eps</span><span class="p">,</span>
                      <span class="s1">&#39;rescale_grad&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span><span class="p">}</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">:</span>
                <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;clip_gradient&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span>
            <span class="n">sparse</span><span class="o">.</span><span class="n">adagrad_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">grad</span> <span class="o">=</span> <span class="n">clip</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">)</span>
            <span class="n">history</span><span class="p">[:]</span> <span class="o">+=</span> <span class="n">square</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
            <span class="n">div</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">history</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">float_stable_eps</span><span class="p">)</span>
            <span class="n">weight</span><span class="p">[:]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">div</span> <span class="o">+</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">wd</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="n">lr</span></div>

<span class="nd">@register</span>
<span class="k">class</span> <span class="nc">RMSProp</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The RMSProp optimizer.</span>

<span class="sd">    Two versions of RMSProp are implemented:</span>

<span class="sd">    If ``centered=False``, we follow</span>
<span class="sd">    http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf by</span>
<span class="sd">    Tieleman &amp; Hinton, 2012.</span>
<span class="sd">    For details of the update algorithm see :class:`~mxnet.ndarray.rmsprop_update`.</span>

<span class="sd">    If ``centered=True``, we follow http://arxiv.org/pdf/1308.0850v5.pdf (38)-(45)</span>
<span class="sd">    by Alex Graves, 2013.</span>
<span class="sd">    For details of the update algorithm see :class:`~mxnet.ndarray.rmspropalex_update`.</span>

<span class="sd">    This optimizer accepts the following parameters in addition to those accepted</span>
<span class="sd">    by :class:`.Optimizer`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    gamma1: float, optional</span>
<span class="sd">        A decay factor of moving average over past squared gradient.</span>
<span class="sd">    gamma2: float, optional</span>
<span class="sd">        A &quot;momentum&quot; factor. Only used if `centered`=``True``.</span>
<span class="sd">    epsilon : float, optional</span>
<span class="sd">        Small value to avoid division by 0.</span>
<span class="sd">    centered : bool, optional</span>
<span class="sd">        Flag to control which version of RMSProp to use.::</span>

<span class="sd">            True: will use Graves&#39;s version of `RMSProp`,</span>
<span class="sd">            False: will use Tieleman &amp; Hinton&#39;s version of `RMSProp`.</span>

<span class="sd">    clip_weights : float, optional</span>
<span class="sd">        Clips weights into range ``[-clip_weights, clip_weights]``.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">gamma1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">gamma2</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                 <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span> <span class="n">centered</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">clip_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RMSProp</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma1</span> <span class="o">=</span> <span class="n">gamma1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma2</span> <span class="o">=</span> <span class="n">gamma2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">centered</span> <span class="o">=</span> <span class="n">centered</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clip_weights</span> <span class="o">=</span> <span class="n">clip_weights</span>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">centered</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">stype</span><span class="p">),</span>  <span class="c1"># n</span>
                <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">stype</span><span class="p">),</span>  <span class="c1"># g</span>
                <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">stype</span><span class="p">))</span>  <span class="c1"># delta</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">stype</span><span class="p">),)</span>  <span class="c1"># n</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_count</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lr</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">wd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wd</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;gamma1&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma1</span><span class="p">,</span> <span class="s1">&#39;epsilon&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">,</span>
                  <span class="s1">&#39;rescale_grad&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span><span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">centered</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;gamma2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma2</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;clip_gradient&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_weights</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;clip_weights&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_weights</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">centered</span><span class="p">:</span>
            <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="p">)</span> <span class="o">=</span> <span class="n">state</span>
            <span class="n">rmsprop_update</span><span class="p">(</span>
                <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">delta</span> <span class="o">=</span> <span class="n">state</span>
            <span class="n">rmspropalex_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
                               <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="AdaDelta"><a class="viewcode-back" href="../../../api/gluon-related/_autogen/mxnet.optimizer.AdaDelta.html#mxnet.optimizer.AdaDelta">[docs]</a><span class="nd">@register</span>
<span class="k">class</span> <span class="nc">AdaDelta</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The AdaDelta optimizer.</span>

<span class="sd">    This class implements AdaDelta, an optimizer described in  *ADADELTA: An adaptive</span>
<span class="sd">    learning rate method*, available at https://arxiv.org/abs/1212.5701.</span>

<span class="sd">    This optimizer updates each weight by::</span>

<span class="sd">        grad = clip(grad * rescale_grad + wd * weight, clip_gradient)</span>
<span class="sd">        acc_grad = rho * acc_grad + (1. - rho) * grad * grad</span>
<span class="sd">        delta = sqrt(acc_delta + epsilon) / sqrt(acc_grad + epsilon) * grad</span>
<span class="sd">        acc_delta = rho * acc_delta + (1. - rho) * delta * delta</span>
<span class="sd">        weight -= (delta + wd * weight)</span>

<span class="sd">    This optimizer accepts the following parameters in addition to those accepted</span>
<span class="sd">    by :class:`.Optimizer`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    rho: float</span>
<span class="sd">        Decay rate for both squared gradients and delta.</span>
<span class="sd">    epsilon : float</span>
<span class="sd">        Small value to avoid division by 0.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="AdaDelta.__init__"><a class="viewcode-back" href="../../../api/gluon-related/_autogen/mxnet.optimizer.AdaDelta.html#mxnet.optimizer.AdaDelta.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rho</span><span class="o">=</span><span class="mf">0.90</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AdaDelta</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rho</span> <span class="o">=</span> <span class="n">rho</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span></div>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">),</span>  <span class="c1"># accumulated g</span>
                <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">))</span>  <span class="c1"># accumulated delta</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="n">wd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wd</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_count</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

        <span class="c1"># preprocess grad</span>
        <span class="n">grad</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">clip</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">)</span>

        <span class="c1"># accumulated g and delta initlization</span>
        <span class="n">acc_g</span><span class="p">,</span> <span class="n">acc_delta</span> <span class="o">=</span> <span class="n">state</span>

        <span class="c1"># update g, delta</span>
        <span class="n">acc_g</span><span class="p">[:]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho</span>
        <span class="n">acc_g</span><span class="p">[:]</span> <span class="o">+=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="n">current_delta</span> <span class="o">=</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">acc_delta</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="n">acc_g</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="n">acc_delta</span><span class="p">[:]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho</span>
        <span class="n">acc_delta</span><span class="p">[:]</span> <span class="o">+=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho</span><span class="p">)</span> <span class="o">*</span> <span class="n">current_delta</span> <span class="o">*</span> <span class="n">current_delta</span>

        <span class="c1"># update weight</span>
        <span class="n">weight</span><span class="p">[:]</span> <span class="o">-=</span> <span class="n">current_delta</span> <span class="o">+</span> <span class="n">wd</span> <span class="o">*</span> <span class="n">weight</span></div>

<span class="c1">#pylint: disable=invalid-name</span>
<span class="c1">#pylint: disable=line-too-long</span>
<div class="viewcode-block" id="Ftrl"><a class="viewcode-back" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Ftrl.html#mxnet.optimizer.Ftrl">[docs]</a><span class="nd">@register</span>
<span class="k">class</span> <span class="nc">Ftrl</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The Ftrl optimizer.</span>

<span class="sd">    Referenced from *Ad Click Prediction: a View from the Trenches*, available at</span>
<span class="sd">    http://dl.acm.org/citation.cfm?id=2488200.</span>

<span class="sd">    eta :</span>
<span class="sd">        .. math::</span>
<span class="sd">           \\eta_{t,i} = \\frac{learningrate}{\\beta+\\sqrt{\\sum_{s=1}^tg_{s,i}^2}}</span>

<span class="sd">    The optimizer updates the weight by::</span>

<span class="sd">        rescaled_grad = clip(grad * rescale_grad, clip_gradient)</span>
<span class="sd">        z += rescaled_grad - (sqrt(n + rescaled_grad**2) - sqrt(n)) * weight / learning_rate</span>
<span class="sd">        n += rescaled_grad**2</span>
<span class="sd">        w = (sign(z) * lamda1 - z) / ((beta + sqrt(n)) / learning_rate + wd) * (abs(z) &gt; lamda1)</span>

<span class="sd">    If the storage types of weight, state and grad are all ``row_sparse``, \</span>
<span class="sd">    **sparse updates** are applied by::</span>

<span class="sd">        for row in grad.indices:</span>
<span class="sd">            rescaled_grad[row] = clip(grad[row] * rescale_grad, clip_gradient)</span>
<span class="sd">            z[row] += rescaled_grad[row] - (sqrt(n[row] + rescaled_grad[row]**2) - sqrt(n[row])) * weight[row] / learning_rate</span>
<span class="sd">            n[row] += rescaled_grad[row]**2</span>
<span class="sd">            w[row] = (sign(z[row]) * lamda1 - z[row]) / ((beta + sqrt(n[row])) / learning_rate + wd) * (abs(z[row]) &gt; lamda1)</span>

<span class="sd">    The sparse update only updates the z and n for the weights whose row_sparse</span>
<span class="sd">    gradient indices appear in the current batch, rather than updating it for all</span>
<span class="sd">    indices. Compared with the original update, it can provide large</span>
<span class="sd">    improvements in model training throughput for some applications. However, it</span>
<span class="sd">    provides slightly different semantics than the original update, and</span>
<span class="sd">    may lead to different empirical results.</span>

<span class="sd">    For details of the update algorithm, see :class:`~mxnet.ndarray.ftrl_update`.</span>

<span class="sd">    This optimizer accepts the following parameters in addition to those accepted</span>
<span class="sd">    by :class:`.Optimizer`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lamda1 : float, optional</span>
<span class="sd">        L1 regularization coefficient.</span>
<span class="sd">    learning_rate : float, optional</span>
<span class="sd">        The initial learning rate.</span>
<span class="sd">    beta : float, optional</span>
<span class="sd">        Per-coordinate learning rate correlation parameter.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Ftrl.__init__"><a class="viewcode-back" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Ftrl.html#mxnet.optimizer.Ftrl.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lamda1</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Ftrl</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lamda1</span> <span class="o">=</span> <span class="n">lamda1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span></div>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">stype</span><span class="p">),</span>  <span class="c1"># z</span>
                <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">stype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">stype</span><span class="p">))</span>  <span class="c1"># n</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_count</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">wd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wd</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lr</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;lamda1&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">lamda1</span><span class="p">,</span> <span class="s1">&#39;beta&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="s1">&#39;rescale_grad&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span><span class="p">}</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">:</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;clip_gradient&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span>

        <span class="c1"># accumulated g and delta initialization</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">state</span>
        <span class="n">ftrl_update</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">weight</span><span class="p">,</span>
                    <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="o">=</span><span class="n">wd</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<span class="c1"># pylint: enable=line-too-long</span>
<div class="viewcode-block" id="Adamax"><a class="viewcode-back" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Adamax.html#mxnet.optimizer.Adamax">[docs]</a><span class="nd">@register</span>
<span class="k">class</span> <span class="nc">Adamax</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The AdaMax optimizer.</span>

<span class="sd">    It is a variant of Adam based on the infinity norm</span>
<span class="sd">    available at http://arxiv.org/abs/1412.6980 Section 7.</span>

<span class="sd">    The optimizer updates the weight by::</span>

<span class="sd">        grad = clip(grad * rescale_grad + wd * weight, clip_gradient)</span>
<span class="sd">        m = beta1 * m_t + (1 - beta1) * grad</span>
<span class="sd">        u = maximum(beta2 * u, abs(grad))</span>
<span class="sd">        weight -= lr / (1 - beta1**t) * m / u</span>

<span class="sd">    This optimizer accepts the following parameters in addition to those accepted</span>
<span class="sd">    by :class:`.Optimizer`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    beta1 : float, optional</span>
<span class="sd">        Exponential decay rate for the first moment estimates.</span>
<span class="sd">    beta2 : float, optional</span>
<span class="sd">        Exponential decay rate for the second moment estimates.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="Adamax.__init__"><a class="viewcode-back" href="../../../api/gluon-related/_autogen/mxnet.optimizer.Adamax.html#mxnet.optimizer.Adamax.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.002</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Adamax</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">=</span> <span class="n">beta1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">=</span> <span class="n">beta2</span></div>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>  <span class="c1"># mean</span>
                <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>  <span class="c1"># variance</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_count</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lr</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">wd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wd</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_index_update_count</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">lr</span> <span class="o">/=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="o">**</span><span class="n">t</span><span class="p">)</span>

        <span class="c1"># preprocess grad</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span> <span class="o">+</span> <span class="n">wd</span> <span class="o">*</span> <span class="n">weight</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">clip</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">)</span>

        <span class="c1"># update m_t and u_t</span>
        <span class="n">m_t</span><span class="p">,</span> <span class="n">u_t</span> <span class="o">=</span> <span class="n">state</span>
        <span class="n">m_t</span><span class="p">[:]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span>
        <span class="n">m_t</span><span class="p">[:]</span> <span class="o">+=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="n">u_t</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">maximum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">*</span> <span class="n">u_t</span><span class="p">,</span> <span class="n">NDabs</span><span class="p">(</span><span class="n">grad</span><span class="p">))</span>

        <span class="c1"># update weight</span>
        <span class="n">weight</span><span class="p">[:]</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">m_t</span> <span class="o">/</span> <span class="n">u_t</span></div>

<span class="nd">@register</span>
<span class="k">class</span> <span class="nc">Nadam</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The Nesterov Adam optimizer.</span>

<span class="sd">    Much like Adam is essentially RMSprop with momentum,</span>
<span class="sd">    Nadam is Adam RMSprop with Nesterov momentum available</span>
<span class="sd">    at http://cs229.stanford.edu/proj2015/054_report.pdf.</span>

<span class="sd">    This optimizer accepts the following parameters in addition to those accepted</span>
<span class="sd">    by :class:`.Optimizer`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    beta1 : float, optional</span>
<span class="sd">        Exponential decay rate for the first moment estimates.</span>
<span class="sd">    beta2 : float, optional</span>
<span class="sd">        Exponential decay rate for the second moment estimates.</span>
<span class="sd">    epsilon : float, optional</span>
<span class="sd">        Small value to avoid division by 0.</span>
<span class="sd">    schedule_decay : float, optional</span>
<span class="sd">        Exponential decay rate for the momentum schedule</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">,</span>
                 <span class="n">schedule_decay</span><span class="o">=</span><span class="mf">0.004</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Nadam</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">=</span> <span class="n">beta1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span> <span class="o">=</span> <span class="n">beta2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">schedule_decay</span> <span class="o">=</span> <span class="n">schedule_decay</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m_schedule</span> <span class="o">=</span> <span class="mf">1.</span>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>  <span class="c1"># mean</span>
                <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>  <span class="c1"># variance</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_count</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_lr</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
        <span class="n">wd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_wd</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>

        <span class="n">t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_index_update_count</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

        <span class="c1"># preprocess grad</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span> <span class="o">+</span> <span class="n">wd</span> <span class="o">*</span> <span class="n">weight</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">clip</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">clip_gradient</span><span class="p">)</span>

        <span class="c1"># warming momentum schedule</span>
        <span class="n">momentum_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="nb">pow</span><span class="p">(</span><span class="mf">0.96</span><span class="p">,</span> <span class="n">t</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">schedule_decay</span><span class="p">)))</span>
        <span class="n">momentum_t_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="nb">pow</span><span class="p">(</span><span class="mf">0.96</span><span class="p">,</span> <span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">schedule_decay</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m_schedule</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_schedule</span> <span class="o">*</span> <span class="n">momentum_t</span>
        <span class="n">m_schedule_next</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_schedule</span> <span class="o">*</span> <span class="n">momentum_t_1</span>

        <span class="c1"># update m_t and v_t</span>
        <span class="n">m_t</span><span class="p">,</span> <span class="n">v_t</span> <span class="o">=</span> <span class="n">state</span>
        <span class="n">m_t</span><span class="p">[:]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span>
        <span class="n">m_t</span><span class="p">[:]</span> <span class="o">+=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta1</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="n">v_t</span><span class="p">[:]</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span>
        <span class="n">v_t</span><span class="p">[:]</span> <span class="o">+=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad</span> <span class="o">*</span> <span class="n">grad</span>

        <span class="n">grad_prime</span> <span class="o">=</span> <span class="n">grad</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">m_schedule</span><span class="p">)</span>
        <span class="n">m_t_prime</span> <span class="o">=</span> <span class="n">m_t</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">m_schedule_next</span><span class="p">)</span>
        <span class="n">v_t_prime</span> <span class="o">=</span> <span class="n">v_t</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="nb">pow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta2</span><span class="p">,</span> <span class="n">t</span><span class="p">))</span>
        <span class="n">m_t_bar</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">momentum_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad_prime</span> <span class="o">+</span> <span class="n">momentum_t_1</span> <span class="o">*</span> <span class="n">m_t_prime</span>

        <span class="c1"># update weight</span>
        <span class="n">weight</span><span class="p">[:]</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">m_t_bar</span> <span class="o">/</span> <span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_t_prime</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>

<span class="nd">@register</span>
<span class="k">class</span> <span class="nc">Test</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The Test optimizer&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Test</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">create_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Creates a state to duplicate weight.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">zeros</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Performs w += rescale_grad * grad.&quot;&quot;&quot;</span>
        <span class="n">weight</span><span class="p">[:]</span> <span class="o">+=</span> <span class="n">grad</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rescale_grad</span>
        <span class="n">state</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">weight</span>

<span class="c1"># backward compatibility wrapper for Optimizer.CreateOptimizer</span>
<span class="n">create</span> <span class="o">=</span> <span class="n">Optimizer</span><span class="o">.</span><span class="n">create_optimizer</span>  <span class="c1"># pylint: disable=invalid-name</span>

<span class="k">class</span> <span class="nc">Updater</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Updater for kvstore.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">states_synced</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_updates</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">aggregate_num</span> <span class="o">&gt;</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">grad</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Updates weight given gradient and index.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">index</span><span class="p">]</span>
            <span class="n">grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">grad</span><span class="p">]</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">weight</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">index</span>
            <span class="n">grads</span> <span class="o">=</span> <span class="n">grad</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">weight</span>
        <span class="k">if</span> <span class="n">weights</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">_set_current_context</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">context</span><span class="o">.</span><span class="n">device_id</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">indices</span><span class="p">):</span>
            <span class="c1"># convert ctypes.char_p.value back to python str if needed</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">bytes</span><span class="p">):</span>
                <span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">py_str</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">create_state_multi_precision</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">states_synced</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">states_synced</span><span class="p">[</span><span class="n">idx</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> \
                    <span class="bp">self</span><span class="o">.</span><span class="n">sync_state_context</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">context</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">states_synced</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_updates</span><span class="p">:</span>
            <span class="c1"># segregate values based on type</span>
            <span class="n">type_map</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">g</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="n">type_map</span><span class="p">:</span>
                    <span class="n">type_map</span><span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">dtype</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">i</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">g</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">type_map</span><span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">dtype</span><span class="p">]</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">g</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">type_map</span><span class="p">:</span>
                <span class="n">current_index</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">indices</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">grads</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">type_map</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
                <span class="k">while</span> <span class="n">current_index</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">):</span>
                    <span class="n">states</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="n">step</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">aggregate_num</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span> <span class="o">-</span> <span class="n">current_index</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
                        <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">current_index</span> <span class="o">+</span> <span class="n">j</span><span class="p">]])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">update_multi_precision</span><span class="p">(</span>
                        <span class="n">indices</span><span class="p">[</span><span class="n">current_index</span><span class="p">:</span><span class="n">current_index</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">aggregate_num</span><span class="p">],</span>
                        <span class="n">weights</span><span class="p">[</span><span class="n">current_index</span><span class="p">:</span><span class="n">current_index</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">aggregate_num</span><span class="p">],</span>
                        <span class="n">grads</span><span class="p">[</span><span class="n">current_index</span><span class="p">:</span><span class="n">current_index</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">aggregate_num</span><span class="p">],</span>
                        <span class="n">states</span><span class="p">)</span>
                    <span class="n">current_index</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">aggregate_num</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">g</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">grads</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">update_multi_precision</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">sync_state_context</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;sync state context.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">NDArray</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">state</span><span class="o">.</span><span class="n">as_in_context</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="n">synced_state</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sync_state_context</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">state</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">synced_state</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">synced_state</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">state</span>

    <span class="k">def</span> <span class="nf">set_states</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">states</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets updater states.&quot;&quot;&quot;</span>
        <span class="n">states</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">states</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">states</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">states</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">states</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="n">states</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">states_synced</span> <span class="o">=</span> <span class="nb">dict</span><span class="o">.</span><span class="n">fromkeys</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_states</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dump_optimizer</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Gets updater states.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dump_optimizer : bool, default False</span>
<span class="sd">            Whether to also save the optimizer itself. This would also save optimizer</span>
<span class="sd">            information such as learning rate and weight decay schedules.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span> <span class="k">if</span> <span class="n">dump_optimizer</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_updater</span><span class="p">(</span><span class="n">optimizer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a closure of the updater needed for kvstore.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    optimizer: Optimizer</span>
<span class="sd">         The optimizer.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    updater: function</span>
<span class="sd">         The closure of the updater.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">Updater</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
</pre></div>

        </div>
        <div class="side-doc-outline">
            <div class="side-doc-outline--content"> 
            </div>
        </div>                    

      <div class="clearer"></div>
    </div><div class="pagenation">
  </div>
            <footer class="site-footer h-card">
    <div class="wrapper">
        <div class="row">
            <div class="col-4">
                <h4 class="footer-category-title">Resources</h4>
                <ul class="contact-list">
                    <li><a class="u-email" href="mailto:dev@mxnet.apache.org">Dev list</a></li>
                    <li><a class="u-email" href="mailto:user@mxnet.apache.org">User mailing list</a></li>
                    <li><a href="https://cwiki.apache.org/confluence/display/MXNET/Apache+MXNet+Home">Developer Wiki</a></li>
                    <li><a href="https://issues.apache.org/jira/projects/MXNET/issues">Jira Tracker</a></li>
                    <li><a href="https://github.com/apache/incubator-mxnet/labels/Roadmap">Github Roadmap</a></li>
                    <li><a href="https://discuss.mxnet.io">MXNet Discuss forum</a></li>
                    <li><a href="/mxnet.io-v2/community/contribute">Contribute To MXNet</a></li>

                </ul>
            </div>

            <div class="col-4"><ul class="social-media-list"><li><a href="https://github.com/apache/incubator-mxnet"><svg class="svg-icon"><use xlink:href="../../../_static/minima-social-icons.svg#github"></use></svg> <span class="username">apache/incubator-mxnet</span></a></li><li><a href="https://www.twitter.com/apachemxnet"><svg class="svg-icon"><use xlink:href="../../../_static/minima-social-icons.svg#twitter"></use></svg> <span class="username">apachemxnet</span></a></li><li><a href="https://youtube.com/apachemxnet"><svg class="svg-icon"><use xlink:href="../../../_static/minima-social-icons.svg#youtube"></use></svg> <span class="username">apachemxnet</span></a></li></ul>
</div>

            <div class="col-4 footer-text">
                <p>A flexible and efficient library for deep learning.</p>
            </div>
        </div>
    </div>
</footer>

<footer class="site-footer2">
    <div class="wrapper">
        <div class="row">
            <div class="col-3">
                <img src="../../../_static/apache_incubator_logo.png" class="footer-logo col-2">
            </div>
            <div class="footer-bottom-warning col-9">
                <p>Apache MXNet is an effort undergoing incubation at The Apache Software Foundation (ASF), <span style="font-weight:bold">sponsored by the <i>Apache Incubator</i></span>. Incubation is required
                    of all newly accepted projects until a further review indicates that the infrastructure,
                    communications, and decision making process have stabilized in a manner consistent with other
                    successful ASF projects. While incubation status is not necessarily a reflection of the completeness
                    or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
                </p><p>"Copyright © 2017-2018, The Apache Software Foundation Apache MXNet, MXNet, Apache, the Apache
                    feather, and the Apache MXNet project logo are either registered trademarks or trademarks of the
                    Apache Software Foundation."</p>
            </div>
        </div>
    </div>
</footer>
        
  </body>
</html>